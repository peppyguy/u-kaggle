{"nbformat": 4, "nbformat_minor": 0, "cells": [{"outputs": [], "metadata": {"_cell_guid": "762b4321-9818-4397-88fc-f5090d48aefc", "_execution_state": "idle", "collapsed": false, "_uuid": "f36ff51f7a8011531c0fc6f45a8e1bca37980870"}, "execution_count": null, "source": "## Featured in [The Wall Street Journal][1].\n\n  [1]: https://www.wsj.com/articles/fans-geek-out-over-game-of-thrones-data-1499877067", "cell_type": "markdown"}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport matplotlib.patches as mpatches\nsns.set_style(\"white\")", "metadata": {"trusted": false, "_cell_guid": "e4a6ad63-122e-44a9-9a17-50fc75cc9d87", "_execution_state": "idle", "_uuid": "f7a98aa52426b1353eae4adb2e0cf348438d9eea"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "plt.rcParams[\"axes.labelsize\"] = 16.\nplt.rcParams[\"xtick.labelsize\"] = 14.\nplt.rcParams[\"ytick.labelsize\"] = 14.\nplt.rcParams[\"legend.fontsize\"] = 12.\nplt.rcParams[\"figure.figsize\"] = [15., 6.]", "metadata": {"trusted": false, "_cell_guid": "701b2c84-0c8f-4456-90b1-bdb418228861", "_execution_state": "idle", "_uuid": "a036de605a0746314e96fe4304a504dd14893f75"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "battles = pd.read_csv(\"../input/battles.csv\")\ncharacter_deaths = pd.read_csv(\"../input/character-deaths.csv\")\ncharacter_predictions = pd.read_csv(\"../input/character-predictions.csv\")", "metadata": {"trusted": false, "_cell_guid": "e36b630b-0d43-46cd-a6ec-266b10ac84c8", "_execution_state": "idle", "_uuid": "d483ad807be792e5e4eb17c2423333f07c0a98dd"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "2bb21e8b-7d19-438e-8fb9-18bb2457a400", "_uuid": "c2bf1a22f55c5ea130698fbcf29450ff891548bb"}, "source": "## New attributes\n1. *defender_count* \u2013 Number of major houses on defending side\n2. *attacker_count* \u2013 Number of major houses on attacking side\n3. *att_comm_count* \u2013 Number of commanders on attacking side\n4. *no_of_books* \u2013 Number of books a character appeared in", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "battles.loc[:, \"defender_count\"] = (4 - battles[[\"defender_1\", \"defender_2\", \"defender_3\", \"defender_4\"]].isnull().sum(axis = 1))\nbattles.loc[:, \"attacker_count\"] = (4 - battles[[\"attacker_1\", \"attacker_2\", \"attacker_3\", \"attacker_4\"]].isnull().sum(axis = 1))\nbattles.loc[:, \"att_comm_count\"] = [len(x) if type(x) == list else np.nan for x in battles.attacker_commander.str.split(\",\")]\ncharacter_predictions.loc[:, \"no_of_books\"] = character_predictions[[x for x in character_predictions.columns if x.startswith(\"book\")]].sum(axis = 1)", "metadata": {"trusted": false, "_cell_guid": "0b3cb149-9773-4ff1-a260-61f6a4681c48", "_execution_state": "idle", "_uuid": "52f226ef98cc5c4b8698e4108c37eb99dd0e4c2f"}}, {"outputs": [], "metadata": {"_cell_guid": "1cb2efaa-3ca6-4307-ac37-bddd871baa86", "_execution_state": "idle", "collapsed": false, "_uuid": "4ff367f70e145450b9624895a77a9ab380fa7fcd"}, "execution_count": null, "source": "# Exploratory Analysis", "cell_type": "markdown"}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "4ffca823-3696-4137-b5f9-58b327ebcb99", "_uuid": "91b8e5c9c51a748c06f051fe4ce977941c7f3ac9"}, "source": "## Major death/capture events by year", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "p = battles.groupby('year').sum()[[\"major_death\", \"major_capture\"]].plot.bar(rot = 0)\n_ = p.set(xlabel = \"Year\", ylabel = \"No. of Death/Capture Events\", ylim = (0, 9)), p.legend([\"Major Deaths\", \"Major Captures\"])", "metadata": {"trusted": false, "_cell_guid": "645bd299-550d-45ad-ada8-d69022d312f5", "_execution_state": "idle", "_uuid": "4aa497cb3db5aaed381bd5f0a9752135b0753bd3"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "62657591-68d6-4de1-96b5-5d0ed3c9b893", "_uuid": "60b440a4391c0672f25dd1e4fbce0951b147ed06"}, "source": "## Impact of army size on outcome\n[Based on ggplot code from this notebook](https://github.com/chrisalbon/war_of_the_five_kings_dataset/blob/master/exploratory_analysis.ipynb)", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "data = battles.dropna(axis = 0, subset = [[\"attacker_size\", \"defender_size\", \"attacker_outcome\"]]).copy(deep = True)\ncolors = [sns.color_palette()[0] if x == \"win\" else \"lightgray\" for x in data.attacker_outcome.values]\np = data.plot.scatter(\"attacker_size\", \"defender_size\", c = colors, s = 100, lw = 2.)\n_ = p.set(xlabel = \"Attacker Size\", ylabel = \"Defender Size\")", "metadata": {"trusted": false, "_cell_guid": "5d4ae3d7-d48e-4334-8882-455815264c5f", "_execution_state": "idle", "_uuid": "cbc2a8c9443b2d6bdcbacaa1b5bf55731f0a262e"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "5c821739-805d-4cc5-b622-5d7a00d6a6c4", "_uuid": "9349789aebe800f9c41260a29c9378c47622ec2f"}, "source": "## How often were there more than one major houses on the attacking side?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "p = battles.attacker_count.value_counts().sort_index().plot.bar(rot = 0)\n_ = p.set(xlabel = \"No. of Major Attacker Houses\", ylabel = \"Count\")", "metadata": {"trusted": false, "_cell_guid": "b9c8e374-9127-4f0c-bbfe-cc20a2865870", "_execution_state": "idle", "_uuid": "cf5f93a04927e088351d8d44539a6c7cae19a501"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "11f238c9-20b4-4f0c-a489-d0e938741309", "_uuid": "070f4401b24775e8740ad027cd5c18a14250197a"}, "source": "## Which pairs fought the most battles?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "#Ignoring records where either attacker_king or defender_king is null. Also ignoring one record where both have the same value.\nc = list(Counter([tuple(set(x)) for x in battles.dropna(subset = [\"attacker_king\", \"defender_king\"])[[\"attacker_king\", \"defender_king\"]].values if len(set(x)) > 1]).items())\np = pd.DataFrame(c).sort_values(1).plot.barh(figsize = (10, 6))\n_ = p.set(yticklabels = [\"%s vs. %s\" % (x[0], x[1]) for x in list(zip(*c))[0]], xlabel = \"No. of Battles\"), p.legend(\"\")", "metadata": {"trusted": false, "_cell_guid": "63f25f27-a179-4651-a92f-071702a9e60b", "_execution_state": "idle", "_uuid": "84f6d54bab6e1b8e617ff5e1aeb07346a36fcf9c"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "5ca4f66c-4d04-448b-bd94-63068b16462f", "_uuid": "b188e1692f7f75338690c47fc4174d83694f9a5d"}, "source": "## How many commanders did armies of different kings have?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "p = sns.boxplot(\"att_comm_count\", \"attacker_king\", data = battles, saturation = .6, fliersize = 10., palette = [\"lightgray\", sns.color_palette()[1], \"grey\", \"darkblue\"])\n_ = p.set(xlabel = \"No. of Attacker Commanders\", ylabel = \"Attacker King\", xticks = range(8))", "metadata": {"trusted": false, "_cell_guid": "0322c93b-f4be-45bf-89dd-f53c161f050b", "_execution_state": "idle", "_uuid": "ddf1921936876416fd79a65b7b3db3b32234c19d"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "d5a4fe93-68f4-4082-b90a-bf77fed59c48", "_uuid": "f651178cab0795b32871d3cd6fe5b6a8fe05c901"}, "source": "## How many major death/capture events occur in each region?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "data = battles.groupby(\"region\").sum()[[\"major_death\", \"major_capture\"]]\np = pd.concat([data, battles.region.value_counts().to_frame()], axis = 1).sort_values(\"region\", ascending = False).copy(deep = True).plot.bar(color = [sns.color_palette()[1], \"grey\", \"darkblue\"], rot = 0)\n_ = p.set(xlabel = \"Region\", ylabel = \"No. of Events\"), p.legend([\"Major Deaths\", \"Major Captures\", \"No. of Battles\"], fontsize = 12.)", "metadata": {"trusted": false, "_cell_guid": "3363d942-cc8f-4c8b-bbd8-8223f919e117", "_execution_state": "idle", "_uuid": "ee2852fde1f6ee570de06799992af9d0f3be0918"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "db3321c9-568b-4a8b-89b7-c61885437b21", "_uuid": "24ae52072fb7cf06a648a124712e8bd3e227d823"}, "source": "## Is there a relationship between survival and having dead relations?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "data = character_predictions.groupby([\"boolDeadRelations\", \"isAlive\"]).count()[\"S.No\"].unstack().copy(deep = True)\np = data.div(data.sum(axis = 1), axis = 0).plot.barh(stacked = True, rot = 0, width = .5)\n_ = p.set_xlim([0, 1]), p.set(yticklabels = [\"No\", \"Yes\"], xticklabels = \"\", xlabel = \"Proportion of Dead vs. Alive\", ylabel = \"Has Dead Relations\"), p.legend([\"Dead\", \"Alive\"])", "metadata": {"trusted": false, "_cell_guid": "e74041a6-b200-4e4a-8f97-de1b6014fcbd", "_execution_state": "idle", "_uuid": "81a72ade04cf628cf68e39f264ca195129fff12e"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "d6478730-7908-4abf-bba5-6e5363e91123", "_uuid": "bc90d80c8665b07516026dc8c39d0db4772fe148"}, "source": "## How does appearing in more books relate to survival?", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "data = character_predictions.groupby([\"no_of_books\", \"isAlive\"]).count()[\"S.No\"].unstack().copy(deep = True)\np = data.div(data.sum(axis = 1), axis = 0).plot.barh(stacked = True, rot = 0, figsize = (15, 8), width = .5)\n_ = p.set(xticklabels = \"\", xlim = [0, 1], ylabel = \"No. of Books\", xlabel = \"Proportion of Dead vs. Alive\"), p.legend([\"Dead\", \"Alive\"], loc = \"upper right\", ncol = 2, borderpad = -.15)", "metadata": {"trusted": false, "_cell_guid": "235f9ee0-1a09-4db3-8f13-e1605de490af", "_execution_state": "idle", "_uuid": "5f03fe29d28aff0e4cf7671d58bc0f4519d4d9e6"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "83ba7686-c2a9-4645-aa22-683657fda00f", "_uuid": "6df40fbe46d1c474351eae8b2a153b7afd4a02f6"}, "source": "## How does culture relate to survival?\nFor this, we will rename cultures using (ahem) domain knowledge as many of the culture values map to a single culture.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "cult = {\n    'Summer Islands': ['summer islands', 'summer islander', 'summer isles'],\n    'Ghiscari': ['ghiscari', 'ghiscaricari',  'ghis'],\n    'Asshai': [\"asshai'i\", 'asshai'],\n    'Lysene': ['lysene', 'lyseni'],\n    'Andal': ['andal', 'andals'],\n    'Braavosi': ['braavosi', 'braavos'],\n    'Dornish': ['dornishmen', 'dorne', 'dornish'],\n    'Myrish': ['myr', 'myrish', 'myrmen'],\n    'Westermen': ['westermen', 'westerman', 'westerlands'],\n    'Westerosi': ['westeros', 'westerosi'],\n    'Stormlander': ['stormlands', 'stormlander'],\n    'Norvoshi': ['norvos', 'norvoshi'],\n    'Northmen': ['the north', 'northmen'],\n    'Free Folk': ['wildling', 'first men', 'free folk'],\n    'Qartheen': ['qartheen', 'qarth'],\n    'Reach': ['the reach', 'reach', 'reachmen'],\n}\n\ndef get_cult(value):\n    value = value.lower()\n    v = [k for (k, v) in cult.items() if value in v]\n    return v[0] if len(v) > 0 else value.title()", "metadata": {"trusted": false, "_cell_guid": "fe18888a-f8b1-4a1a-b12e-b5661ed708ef", "_execution_state": "idle", "_uuid": "96b7d73fd9750ba7aef262374daeb140d561a826"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "character_predictions.loc[:, \"culture\"] = [get_cult(x) for x in character_predictions.culture.fillna(\"\")]\ndata = character_predictions.groupby([\"culture\", \"isAlive\"]).count()[\"S.No\"].unstack().copy(deep = True)\ndata.loc[:, \"total\"]= data.sum(axis = 1)\np = data[data.index != \"\"].sort_values(\"total\")[[0, 1]].plot.barh(stacked = True, rot = 0, figsize = (14, 12),)\n_ = p.set(xlabel = \"No. of Characters\", ylabel = \"Culture\"), p.legend([\"Dead\", \"Alive\"], loc = \"lower right\")", "metadata": {"trusted": false, "_cell_guid": "1e92e84d-c187-4200-ad43-bc9f81dbcdb4", "_execution_state": "idle", "_uuid": "f971d60f8cb67b880a29c5fe2926ac8c7e370c01"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "d2f49a99-46db-4836-9439-a9350dda0d49", "_uuid": "2080ada9a2e3bf03dc073d851e5ee56d1b7d9650"}, "source": "## Do larger armies necessarily win?\nThe results for this one are, well, weird as you can see.\n\nTo be fair, though, I have only considered battles with valid values for *attacker\\_size* and *defender\\_size*, which reduces the record count to 16 down from 37. I am not a GoT fan (yet) nor have I watched the TV series.\n\nI read about one of the battles with `NaN` *attacker\\_size* on the [GoT Wikia](http://gameofthrones.wikia.com/wiki/Battle_at_the_Mummer's_Ford), wherein the following is stated under the _Forces_ section:\n> A raiding party was reported by the Riverlands smallfolk refugees but the Iron Throne detachment was met by a considerably larger force.\n\nBased on this, if we assumed that *attacker\\_size* was larger, it would count in favor of the position that larger armies are likelier to win. However, we do not have this data for the remaining 20 battles so we cannot say anything conclusively.\n\n**If you are knowledgeable about GoT, do comment below on this.**", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "data = battles.dropna(subset = [\"attacker_size\", \"defender_size\"]).copy(deep = True)\ndata = pd.concat([(data.attacker_size - data.defender_size).to_frame(), battles[[\"attacker_outcome\"]]], axis = 1, join = \"inner\")\ndata = data[data[0] != 0]\np = data[0].plot.barh(figsize = (12, 8), width = .8, color = [sns.color_palette()[0] if x == \"win\" else sns.color_palette()[2] if x == \"loss\" else \"white\" for x in data.attacker_outcome.values])\n_ = p.legend(handles = [mpatches.Patch(color = sns.color_palette()[0], label = \"Victory\", aa = True), mpatches.Patch(color = sns.color_palette()[2], label = \"Loss\", aa = True)])\n_ = p.axvline(0, color = 'k'), p.set(yticklabels = battles.name.iloc[data.index].values, xlabel = \"Difference in Army Size (attacker_size - defender_size)\", ylabel = \"Battle Name\")", "metadata": {"trusted": false, "_cell_guid": "b7261f41-6779-4ecb-8df3-d9f0e3263263", "_execution_state": "idle", "_uuid": "fcbecb9e8fee36e4985ac93e834e5f75efd245e0"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "155c8174-beee-4358-b289-ba2ca98e543f", "_uuid": "ae06fbe9a2bc172a711579bf203c1ec77ae6b5e0"}, "source": "## How often did kings fight different types of battles?\nThe data contains four types of battles of which _Pitched Battle_ is the most frequent and _Razing_ the least.\n\nIt turns out that _Ambush_ seems to be Robb Stark's favorite type of attack. All five of his _Ambush_ type battles are against Joffrey/Tommen Baratheon. Robb Stark has also been a target of an ambush: twice by Balon/Euron Greyjoy and thrice by Joffrey/Tommen Baratheon.\n\nBalon/Euron Greyjoy has fought each type of battle at least once as an attacker while Joffrey/Tommen Baratheon has done so as a defender.\n\nSee chart below.\n\n*(Using code from matplotlib's radar chart [example](http://matplotlib.org/examples/api/radar_chart.html).)*", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "from matplotlib.path import Path\nfrom matplotlib.spines import Spine\nfrom matplotlib.projections.polar import PolarAxes\nfrom matplotlib.projections import register_projection\n\ndef radar_factory(num_vars, frame = \"circle\"):\n    theta = np.linspace(0, 2 * np.pi, num_vars, endpoint = False)\n    theta += np.pi / 2\n\n    def draw_poly_patch(self):\n        verts = unit_poly_verts(theta)\n        return plt.Polygon(verts, closed = True, edgecolor = 'k')\n\n    def draw_circle_patch(self):\n        return plt.Circle((0.5, 0.5), 0.5)\n\n    patch_dict = {'polygon': draw_poly_patch, 'circle': draw_circle_patch}\n    if frame not in patch_dict: raise ValueError('unknown value for `frame`: %s' % frame)\n\n    class RadarAxes(PolarAxes):\n        name, RESOLUTION, draw_patch = 'radar', 1, patch_dict[frame]\n\n        def fill(self, *args, **kwargs):\n            closed = kwargs.pop(\"closed\", True)\n            return super(RadarAxes, self).fill(closed = closed, *args, **kwargs)\n\n        def plot(self, *args, **kwargs):\n            lines = super(RadarAxes, self).plot(*args, **kwargs)\n            for line in lines: self._close_line(line)\n\n        def _close_line(self, line):\n            x, y = line.get_data()\n            if x[0] != x[-1]:\n                x = np.concatenate((x, [x[0]]))\n                y = np.concatenate((y, [y[0]]))\n                line.set_data(x, y)\n\n        def set_varlabels(self, labels):\n            self.set_thetagrids(np.degrees(theta), labels)\n\n        def _gen_axes_patch(self):\n            return self.draw_patch()\n\n        def _gen_axes_spines(self):\n            if frame == \"circle\": return PolarAxes._gen_axes_spines(self)\n            spine_type, verts = \"circle\", unit_poly_verts(theta)\n            verts.append(verts[0])\n            path = Path(verts)\n            spine = Spine(self, spine_type, path)\n            spine.set_transform(self.transAxes)\n            return {'polar': spine}\n    register_projection(RadarAxes)\n    return theta\n\ndef unit_poly_verts(theta):\n    x0, y0, r = [0.5] * 3\n    verts = [(r * np.cos(t) + x0, r * np.sin(t) + y0) for t in theta]\n    return verts\n\nkings = list(battles.attacker_king.append(battles.defender_king).fillna(\"Unknown\").unique())\nbattle_types = list(battles.battle_type.fillna(\"Unknown\").str.title().unique())\n\ndef example_data():\n    data = battles[[\"battle_type\", \"attacker_king\", \"defender_king\", \"name\"]].copy(deep = True).fillna(\"Unknown\")\n    data.loc[:, \"battle_type\"] = data.battle_type.fillna(\"Unknown\").str.title()\n    grouped, ret_data = data.groupby([\"attacker_king\", \"battle_type\"]).count()[[\"name\"]], [battle_types]\n    ret_data.append((\"As Attacker King\", [[grouped.loc[(kings[j], battle_types[i])].values[0]\n                                    if (kings[j], battle_types[i]) in grouped.index else 0\n                                    for i in range(len(battle_types))] for j in range(len(kings))]))\n    grouped = data.groupby([\"defender_king\", \"battle_type\"]).count()[[\"name\"]]\n    ret_data.append((\"As Defender King\", [[grouped.loc[(kings[j], battle_types[i])].values[0]\n                                    if (kings[j], battle_types[i]) in grouped.index else 0\n                                    for i in range(len(battle_types))] for j in range(len(kings))]))\n    return ret_data\n\nN = 5\ntheta, data = radar_factory(N, frame = \"polygon\"), example_data()\nspoke_labels, fig = data.pop(0), plt.figure(figsize = (14, 14))\nfig.subplots_adjust(wspace = 0.35, hspace = 0.20, top = 0.85, bottom = 0.05)\ncolors = sns.color_palette() + [\"k\"]\nfor n, (title, case_data) in enumerate(data):\n    ax, _ = fig.add_subplot(2, 2, n + 1, projection = \"radar\"), plt.rgrids([1, 2, 3, 4, 5])\n    ax.set_title(title, weight = \"bold\", position = (0.5, 1.1), horizontalalignment = \"center\", verticalalignment = \"center\", fontsize = 13.)\n    for d, color in zip(case_data, colors):\n        ax.plot(theta, d, color = color)\n        ax.fill(theta, d, facecolor = color, alpha = 0.5)\n    ax.set_varlabels(spoke_labels)\nplt.subplot(2, 2, 1)\nlabels = kings\nlegend = plt.legend(labels, loc = (.95, .95), labelspacing = 0.1)\nplt.setp(legend.get_texts(), fontsize = \"large\")\nplt.figtext(0.5, 0.965, \"Types of Battles Fought By Kings as Attacker/Defender\", ha = \"center\", color = \"k\", size = 16.)\nplt.show()", "metadata": {"trusted": false, "_cell_guid": "d6b32cb0-a0fa-4b09-9d3b-15ab476c63f9", "_execution_state": "idle", "_uuid": "c21a12c9901c41d74e127932561d0d53e924c2d8"}}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "death_preds = character_predictions.copy(deep = True)", "metadata": {"trusted": false, "_cell_guid": "7a24b88d-d231-4d4c-a0bc-70787bae602c", "_execution_state": "idle", "_uuid": "b2d4d9e25e0b95c6555b9dbf9771c7467b028e0c"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "69710b69-394f-431a-b7cd-f0d1cbdb49b3", "_uuid": "dc64e863034ec2d27c0fb1f4b8f29e57d100181f"}, "source": "# Predictive Experiment\nI have added this quick predictive experiment to complete the analysis. It does not go into too much depth. However, I will try and add more things as and when I get time.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "from xgboost import plot_importance\nfrom xgboost import XGBClassifier as XGBC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, roc_curve, log_loss, confusion_matrix, precision_score, recall_score, classification_report, accuracy_score", "metadata": {"trusted": false, "_cell_guid": "7128ba1b-4f3b-4701-8d11-6266cf11fe63", "_execution_state": "idle", "_uuid": "085eb330ec7f43b3e7719e6225e999b94f82a61c"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "0d2ff403-2a00-408b-beff-2b351f86b748", "_uuid": "2dc59e65cdf88c2d8612e72b868532ec3051aa1e"}, "source": "## A bit of preprocessing\nWe quickly convert non-numeric categorical features to numeric. Then we drop some columns and replace missing values with -1.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "death_preds.loc[:, \"culture\"] = [get_cult(x) for x in death_preds.culture.fillna(\"\")]\ndeath_preds.loc[:, \"title\"] = pd.factorize(death_preds.title)[0]\ndeath_preds.loc[:, \"culture\"] = pd.factorize(death_preds.culture)[0]\ndeath_preds.loc[:, \"mother\"] = pd.factorize(death_preds.mother)[0]\ndeath_preds.loc[:, \"father\"] = pd.factorize(death_preds.father)[0]\ndeath_preds.loc[:, \"heir\"] = pd.factorize(death_preds.heir)[0]\ndeath_preds.loc[:, \"house\"] = pd.factorize(death_preds.house)[0]\ndeath_preds.loc[:, \"spouse\"] = pd.factorize(death_preds.spouse)[0]\n\ndeath_preds.drop([\"name\", \"alive\", \"pred\", \"plod\", \"isAlive\", \"dateOfBirth\"], 1, inplace = True)\ndeath_preds.columns = map(lambda x: x.replace(\".\", \"\").replace(\"_\", \"\"), death_preds.columns)\ndeath_preds.fillna(value = -1, inplace = True)", "metadata": {"trusted": false, "_cell_guid": "0ae8114a-895a-4106-84ba-308fa15a6eb6", "_execution_state": "idle", "_uuid": "261ce2834a628856285c09ad2076ae3be89aaa16"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "e966c23a-5bd0-4ea5-a09a-b3b7a7da14f0", "_uuid": "edb67a6bfb0523a0554da3379f80a6696a845617"}, "source": "## Is there a class imbalance?\nLet us take a look at the class distribution now.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "f, ax = plt.subplots(1, 2, figsize = (15, 7))\nf.suptitle(\"Class Distribution\", fontsize = 18.)\n_ = death_preds.actual.value_counts().plot.bar(ax = ax[0], rot = 0, color = (sns.color_palette()[0], sns.color_palette()[2])).set(xticklabels = [\"Alive\", \"Deceased\"])\n_ = death_preds.actual.value_counts().plot.pie(labels = (\"Alive\", \"Deceased\"), autopct = \"%.2f%%\", label = \"\", fontsize = 13., ax = ax[1],\\\ncolors = (sns.color_palette()[0], sns.color_palette()[2]), wedgeprops = {\"linewidth\": 1.5, \"edgecolor\": \"#F7F7F7\"}), ax[1].texts[1].set_color(\"#F7F7F7\"), ax[1].texts[3].set_color(\"#F7F7F7\")", "metadata": {"trusted": false, "_cell_guid": "a2917f76-b086-4e9c-9362-cd8ebea95368", "_execution_state": "idle", "_uuid": "1f72accf32ad4fac16cc86e8f070e0a7c75bd115"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "b229733f-ed76-40c6-9c87-ddf464765859", "_uuid": "6dae708e6cf49a0758a0307955e033e1725403a7"}, "source": "The class distribution indicates an imbalance. There are many more characters alive than dead. There are several well-known ways to tackle this problem.\n\nTwo of the simplest ways are undersampling and oversampling. In this case, we will undersample the majority class. We will draw ~70% samples without replacement from the minority *Deceased* class. We will draw an equal number of samples (~350) from the majority *Alive* class.\n\nUsing this train-test split we will build and compare two models: an XGB Classifier model and a Logistic Regression model.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "X = death_preds[death_preds.actual == 0].sample(350, random_state = 62).append(death_preds[death_preds.actual == 1].sample(350, random_state = 62)).copy(deep = True).astype(np.float64)\nY = X.actual.values\ntX = death_preds[~death_preds.index.isin(X.index)].copy(deep = True).astype(np.float64)\ntY = tX.actual.values\nX.drop([\"SNo\", \"actual\", \"DateoFdeath\"], 1, inplace = True)\ntX.drop([\"SNo\", \"actual\", \"DateoFdeath\"], 1, inplace = True)", "metadata": {"trusted": false, "_cell_guid": "de806dc9-5d15-4a2a-a6c6-10a0671eefe0", "_execution_state": "idle", "_uuid": "ce5b7ed36ff338a40f25b7d293a849f06b4883b4"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "53e74a63-925d-49fc-a35f-75ce322e9be1", "_uuid": "c546ef08fcd454af99d3af7931e1f2852cf10dc6"}, "source": "## XGB Classifier", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "clf_xgb = XGBC(subsample = .8, colsample_bytree = .8, seed = 14, max_depth = 3).fit(X, Y)\npreds_xgb = clf_xgb.predict_proba(tX)\nax = pd.DataFrame(list(clf_xgb.get_booster().get_fscore().items())).set_index(0)\\\n.sort_values(1).plot.barh(figsize = (12, 8))\n_ = ax.set(frame_on = False, ylim = (0, len(clf_xgb.get_booster().get_fscore())), xticklabels = \"\", xlabel = \"\", ylabel = \"\"), ax.legend(\"\")\n_ = plt.title(\"XGB Feature Importance\", fontsize = 18.)", "metadata": {"trusted": false, "_cell_guid": "2b9b3493-ea78-4411-b874-f71cdc7fefb4", "_execution_state": "idle", "_uuid": "8861a595d4b68c44bfeb3c6e4a29efcf6a845938"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "06c38ed9-026d-4f01-8875-77137c9b03cd", "_uuid": "91e581a2058ff477c6d9b73051ce3a12472db343"}, "source": "## Logistic Regression", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "logreg = LogisticRegression(random_state = 14).fit(X, Y)\npreds_lr = logreg.predict_proba(tX)\n\ndf = pd.DataFrame(list(zip(tX.columns, logreg.coef_[0])))\ndf = df.reindex(df[1].abs().sort_values().index).set_index(0)\nax = df.plot.barh(width = .6, legend = \"\", figsize = (12, 9))\nax.set_title(\"Logistic Regression Coefficients\", y = 1.03, fontsize = 16.)\n_ = ax.set(frame_on = False, xlabel = \"\", xticklabels = \"\", ylabel = \"\")\n\nfor i, label in enumerate(list(df.index)):\n    score = df.loc[label][1]\n    ax.annotate('%.2f' % score, (score + (-.12 if score < 0 else .02), i - .2), fontsize = 10.5)", "metadata": {"trusted": false, "_cell_guid": "f58eb0ad-1557-4699-9d4c-f71edf54e835", "_execution_state": "idle", "_uuid": "7d800bc7aec4d52f374e859d874e070ba97992f0"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "35c04284-2d5e-404b-839c-4d480cf9c431", "_uuid": "501e103285d6346e22e83f4bfdc610beac1e1801"}, "source": "## Comparison of XGB Classifier and Logistic Regression", "execution_count": null}, {"outputs": [], "metadata": {"_cell_guid": "cc932ba6-9ead-4068-b9a3-3c4614ac5f2b", "_execution_state": "idle", "collapsed": false, "_uuid": "77a9240e881f97c7acf679f7e96ae44a682294d2"}, "execution_count": null, "source": "### Confusion Matrix\nFirst we see the confusion matrices for both models. We will normalize these by their row-wise sums before visualizing.", "cell_type": "markdown"}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "f, ax = plt.subplots(1, 2, figsize = (15, 8))\nf.suptitle(\"Normalized Confusion Matrices\", fontsize = 18.)\ndef make_cm(p, t, axis):\n    cm = confusion_matrix(tY, np.argmax(p, axis = 1))\n    cm = cm.astype('float') / cm.sum(axis = 1)[:, np.newaxis]\n    _ = sns.heatmap(cm, square = True, xticklabels = [\"Deceased\", \"Alive\"], annot = True,\n                    annot_kws = {\"fontsize\": 13}, yticklabels = [\"Deceased\", \"Alive\"],\n                    cbar = True, cbar_kws = {\"orientation\": \"horizontal\"}, ax = ax[axis], cmap = \"Blues\").set(\n        xlabel = \"Predicted Class\", ylabel = \"Actual Class\", title = t)\nmake_cm(preds_xgb, \"XGB Classifier\", 0)\nmake_cm(preds_lr, \"Logistic Regression\", 1)", "metadata": {"trusted": false, "_cell_guid": "24acc660-c1d6-4e93-82b6-3caf31e3852b", "_execution_state": "idle", "_uuid": "704728ce8b95c6eb9f50d2854ab2d65f9cdd9088"}}, {"outputs": [], "metadata": {"_cell_guid": "38fc29be-aca8-40c6-90ce-5bbc6176f62f", "_execution_state": "idle", "collapsed": false, "_uuid": "8ed87696d890bd6ee56b8d178853b79d0f0aaba7"}, "execution_count": null, "source": "### Scorecard\nNext, we see the scorecard of both models. We use the handy `classification_report` and a number of other functions from `sklearn.metrics` to look at different evaluation metrics such as AUC, log loss, and accuracy.", "cell_type": "markdown"}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "print(\"XGB Classifier Performance\\n\" + \"=\" * 26 + \"\\n\", classification_report(tY, np.argmax(preds_xgb, axis = 1), target_names = [\"Deceased\", \"Alive\"]))\nprint(\"AUC      : %.4f\" % roc_auc_score(tY, preds_xgb[:, 1]))\nprint(\"Accuracy : %.4f\" % accuracy_score(tY, np.argmax(preds_xgb, axis = 1)))\nprint(\"Log Loss : %.4f\\n\\n\" % log_loss(tY, preds_xgb[:, 1]))\nprint(\"Logistic Regression Performance\\n\" + \"=\" * 31 + \"\\n\", classification_report(tY, np.argmax(preds_lr, axis = 1), target_names = [\"Deceased\", \"Alive\"]))\nprint(\"AUC      : %.4f\" % roc_auc_score(tY, preds_lr[:, 1]))\nprint(\"Accuracy : %.4f\" % accuracy_score(tY, np.argmax(preds_lr, axis = 1)))\nprint(\"Log Loss : %.4f\" % log_loss(tY, preds_lr[:, 1]))", "metadata": {"trusted": false, "_cell_guid": "e79fdfb9-e94e-4fee-bc74-b2e18fc39082", "_execution_state": "idle", "_uuid": "b037d76200d1217090cf06c0c13f59d3a832ba2e"}}, {"outputs": [], "cell_type": "markdown", "metadata": {"_cell_guid": "f362af12-016e-4c89-aed1-09b999df7439", "_uuid": "b923f4fc1aba103d7a5dc3cfd9fe2a920eeff207"}, "source": "### ROC Curves\nFinally, we look at the ROC curves for both models.", "execution_count": null}, {"outputs": [], "cell_type": "code", "execution_count": null, "source": "_ = plt.figure(figsize = (8, 8)), plt.plot(*roc_curve(tY, preds_xgb[:, 1])[:2]), plt.plot(*roc_curve(tY, preds_lr[:, 1])[:2], c = sns.color_palette()[1]), plt.legend([\"XGB Classifier\", \"Logistic Regression\"], loc = \"upper left\")\n_ = plt.plot((0., 1.), (0., 1.), \"--k\", alpha = .7), plt.xlabel(\"False Positive Rate\"), plt.ylabel(\"True Positive Rate\"), plt.title(\"ROC Curves\", fontsize = 16.)", "metadata": {"trusted": false, "_cell_guid": "cd0143c5-29d9-4f8d-98df-cf886353f7a4", "_execution_state": "idle", "_uuid": "2656072bc857f812897d36d98c6b3dd42a2651f5"}}], "metadata": {"_change_revision": 0, "_is_fork": false, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "pygments_lexer": "ipython3", "name": "python", "nbconvert_exporter": "python", "version": "3.6.1", "file_extension": ".py", "mimetype": "text/x-python"}}}