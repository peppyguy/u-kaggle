{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8ed0a71d-81a2-9918-5943-c1703a0f27ff"
      },
      "source": ""
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce53be83-4475-8d60-f4a5-b7baa884bd11"
      },
      "source": [
        "Here I am going to run Support Vector machine on the datasets and do cross validation and then use accuracy score as a parameter to judge the best combination of kernel and values of C which are the hyperparameters in SVM . Here I am taking 1 kernel at a time although we could have avoided it using GridSearchCV. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a627464e-bd59-249c-ff6e-1483fcfcf5c8"
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "from subprocess import check_output\n",
        "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cd01fe18-db57-3da4-2916-f99e096988ac"
      },
      "source": [
        "# Importing all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0247ac12-6357-659f-0182-36d245e9b551"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0200d0e4-320f-2822-88a9-f6c0225658e6"
      },
      "source": [
        "# Reading the comma separated values file into the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "2e847afc-36c5-b7bb-78c6-4288f847868e"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../input/voice.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2d654f09-1018-5498-e4ea-428752a19d4b"
      },
      "source": [
        "# Checking the correlation between each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8c9f6f78-3e24-bb65-8270-f9a795441d5e"
      },
      "outputs": [],
      "source": [
        "df.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "51c112a4-8b80-2a6a-5688-825581b9c1dd"
      },
      "source": [
        "# Checking whether there is any null values "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "af637554-1c8d-cdf4-c76e-6429511dbcf7"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da3a570c-0527-1f21-a980-edebea590239"
      },
      "outputs": [],
      "source": [
        "df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fe354f60-1504-a06e-9675-c80c755bf66f"
      },
      "outputs": [],
      "source": [
        "print(\"Total number of labels: {}\".format(df.shape[0]))\n",
        "print(\"Number of male: {}\".format(df[df.label == 'male'].shape[0]))\n",
        "print(\"Number of female: {}\".format(df[df.label == 'female'].shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "af99e2cb-9132-7c97-3dce-6a81c6b85bb9"
      },
      "source": [
        "Thus we can see there are equal number of male and female labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78f518d5-a32d-376f-d132-1250bd0b7544"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "85fbbf85-f199-9528-8147-7583154c4c6e"
      },
      "source": [
        "There are 21 features and 3168 instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "35926698-93b2-6af7-7647-20e876461359"
      },
      "source": [
        "# Separating features and labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "36d5feea-f653-99c9-aa5d-a60c9f0d20f8"
      },
      "outputs": [],
      "source": [
        "X=df.iloc[:, :-1]\n",
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "eabb15db-3594-8ad5-2a5b-10527ac27b88"
      },
      "source": [
        "# Converting string value to int type for labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d4681c81-0d46-deac-48a8-8238f7fe330c"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "y=df.iloc[:,-1]\n",
        "\n",
        "# Encode label category\n",
        "# male -> 1\n",
        "# female -> 0\n",
        "\n",
        "gender_encoder = LabelEncoder()\n",
        "y = gender_encoder.fit_transform(y)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c4badc10-5597-845a-85e2-c8cbf4c3e0d4"
      },
      "source": [
        "# Data Standardisation\n",
        "Standardization refers to shifting the distribution of each attribute to have a mean of zero and a standard deviation of one (unit variance). It is useful to standardize attributes for a model. Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3c999a7a-cded-223a-3b4f-55ee8fbbdb7e"
      },
      "outputs": [],
      "source": [
        "# Scale the data to be between -1 and 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "31ce4128-0a4a-ae10-3a25-1c362398295c"
      },
      "source": [
        "# Splitting dataset into training set and testing set for better generalisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "ea416e41-d033-34de-6e28-5725be182435"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "416eb826-73fc-bbd2-0676-2a803ae9327b"
      },
      "source": [
        "# Running SVM with default hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "05ccf988-5612-03ac-5d2f-122baa32ab19"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "svc=SVC() #Default hyperparameters\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred=svc.predict(X_test)\n",
        "print('Accuracy Score:')\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "7bdca3cb-606e-b49b-eedf-9f4e128c05d8"
      },
      "source": [
        "We are getting a good accuracy score.But data are split into training and testing data randomly.Thus a lot depends on how the data got split. When we are not using Random state as a hyperparameter everytime data is splitted differently into training and testing testsa and we get different accuracy score. This is when K-fold Cross validation is a good option"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "fd19993f-2f0d-c9da-e944-3206e6a292c0"
      },
      "outputs": [],
      "source": [
        "svc=SVC(kernel='linear',C=1)\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred=svc.predict(X_test)\n",
        "print('Accuracy Score:')\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "61a30229-7028-815d-631f-1b24343da1b3"
      },
      "outputs": [],
      "source": [
        "svc=SVC(kernel='rbf',C=1)\n",
        "svc.fit(X_train,y_train)\n",
        "y_pred=svc.predict(X_test)\n",
        "print('Accuracy Score:')\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3930931d-baeb-c86d-73a8-ec2b72cc67ba"
      },
      "source": [
        "Again with kernel as rbf we are getting a marginal less accuracy score s compared to linear kernel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c353406f-4374-0301-8d96-5767e038551a"
      },
      "source": [
        "Thus with K-fold cross validation we are splitting data in K equal parts(in our case K=10).For every value of K we got different training and testing data picking 1/10th of the data a time and train all of them thus covering all the data.In the end we take mean of all the sets. Generally K=10 is taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "25f97e10-5a1c-103a-4be1-f9d766ade49d"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import cross_val_score\n",
        "svc=SVC(kernel='linear',C=1)\n",
        "scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "f1e11e9e-0d61-70cb-8d80-3c31fcce6cef"
      },
      "outputs": [],
      "source": [
        "We can see above how the accuracy score is different everytime.This shows that accuracy score depends upon how the datasets got split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a2e7ab72-5fa9-3e54-d59c-b2b4c24ed7dc"
      },
      "outputs": [],
      "source": [
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d61c1df-0285-0a0e-64ad-c2bef642e15d"
      },
      "source": [
        "In K-fold cross validation we generally take the mean of all the scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0912611e-a132-cd7e-edcf-8f63603a7f38"
      },
      "source": [
        "### Taking all the values of C and checking out the accuracy score and kernel as linear."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "75bfb3a4-06d5-c828-23bb-a03ffea9b6c7"
      },
      "outputs": [],
      "source": [
        "C_range=list(range(1,26))\n",
        "acc_score=[]\n",
        "for c in C_range:\n",
        "    svc = SVC(kernel='linear', C=c)\n",
        "    svc.fit(X_train,y_train)\n",
        "    y_pred=svc.predict(X_test)\n",
        "    acc_score.append(metrics.accuracy_score(y_test,y_pred))\n",
        "print(acc_score)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d7d004c8-458f-ae86-d777-ab92b253df34"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "C_values=list(range(1,26))\n",
        "\n",
        "# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "plt.plot(C_values,acc_score )\n",
        "plt.xlabel('Value of C for SVC')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5f902ce7-ae22-b338-1da6-885f607ca48c"
      },
      "source": [
        "From the above plot we can see that accuracy has been close to 97.8% for C=1 and then it drops below 97.65% and remains constant.Thus we can conclude that C=1 is the best hyperparameter for linear kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a8d63c32-a177-b287-08c4-f85f144c6324"
      },
      "source": [
        "### Taking kernel as **rbc** and and taking different values of C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "282b0fe3-0b34-d692-7412-8acab5711326"
      },
      "outputs": [],
      "source": [
        "C_range=list(range(1,41))\n",
        "acc_score=[]\n",
        "for c in C_range:\n",
        "    svc = SVC(kernel='rbf', C=c)\n",
        "    svc.fit(X_train,y_train)\n",
        "    y_pred=svc.predict(X_test)\n",
        "    acc_score.append(metrics.accuracy_score(y_test,y_pred))  \n",
        "print(acc_score)        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "22bc0e0e-fdfc-6c6d-c9c5-8863f818254f"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "C_values=list(range(1,41))\n",
        "\n",
        "# plot the value of C for SVM (x-axis) versus the cross-validated accuracy (y-axis)\n",
        "plt.plot(C_values,acc_score )\n",
        "plt.xlabel('Value of C for SVC with kernel rbf')\n",
        "plt.ylabel('Cross-Validated Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ce48d3d2-322b-9d01-9649-b05ae6414735"
      },
      "source": [
        "We can see from the plot that the accuracy score is highest for C=3, and then drops at a bit and then again it is highest for C-=8,9,10,11,12,13.Also the accuracy score is slightly more than linear kernel.In this case it is around 98% particular values of C."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "10129743-3044-9dbc-b6cb-30c7d84d31a9"
      },
      "source": [
        "### Thus from the above two plots we can conclude that **rbf** kernel is performing better than the **linear** kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "2143d3d8-4abf-983d-ee4c-cc74f4fde0b7"
      },
      "source": [
        "# Now performing SVM by taking hyperparameter C=1 and kernel as linear \n",
        "\n",
        "\n",
        "----------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "499ae7bd-c349-3c50-0f6e-3ca8633d0b28"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "svc= SVC(kernel='linear',C=1)\n",
        "svc.fit(X_train,y_train)\n",
        "y_predict=svc.predict(X_test)\n",
        "accuracy_score= metrics.accuracy_score(y_test,y_predict)\n",
        "print(accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b4cf3a4a-9f64-5567-3037-bc2719ae098c"
      },
      "source": [
        "# With K-fold cross validation(where K=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4b9e8e3f-2861-ed79-d48f-ca71c9264165"
      },
      "outputs": [],
      "source": [
        "from sklearn.cross_validation import cross_val_score\n",
        "svc=SVC(kernel='linear',C=1)\n",
        "scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "daad2a8a-c37f-86b7-9120-8fb3a67cdc38"
      },
      "source": [
        "Taking the mean of all the scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "57b5946d-b6b8-b758-9570-b855ebaa6bd2"
      },
      "outputs": [],
      "source": [
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "76ec14cd-f216-6179-063e-8ec211daa46c"
      },
      "source": [
        "The accuracy is slightly good without K-fold cross validation but it may fail to generalise the unseen data.Hence it is advisable to perform K-fold cross validation where all the data is covered so it may predict unseen data well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "56374d8a-d033-e6bf-eac9-0bc508aaa171"
      },
      "source": [
        "# Now performing SVM by taking hyperparameter C=8,9,10,11,12,13 and kernel as rbf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d2233d5d-cbbb-037e-1b2f-91a1e76a3d5d"
      },
      "outputs": [],
      "source": [
        "C_range=[8,9,10,11,12,13]\n",
        "acc_score_rbf=[]\n",
        "for c in C_range:\n",
        "    svc= SVC(kernel='rbf',C=c)\n",
        "    svc.fit(X_train,y_train)\n",
        "    y_predict=svc.predict(X_test)\n",
        "    acc_score_rbf= metrics.accuracy_score(y_test,y_predict)\n",
        "    print(acc_score_rbf)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "a5530b31-17ed-8c82-6e20-bf7683b0f23d"
      },
      "source": [
        "Thus we can see that it is giving the same score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "e0b485e2-4ea3-ed6d-ece1-d29cda102038"
      },
      "source": [
        "# With K-fold cross validation(where K=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "e3baf72f-df6a-f4a0-029e-5c5dcd0aa726"
      },
      "outputs": [],
      "source": [
        "C_range=[8,9,10,11,12,13]\n",
        "acc_score_rbf=[]\n",
        "for c in C_range:\n",
        "    svc=SVC(kernel='linear',C=c)\n",
        "    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n",
        "    print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dde5471d-ff08-7762-d799-00e15fa3110e"
      },
      "outputs": [],
      "source": [
        "print(scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "78cc1818-eded-9df6-fbdb-90db00eff6c0"
      },
      "source": [
        "Thus we can conclude that kernel **rbf** and C in the range of 8 to 13 is the good choice since it is performing slightly better."
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}