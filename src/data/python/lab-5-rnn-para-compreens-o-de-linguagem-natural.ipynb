{"cells":[{"metadata":{"_uuid":"68d84bb858fe129470efff1ae450546281aee637"},"cell_type":"markdown","source":"# Laboratório 5 – Aplicação de RNN para Compreensão de Linguagem Natural"},{"metadata":{"_uuid":"bc08fbd43e13bb20f27db520ceb0147a226e0a9c"},"cell_type":"markdown","source":"Obs: Esse laboratório foi baseado [nesse artigo](https://chsasank.github.io/spoken-language-understanding.html)\n\nO problema que vamos lidar aqui é uma das tarefas típicas da [compreensão de linguagem natural](https://en.wikipedia.org/wiki/Natural_language_understanding). Nosso objetivo é identificar elementos principais em uma frase. A tarefa será, dada uma pergunta feita em um sistema sobre vôos, identificar elementos como cidade de origem e destino, datas, horários, etc.\n\nO conjunto de dados utilizado é o Airline Travel Information System (ATIS). Esses dados foram coletados na década de 90 pelo Departamento de defesa americano (DARPA). ATIS consiste em pares de perguntas e de labels para cada palavra da pergunta. \n\nAqui está um exemplo de pergunta e seus rótulos, que estão codificados usando a notação [Inside Outside Beginning (IOB)](https://en.wikipedia.org/wiki/Inside_Outside_Beginning):\n"},{"metadata":{"_uuid":"022fe8fc088cba5776f45a7b95416cd0cf8a2ace"},"cell_type":"markdown","source":"Primeiro importamos as bibliotecas que vamos usar e os dados de um arquivo no formato [pickle](https://docs.python.org/3/library/pickle.html)."},{"metadata":{"trusted":true,"_uuid":"3ed910961744d818b06b6e17ac0d9bee2508212d"},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport pickle\nimport numpy as np\nimport progressbar\n\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom keras.models import Sequential\nfrom keras.layers.embeddings import Embedding\nfrom keras.layers.recurrent import SimpleRNN, GRU, LSTM\nfrom keras.layers.core import Dense, Dropout\nfrom keras.layers.wrappers import TimeDistributed\nfrom keras.layers import Convolution1D, MaxPooling1D\nfrom keras import optimizers\nfrom keras.regularizers import l1_l2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfb5f271d6062262b64315eb9f554160e09229cb"},"cell_type":"markdown","source":"### Carregando e analisando os dados"},{"metadata":{"trusted":true,"_uuid":"c142846c1ba1d57a45c19cacd3a607f06f13cc90"},"cell_type":"code","source":"with open('../input/atis.pkl/atis.pkl', 'rb') as f:\n    train_set, valid_set, test_set, dicts = pickle.load(f, encoding='latin1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"991af6166a5a36552c58b7526c8aed74beb54906"},"cell_type":"code","source":"train_x, train_ne, train_label = train_set\nval_x, val_ne, val_label = valid_set\ntest_x, test_ne, test_label = test_set","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"49493405081b833705bc56b8a907d51eb8ab591d"},"cell_type":"markdown","source":"A variável dicts guarda os dicionários de palavras para índices. Aqui criamos os índices inversos (números para palavras)."},{"metadata":{"trusted":true,"_uuid":"1e7409345ad5e889d57c2e1387223ebb2e8606b1"},"cell_type":"code","source":"w2idx, ne2idx, labels2idx = dicts['words2idx'], dicts['tables2idx'], dicts['labels2idx']\n\n# Create index to word/label dicts\nidx2w  = {w2idx[k]:k for k in w2idx}\nidx2ne = {ne2idx[k]:k for k in ne2idx}\nidx2la = {labels2idx[k]:k for k in labels2idx}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6281cdcfb75bf9b45d173669539b1f1b1dfd5a66"},"cell_type":"markdown","source":"Cada exemplo é um vetor com os índices das palavras no dicionário. Para obter as palavras usamos o índice inverso, como ilustrado abaixo com o exemplo 0."},{"metadata":{"trusted":true,"_uuid":"39f3e0fe31fc0a320a560e9b40254db13d118de4"},"cell_type":"code","source":"print(train_x[0])\nprint([idx2w[i] for i in train_x[0]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c368230557575357af1d015a9a48f204c91b186a"},"cell_type":"markdown","source":"Veja os labels do exemplo 0."},{"metadata":{"trusted":true,"_uuid":"ff6edc4fa6b58760a7a9a89166ea5d1f472f4540"},"cell_type":"code","source":"print([idx2la[i] for i in train_label[0]])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98ae3cf5290068a43faa22e528aac4512dea08df"},"cell_type":"markdown","source":"Aqui transformamos dados de treino e validação que guardam os índices, em listas com as palavras."},{"metadata":{"trusted":true,"_uuid":"45e5f71384678c8578fdc2f2f7df0f35b8f86a80"},"cell_type":"code","source":"words_val = [ list(map(lambda x: idx2w[x], w)) for w in val_x]\ngroundtruth_val = [ list(map(lambda x: idx2la[x], y)) for y in val_label]\nwords_train = [ list(map(lambda x: idx2w[x], w)) for w in train_x]\ngroundtruth_train = [ list(map(lambda x: idx2la[x], y)) for y in train_label]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f88188d7a81d24b3bd0a45c8df1cf136193e9a0f"},"cell_type":"markdown","source":"Note que estamos lidando com um conjunto de dados muito pequeno. São apenas 4978 exemplos para treinamento e 572 palavras distintas nas perguntas."},{"metadata":{"trusted":true,"_uuid":"7a72ad664243a0d396291a1804d57036ed058333"},"cell_type":"code","source":"n_classes = len(idx2la)\nn_vocab = len(idx2w)\nn_examples = len(words_train)\nprint('#labels: ', n_classes, '\\t#distinct words: ', n_vocab, '\\t#examples: ', n_examples)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93d56eb3331fdf68dd9a74d77d58bc52a1e605ed"},"cell_type":"markdown","source":"### Criando a RNN e realizando o treinamento e validação"},{"metadata":{"_uuid":"0f7899f7682aa597f46a00ebf18108d2d569466e"},"cell_type":"markdown","source":"Aqui está nosso código que vai criar nosso modelo de uma rede neuronal recorrente. Usaremos a classe GRU do keras, que é um tipo especial de rede recorrente."},{"metadata":{"scrolled":false,"trusted":true,"_uuid":"493c9dbac1765ba42a3dd277dc77ea48a7864a91"},"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(n_vocab,100))\n\n## Essas duas camadas são opcionais. Daremos mais detalhes nos próximos laboratórios\n#model.add(Convolution1D(64, 5, border_mode='same', activation='relu'))\n#model.add(Dropout(0.1))\n\nmodel.add(GRU(100, return_sequences=True, \n              kernel_regularizer=l1_l2(l1=0.0, l2=0.0), \n              recurrent_regularizer=l1_l2(l1=0.0, l2=0.0)\n             ))\n\nmodel.add(TimeDistributed(Dense(n_classes, activation='softmax')))\n#optm = optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n#optm = optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\noptm = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=optm)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cded1695fb178fe357d717652193de7d56a46b2"},"cell_type":"markdown","source":"No código abaixo treinamos a nossa rede recorrente. O número de épocas pode ser ajustado. A cada época é consolidado as métricas `precision`, `recall` e `f1-score`. Ver detalhes de como é feito o cálculo [aqui](https://en.wikipedia.org/wiki/F1_score). Obtendo 1 nestes scores temos um classificador perfeito."},{"metadata":{"trusted":true,"_uuid":"02a572c057d5c69a4f768182185a31b59d5839e1"},"cell_type":"code","source":"ml = MultiLabelBinarizer(classes=list(idx2la.values())).fit(idx2la.values())\n\ndef conlleval( trues, preds ):\n    trues = ml.transform(trues)\n    preds = ml.transform(preds)\n    return score(trues, preds, beta=1, average='macro' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4dba4f82ab929da8171603e296aefa1fbc7b0830","scrolled":false},"cell_type":"code","source":"# Defina aqui o número de épocas\nn_epochs = 12\n\ntrain_f_scores = []\nval_f_scores = []\nbest_val_f1 = 0\ncon_dict = {}\n\nfor i in range(n_epochs):\n    print(\"\\nEpoch {}\".format(i))\n    \n    print(\"Training =>\")\n    train_pred_label = []\n    avgLoss = 0\n    \n    bar = progressbar.ProgressBar(max_value=len(train_x))\n    for n_batch, sent in bar(enumerate(train_x)):\n        label = train_label[n_batch]\n        label = np.eye(n_classes)[label][np.newaxis,:]\n        sent = sent[np.newaxis,:]\n        \n        if sent.shape[1] > 1: #some bug in keras\n            loss = model.train_on_batch(sent, label)\n            avgLoss += loss\n\n        pred = model.predict_on_batch(sent)\n        pred = np.argmax(pred,-1)[0]\n        train_pred_label.append(pred)\n\n    avgLoss = avgLoss/n_batch\n    \n    predword_train = [ list(map(lambda x: idx2la[x], y)) for y in train_pred_label]\n    con_dict['p'], con_dict['r'], con_dict['f1'], _ = conlleval(groundtruth_train, predword_train)\n    train_f_scores.append(con_dict['f1'])\n    \n    print('Loss = {}, Precision = {}, Recall = {}, F1 = {}'.format(avgLoss, con_dict['p'], con_dict['r'], con_dict['f1']))\n    \n    print(\"\\n\\nValidating =>\")\n    \n    val_pred_label = []\n    avgLoss = 0\n    \n    bar = progressbar.ProgressBar(max_value=len(val_x))\n    for n_batch, sent in bar(enumerate(val_x)):\n        label = val_label[n_batch]\n        label = np.eye(n_classes)[label][np.newaxis,:]\n        sent = sent[np.newaxis,:]\n        \n        if sent.shape[1] > 1: #some bug in keras\n            loss = model.test_on_batch(sent, label)\n            avgLoss += loss\n\n        pred = model.predict_on_batch(sent)\n        pred = np.argmax(pred,-1)[0]\n        val_pred_label.append(pred)\n\n    avgLoss = avgLoss/n_batch\n    \n    predword_val = [ list(map(lambda x: idx2la[x], y)) for y in val_pred_label]\n    con_dict['p'], con_dict['r'], con_dict['f1'], _ = conlleval(groundtruth_val, predword_val)\n    val_f_scores.append(con_dict['f1'])\n    \n    print('Loss = {}, Precision = {}, Recall = {}, F1 = {}'.format(avgLoss, con_dict['p'], con_dict['r'], con_dict['f1']))\n\n    if con_dict['f1'] > best_val_f1:\n        best_val_f1 = con_dict['f1']\n        open('model_architecture.json','w').write(model.to_json())\n        model.save_weights('best_model_weights.h5',overwrite=True)\n        print(\"Best validation F1 score = {}\".format(best_val_f1))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8f8ba24cdb313fafbe77fae54bf17e00a49b1998"},"cell_type":"code","source":"print(\"Best epoch to stop = {}\".format(val_f_scores.index(max(val_f_scores))))\nprint(\"Best validation F1 score = {}\".format(best_val_f1))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"511f75588e38d7b416ca64635156618878272829"},"cell_type":"markdown","source":"Aqui escolhemos um exemplo aleatório dos dados de validação para comparar os labels reais x previstos"},{"metadata":{"trusted":true,"_uuid":"ff078e63370806878b0f4b05fff5e93c5ba87974"},"cell_type":"code","source":"idx = np.random.randint(len(words_val))\npreds = [idx2la[i[0]] for i in np.argmax(model.predict(val_x[idx]), -1)]\nfor k in zip(words_val[idx],groundtruth_val[idx], preds):\n    print('Word: %s\\t\\tLabel: %s\\t\\tPred: %s' % k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0505bb711013ca4327f63320d41f9903b1cab5e0"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}