{"cells":[{"metadata":{"_uuid":"e0db02d257c6bb6631773d9bcd03ff022e25649a"},"cell_type":"markdown","source":"<img src=\"http://s5047.pcdn.co/wp-content/uploads/2015/04/iris_petal_sepal.png\">\n"},{"metadata":{"_uuid":"283e08476dae18925992a6168f868693e81dcd2a"},"cell_type":"markdown","source":"<a href='#'>Preface</a><br>\n<a href='#desc'>description</a><br>\n<a href='#about'>About notebook</a><br>\n<a href='#load_lib'>Load libraries</a><br>\n<a href='#load_data'>Load Dataset</a><br>\n<a href='#visual'>Let's Visualize the dataset</a><br>\n- <a href='#types_species'> Types of species</a>\n- <a href='#corelation'>Corelation between features</a><br>\n- <a href='#visual_sepal'>Visualizing species based on sepal length and width</a><br>\n- <a href='#visual_petal'>Visualizing species based on petal length and width</a><br>\n- <a href='#value_petal_width'>Values distribution based on petal width</a><br>\n- <a href='#value_petal_length'>Values distribution based on petal length</a><br>\n- <a href='#value_sepal_length'>Values distribution based on sepal length</a><br>\n- <a href='#value_sepal_width'>Values distribution based on sepal width</a><br>\n- <a href='#andrew'>Andrew curves</a><br>\n- <a href='#lin_sepal'>Linear regression based on sepal</a><br>\n- <a href='#lin_petal'>Linear regression based on petal</a><br>\n\n<a href='#ml'>Machine Learning</a><br>\n- <a href='#list'> List of algorithms</a>\n- <a href='#logistic'>Logistic regression</a><br>\n- <a href='#decision'>Decision tree</a><br>\n- <a href='#knn'>KNN</a><br>\n- <a href='#svm'>SVM</a><br>\n- <a href='#nbc'>Naive Bayes Classification</a><br>\n- <a href='#random'>Random forest</a><br>\n- <a href='#etc'>Extra Tree Classifier</a><br>\n- <a href='#xgboost'>XGBoost</a><br>\n- <a href='#lbgm'>LigthGBM</a><br>\n\n<a href='#dl'>Deep Learning</a><br>\n- <a href='#shallow'>Shallow Deep learning</a><br>\n- <a href='#deep'>Deep Deep learning</a><br>\n"},{"metadata":{"_uuid":"b76ae77466be5ddfeb2ad8510c7c0c341ce863c4"},"cell_type":"markdown","source":"# <a id='desc'> Description</a>\n"},{"metadata":{"_uuid":"3c23607dc3ccb91848089096ccfd7620666903ae"},"cell_type":"markdown","source":"The Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n\nIt includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n\nThe columns in this dataset are:\n\n- Id\n- SepalLengthCm\n- SepalWidthCm\n- PetalLengthCm\n- PetalWidthCm\n- Species"},{"metadata":{"_uuid":"c48025029289ae1508f0757431ded97fa406da1a"},"cell_type":"markdown","source":"# <a id='about'>About the notebook</a>\n"},{"metadata":{"_uuid":"5ad3d0ac84f2ef712c4a77d0e8e83db59f1bb434"},"cell_type":"markdown","source":"In this notebook we will look into famous dataset which is iris, we will analyse the dataset with plotly library which is very interactive library in python then later we will apply different macine learning algorithms and see the best accuracy.\n\n"},{"metadata":{"_uuid":"b4d6c82733d12e223387758889036b50c68884dd"},"cell_type":"markdown","source":"# <a id='load_lib'>Let's load the required libraries</a>\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ab3c2f7c07531992dd024b7d1df6997ba1a251b3"},"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nfrom pandas.tools import plotting\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport plotly.offline as py\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected=True)  \nimport plotly.figure_factory as ff\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import  accuracy_score\n\nimport xgboost as xgb\nimport lightgbm as  lgb\nfrom xgboost.sklearn import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\n# auxiliary function\nfrom sklearn.preprocessing import LabelEncoder\ndef random_colors(number_of_colors):\n    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n                 for i in range(number_of_colors)]\n    return color\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc720b9cb2ab8ee436074089b4d6d74fc5b8f882"},"cell_type":"markdown","source":"# <a id='load_data'>Load data set</a>\n\n"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"0caff7f827cd7a8a0352992e2a80d42fdb8d26dc"},"cell_type":"code","source":"df = pd.read_csv('../input/Iris.csv')\ntable = ff.create_table(df.head())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"3f04383afd4c6edfdd1a395d6425f5278a8bc778"},"cell_type":"code","source":"py.iplot(table,filename='jupyter-table1')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"60779db42446412a6b94d353e9173285351042e2"},"cell_type":"code","source":"py.iplot(ff.create_table(df.describe()),filename='jupyter-table1')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1179c41df2d7a6e61012afbeab13b4cb97003724"},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d94cacaeb20745de52b44cecadb9f124bba6ede0"},"cell_type":"markdown","source":"so there is no null values available in the data set"},{"metadata":{"_uuid":"00fb91122216780bf8fbd66c2a13cee1eddfade0"},"cell_type":"markdown","source":"# <a id='visual'>Now lets start visualizing the data set</a>"},{"metadata":{"_uuid":"3771de617effaadbf899a4bcbf7db24ec45e9402"},"cell_type":"markdown","source":"given the coloums are<br>\nSepalLengthCm<br>\nSepalWidthCm<br>\nPetalLengthCm<br>\nPetalWidthCm<br>\nSpecies<br>"},{"metadata":{"_uuid":"4c54df7ef24e7d9e75fb6f2e6b137ef086a06319"},"cell_type":"markdown","source":"# <a id='types_species'> Types of Species</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"ceea7a2606503e6afa020ec014be2efd989fd9d4"},"cell_type":"code","source":"Species = df['Species'].unique()\nSpecies","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3deeea05193d2bff16945fa5eee75f57144ecf06"},"cell_type":"markdown","source":"So there are three types of species \n\nIris-setosa<br/>\nIris-versicolor<br/>\nIris-virginica<br/>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"c0cc233be99d92c867be5b0e4ad77252b092418c"},"cell_type":"code","source":"species_count = df['Species'].value_counts()\ndata = [go.Bar(\n    x = species_count.index,\n    y = species_count.values,\n    marker = dict(color = random_colors(3))\n)]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d23bea755d9d9dcafb8038277c26b386fceaafa4"},"cell_type":"markdown","source":"So we have equally distributed species all are of 50"},{"metadata":{"_uuid":"7e7c935c6749f76b8bb619b1a629861660d5878d"},"cell_type":"markdown","source":"# <a id='corelation'>Corelation between features</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"47326e3e9bc656c6dbf3abffaddd8464180ba585"},"cell_type":"code","source":"corelation = df.corr()\ndata = [go.Heatmap(z = np.array(corelation.values),\n                   x = np.array(corelation.columns),\n                   y = np.array(corelation.columns),\n                     colorscale='Blackbody',)\n       ]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b56bbb038bd566ac3814c6229195ee98ead714d"},"cell_type":"markdown","source":"# <a id='visual_sepal'>Visualizing species based on Sepal length and width</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2ef0b1dfaae5c114d43e6ae957aab61e28f178b3"},"cell_type":"code","source":"setosa = go.Scatter(x = df['SepalLengthCm'][df.Species =='Iris-setosa'], y = df['SepalWidthCm'][df.Species =='Iris-setosa']\n                   , mode = 'markers', name = 'setosa')\nversicolor = go.Scatter(x = df['SepalLengthCm'][df.Species =='Iris-versicolor'], y = df['SepalWidthCm'][df.Species =='Iris-versicolor']\n                   , mode = 'markers', name = 'versicolor')\nvirginica = go.Scatter(x = df['SepalLengthCm'][df.Species =='Iris-virginica'], y = df['SepalWidthCm'][df.Species =='Iris-virginica']\n                   , mode = 'markers', name = 'virginica')\ndata = [setosa, versicolor, virginica]\nfig = dict(data=data)\npy.iplot(fig, filename='styled-scatter')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40067201ffdfbdf8c61c2c4b9ec7fda510430eaa"},"cell_type":"markdown","source":"We can easily differentiate setosa based on Sepal but for versicolor and virginica its difficult because the data is scattred."},{"metadata":{"_uuid":"57ee9c60cac06b153615b63a0e42bebf3afd9e6a"},"cell_type":"markdown","source":"#  <a id='visual_petal'>Visualizing species based on petal length and width</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cfe04b72e851722e20c282f0434c1da2c33715f9"},"cell_type":"code","source":"setosa = go.Scatter(x = df['PetalLengthCm'][df.Species =='Iris-setosa'], y = df['PetalWidthCm'][df.Species =='Iris-setosa']\n                   , mode = 'markers', name = 'setosa')\nversicolor = go.Scatter(x = df['PetalLengthCm'][df.Species =='Iris-versicolor'], y = df['PetalWidthCm'][df.Species =='Iris-versicolor']\n                   , mode = 'markers', name = 'versicolor')\nvirginica = go.Scatter(x = df['PetalLengthCm'][df.Species =='Iris-virginica'], y = df['PetalWidthCm'][df.Species =='Iris-virginica']\n                   , mode = 'markers', name = 'virginica')\ndata = [setosa, versicolor, virginica]\nfig = dict(data=data)\npy.iplot(fig, filename='styled-scatter')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cf26e01889e05607ff263ef64047020bcf10441"},"cell_type":"markdown","source":"Again based on petal we can easily classify setosa and for versicolor and virginica also we can classify but there is a thin line which should be taken care of"},{"metadata":{"_uuid":"a1b7b9f53e9ef05304b3bc39977bc786fa461fc0"},"cell_type":"markdown","source":"# <a id='value_petal_width'>Values distribution based on petal width</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"071848513d26db0df5a8e537bbbe18734db7f9db"},"cell_type":"code","source":"trace0 = go.Box(y=df['PetalWidthCm'][df['Species'] == 'Iris-setosa'],boxmean=True, name = 'setosa')\n\ntrace1 = go.Box(y=df['PetalWidthCm'][df['Species'] == 'Iris-versicolor'],boxmean=True, name = 'versicolor')\n\ntrace2 = go.Box(y=df['PetalWidthCm'][df['Species'] == 'Iris-virginica'],boxmean=True, name = 'virginica')\n\ndata = [trace0, trace1, trace2]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"701b1b342063c036cc90434c31816a97d0cd9576"},"cell_type":"markdown","source":"# <a id='value_petal_length'>Values distribution based on petal length</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"86a5654cad855f20849d36bf03aa3bd96902ec95"},"cell_type":"code","source":"trace0 = go.Box(y=df['PetalLengthCm'][df['Species'] == 'Iris-setosa'],name = 'setosa')\n\ntrace1 = go.Box(y=df['PetalLengthCm'][df['Species'] == 'Iris-versicolor'], name = 'versicolor')\n\ntrace2 = go.Box(y=df['PetalLengthCm'][df['Species'] == 'Iris-virginica'], name = 'virginica')\n\ndata = [trace0, trace1, trace2]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eeced3bb248a78ebbae2f14e14c606e21f66fa1f"},"cell_type":"markdown","source":"# <a id='value_sepal_length'>Values distribution based on sepal length</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"bf133320780ea073a2d563d34ae134cc846c87f3"},"cell_type":"code","source":"trace0 = go.Box(y=df['SepalLengthCm'][df['Species'] == 'Iris-setosa'], name = 'setosa')\n\ntrace1 = go.Box(y=df['SepalLengthCm'][df['Species'] == 'Iris-versicolor'], name = 'versicolor')\n\ntrace2 = go.Box(y=df['SepalLengthCm'][df['Species'] == 'Iris-virginica'], name = 'virginica')\n\ndata = [trace0, trace1, trace2]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95a6803effd816173cca2541d484006cfb265d93"},"cell_type":"markdown","source":"# <a id='value_sepal_width'>Values distribution based on sepal width</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"79dc6ea6222ce9657a44cb79400a5c1689a775be"},"cell_type":"code","source":"setosa = go.Box(y=df['SepalWidthCm'][df['Species'] == 'Iris-setosa'])\n\nversicolor = go.Box(y=df['SepalWidthCm'][df['Species'] == 'Iris-versicolor'])\n\nvirginica = go.Box(y=df['SepalWidthCm'][df['Species'] == 'Iris-virginica'])\n\ndata = [trace0, trace1, trace2]\npy.iplot(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b45612410841c2119cf11e1337f0e089946b5357"},"cell_type":"markdown","source":"- From the above four graph you can see that the distribution of setosa < vericolor < virginica\n- There are few outliers which can be explained by the scatter plot graph."},{"metadata":{"_uuid":"4b410ac18f7e4542d395224b11b85899c8d33d8e"},"cell_type":"markdown","source":"# <a id='andrew'>Andrew curves</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"1e8b8291b2ce40d551e3d735f44bcb148ddf21bc"},"cell_type":"code","source":"plt.subplots(figsize = (10,8))\n\nplotting.andrews_curves(df.drop(\"Id\", axis=1), \"Species\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"63b9baaba108899a03d086f070cffcb686ab46f3"},"cell_type":"markdown","source":"Andrews curves are a method for visualizing multidimensional data by mapping each observation onto a function.\n\nSource - https://dzone.com/articles/andrews-curves"},{"metadata":{"_uuid":"6dd6113a725c65cd882b9694c928ae50cf2108c8"},"cell_type":"markdown","source":"Lets create a regression plot for both petal and sepal"},{"metadata":{"_uuid":"c82b8e53167921c3fe707b3a04cdc1c157302910"},"cell_type":"markdown","source":"# <a id='lin_sepal'>Linear regression based on sepal</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"59cccdfa7d2cfc6454e7ec289662121f1ae45af2"},"cell_type":"code","source":"g = sns.lmplot(x=\"SepalWidthCm\", y=\"SepalLengthCm\", hue=\"Species\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"98e6c59ba5e18909aa2012a3e5360e2b51e517dd"},"cell_type":"markdown","source":"# <a id='lin_petal'>Linear regression based on petal</a><br>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"90c3f7b518b9ee89dc7a407232c32b3c394b78f7"},"cell_type":"code","source":"g = sns.lmplot(x=\"PetalWidthCm\", y=\"PetalLengthCm\", hue=\"Species\", data=df)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"990cd600747e780a0a5941564fc87ec1b2cf5d38"},"cell_type":"markdown","source":"We have seen the visualization part\n<br>\nNow lets see the how to apply machine learning to the dataset"},{"metadata":{"_uuid":"3bb8608826995545cf9cbaba625a6a877afb13a0"},"cell_type":"markdown","source":"# <a id='ml'>What is machine learning ?</a><br> "},{"metadata":{"trusted":true,"_uuid":"3070eda42cec146241b3b53952d14d0034e56ced"},"cell_type":"markdown","source":"The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers learn automatically without human intervention or assistance and adjust actions accordingly.\n\nPlease go through the blog for in-depth description of machine learning\nhttps://www.expertsystem.com/machine-learning-definition/"},{"metadata":{"trusted":true,"_uuid":"c570c2cf8c63a01260ac932868a3bd2244d501cf"},"cell_type":"markdown","source":"So by the defination we see that we need data and we do have the data (Iris dataset).\nBut how will we test the dataset ?"},{"metadata":{"trusted":true,"_uuid":"64480dd6003d8bcd4faaffd09fc9a40efe87fa85"},"cell_type":"markdown","source":"For that we will split out data set into three parts train, test, validation sets.<br>\nwe are going to use the scikit-learn library which has all the required functions and machine learning algorithms required for this notebook"},{"metadata":{"_uuid":"9a5b85ab1fb12172635c7215b4da2aef6f2f5778"},"cell_type":"markdown","source":"Before we split our data lets look at the output we want to predict.<br> \nWe want to predict the given sepal and petal dimensions follows to which type of species.<br>\nwe have 3 type of species  Iris-setosa Iris-versicolor Iris-virginica.<br>\nWe will convert those species names to a categorical values using label encoding.<br>"},{"metadata":{"trusted":true,"_uuid":"174f80946174bd6bc0ba64bfebf6a5c8fac36db8"},"cell_type":"code","source":"x = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ny = df['Species']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6150c9fdda1b523ba908271960aa4f6508bffe6d"},"cell_type":"code","source":"encoder = LabelEncoder()\ny = encoder.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c130a4ad47d1336614303a58d21b3a498b203e2"},"cell_type":"code","source":"y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1133179fff6a668edc493033557b4ab0dbbc65a"},"cell_type":"markdown","source":"As you can see Iris-setosa Iris-versicolor Iris-virginica are converted to 0, 1, 2 respectively"},{"metadata":{"trusted":true,"_uuid":"2154389e9a256b2e5b8e77280cfa13542fa15541"},"cell_type":"markdown","source":"First we are splitting the data set into training data and testing data which is 7:3 ratio "},{"metadata":{"trusted":true,"_uuid":"e95d548a7f9a3fbef363cf50060375e3bd4b2def"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a429c38170278cbc2b6220b9e7b2cdcf97104c75"},"cell_type":"markdown","source":"# <a id='list'> List of algorithms</a>"},{"metadata":{"trusted":true,"_uuid":"a37b694d493d259be10a23e1123f2dd0a349e12f"},"cell_type":"markdown","source":"Since it is a classification problem we will be using<br>\nLogistic regression<br>\nDecision tree<br>\nKNN<br>\nSVM<br>\nNaive Bayes Classification<br>\nRandom forest<br>\nXGBoost<br>\nLightGBM<br>"},{"metadata":{"trusted":true,"_uuid":"b222fe6d3fc4d877e3d428d6a2ff8a5d29b2c528"},"cell_type":"markdown","source":"# <a id='logistic'>Logistic regression</a><br>"},{"metadata":{"_uuid":"be3e8af2de05f1a79e33812a6e835073ea5068cb"},"cell_type":"markdown","source":"<img src = \"https://image.slidesharecdn.com/logitregression-161121215510/95/intro-to-logistic-regression-4-638.jpg?cb=1479765630\">"},{"metadata":{"_uuid":"e36981fb2be6be8f58fdf81e5e41bacd9f429ed4"},"cell_type":"markdown","source":"**Logistic regression** is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes).\n(https://www.medcalc.org/manual/logistic_regression.php)"},{"metadata":{"trusted":true,"_uuid":"ce27be1c4fe5918c150798b398d3004969b5ba0f"},"cell_type":"code","source":"lr_model = LogisticRegression()\nlr_model.fit(x_train,y_train)\nlr_predict = lr_model.predict(x_test)\nprint('Logistic Regression - ',accuracy_score(lr_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"67fc07be60779c31c2ada8c725289d8ef943c1bd"},"cell_type":"markdown","source":"# <a id='svm'>SVM</a><br>"},{"metadata":{"_uuid":"94f1dded6dca929473527ed7c42697021ace1e6c"},"cell_type":"markdown","source":"<img src = \"https://cdn-images-1.medium.com/max/1600/1*TudH6YvvH7-h5ZyF2dJV2w.jpeg\">"},{"metadata":{"_uuid":"0aac492ad1b1be323d503bc1a149364ae24d51af"},"cell_type":"markdown","source":"**“Support Vector Machine” (SVM)** is a supervised machine learning algorithm which can be used for both classification or regression challenges. However,  it is mostly used in classification problems. In this algorithm, we plot each data item as a point in n-dimensional space (where n is number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiate the two classes very well.\n\nSupport Vectors are simply the co-ordinates of individual observation. Support Vector Machine is a frontier which best segregates the two classes (hyper-plane/ line).\n(https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)\n"},{"metadata":{"trusted":true,"_uuid":"9c86b283ce845304587a40a9e92e22130b43caee"},"cell_type":"code","source":"svm_model = SVC(kernel='linear')\nsvm_model.fit(x_train,y_train)\nsvc_predict = svm_model.predict(x_test)\nprint('SVM - ',accuracy_score(svc_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e7abe757465fb5904e59acf6d5c49f37ff0e740"},"cell_type":"markdown","source":"# <a id='nbc'>Naive Bayes Classification</a><br>"},{"metadata":{"_uuid":"502b809d07b32bf45dc6d147f479a305bfde5c79"},"cell_type":"markdown","source":"<img src = \"https://helloacm.com/wp-content/uploads/2016/03/Bayes_rule.png\">"},{"metadata":{"_uuid":"de46c12ea0ca21f4167706d660c0819e844e4dce"},"cell_type":"markdown","source":"**Naive Bayes** is a simple, yet effective and commonly-used, machine learning classifier. It is a probabilistic classifier that makes classifications using the Maximum A Posteriori decision rule in a Bayesian setting. It can also be represented using a very simple Bayesian network. Naive Bayes classifiers have been especially popular for text classification, and are a traditional solution for problems such as spam detection.\n(https://towardsdatascience.com/introduction-to-naive-bayes-classification-4cffabb1ae54)"},{"metadata":{"trusted":true,"_uuid":"ad312dc9438ae6a0afde56012bf3e101064373fe"},"cell_type":"code","source":"nb_model = GaussianNB()\nnb_model.fit(x_train,y_train)\nnb_predict = nb_model.predict(x_test)\nprint('Naive bayes - ',accuracy_score(nb_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4dda5f1d31e579cf25e2c18175cae01704053e76"},"cell_type":"markdown","source":"# <a id='decision'>Decision tree</a><br>"},{"metadata":{"_uuid":"117b1972679f8ef22c76fd29ea385fd124a7eaaf"},"cell_type":"markdown","source":"<img src = \"https://annalyzin.files.wordpress.com/2016/07/decision-trees-titanic-tutorial.png\">"},{"metadata":{"_uuid":"5a102d4fbf83103ac455022c4f25809fad4e1fd6"},"cell_type":"markdown","source":"**Decision tree** is a type of supervised learning algorithm (having a pre-defined target variable) that is mostly used in classification problems. It works for both categorical and continuous input and output variables. In this technique, we split the population or sample into two or more homogeneous sets (or sub-populations) based on most significant splitter / differentiator in input variables.\n(https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/)"},{"metadata":{"trusted":true,"_uuid":"567f22ed14b3fb568c4a85af9b306214108de7f4"},"cell_type":"code","source":"dt_model = DecisionTreeClassifier(max_leaf_nodes=3)\ndt_model.fit(x_train,y_train)\ndt_predict = dt_model.predict(x_test)\nprint('Decision Tree - ',accuracy_score(dt_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42d55936cf6cbaa54948a268c9e243c733ce39cd"},"cell_type":"markdown","source":"# <a id='random'>Random forest</a><br>"},{"metadata":{"_uuid":"0a1de00cf9ef4c1ca8268f28ba2920ea9ca4a79c"},"cell_type":"markdown","source":"<img src=\"https://i1.wp.com/dataaspirant.com/wp-content/uploads/2017/04/Random-Forest-Introduction.jpg?resize=690%2C345\">"},{"metadata":{"_uuid":"c54dead6420adaa799cb24c8dbee75b6b39c005f"},"cell_type":"markdown","source":"**Random Forest** is considered to be a panacea of all data science problems. On a funny note, when you can’t think of any algorithm (irrespective of situation), use random forest!\n\nRandom Forest is a versatile machine learning method capable of performing both regression and classification tasks. It also undertakes dimensional reduction methods, treats missing values, outlier values and other essential steps of data exploration, and does a fairly good job. It is a type of ensemble learning method, where a group of weak models combine to form a powerful model.\n\n(https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/#nine)"},{"metadata":{"trusted":true,"_uuid":"4aeb3ce119c947d44b85dd398afaeb21504a2221"},"cell_type":"code","source":"rfc_model = RandomForestClassifier(max_depth=3)\nrfc_model.fit(x_train,y_train)\nrfc_predict = rfc_model.predict(x_test)\nprint('Random Forest - ',accuracy_score(rfc_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46dc2d7de36b297dad987cdc98bb9cf41c29efd7"},"cell_type":"markdown","source":"# <a href='etc'>Extra Tree Classifier</a><br>"},{"metadata":{"_uuid":"14e5546a2a0e8eafecb2f4a59faae12b0a330f0a"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"8991cdf3a0054cd64281b2c6cd260726440dc733"},"cell_type":"markdown","source":"\n(https://machinelearningmastery.com/ensemble-machine-learning-algorithms-python-scikit-learn/)"},{"metadata":{"trusted":true,"_uuid":"fc1c65b5b7b1eabbb09db35cec298b29ae00ec51"},"cell_type":"code","source":"etc_model = ExtraTreesClassifier()\netc_model.fit(x_train,y_train)\netc_predict = etc_model.predict(x_test)\nprint('Extra Tree Classifier - ',accuracy_score(etc_predict,y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f575634697a8321b9fbc53a69025b8d21baa3a1c"},"cell_type":"markdown","source":"# <a id='knn'>KNN</a><br>"},{"metadata":{"_uuid":"f3602f23df5dbe07978ca00e5d97b3a15a470f24"},"cell_type":"markdown","source":"<img src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1531424125/Knn_k1_z96jba.png\">"},{"metadata":{"_uuid":"6a6e8e7a68403099e698efed00d0eb0a3ba93281"},"cell_type":"markdown","source":"**K nearest neighbors** is a simple algorithm that stores all available cases and classifies new cases based on a similarity measure (e.g., distance functions). KNN has been used in statistical estimation and pattern recognition already in the beginning of 1970's as a non-parametric technique.\n(https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)"},{"metadata":{"trusted":true,"_uuid":"94a5fe5f4c50210bbc141d75cba423f0dde1b3b2"},"cell_type":"code","source":"knn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train,y_train)\nknn_predict = knn_model.predict(x_test)\nprint('knn - ',accuracy_score(knn_predict,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd3fc2bfba1626652c5a1b879345d3e8e3d95595"},"cell_type":"markdown","source":"# <a id='xgboost'>XGBoost</a><br>"},{"metadata":{"_uuid":"1d35d1a725ec33c906d32ebd6c01e9cb5b1cf36f"},"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/e7MIgXk.png\">"},{"metadata":{"_uuid":"7fff57c6d99ab43155ffddcc4c73884cee7e9b99"},"cell_type":"markdown","source":"The beauty of this powerful algorithm lies in its scalability, which drives fast learning through parallel and distributed computing and offers efficient memory usage.\n\nIt’s no wonder then that CERN recognized it as the best approach to classify signals from the Large Hadron Collider. This particular challenge posed by CERN required a solution that would be scalable to process data being generated at the rate of 3 petabytes per year and effectively distinguish an extremely rare signal from background noises in a complex physical process. XGBoost emerged as the most useful, straightforward and robust solution.\n\n(https://www.analyticsvidhya.com/blog/2018/09/an-end-to-end-guide-to-understand-the-math-behind-xgboost/)"},{"metadata":{"trusted":true,"_uuid":"b4f09827b3f335da235608b2ede27e60df6ce161"},"cell_type":"code","source":"xg_model = xgb.XGBClassifier()\nxg_model = xg_model.fit(x_train,y_train)\nxg_model.score(x_test, y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4705805636047c4ce43898c0c36259407f543a0d"},"cell_type":"markdown","source":"# <a id='dl'>Deep Learning</a><br>"},{"metadata":{"_uuid":"68b1d94d10fe279961e28e6bba90f27baeceebe2"},"cell_type":"markdown","source":"Best place to understand deep learning.\nPlease follow the blog\n\nhttps://machinelearningmastery.com/what-is-deep-learning/"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"2bc41a138e69a3d02acdfa46cd47ad2b4fcfa74e"},"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"93256144af33cc23c71dd8336f5622b2aab2ef90"},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, LabelBinarizer\nX = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\ny = df['Species']\n\nX = StandardScaler().fit_transform(X)\ny = LabelBinarizer().fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9df7b248a5352b8e2d0e1d9d3ed68d9a253c02e2"},"cell_type":"markdown","source":"Spliting the data into train - 70% and test - 30%"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"8984cfef81f4e31db498376f5ca2bf72748faf13"},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"313afe4a5c4b5ac84f1360a0196364d266878ea9"},"cell_type":"markdown","source":"# <a id='shallow'>Shallow Deep learning</a>"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"08365090312fac823129d5026f027617f6b9a2f3"},"cell_type":"code","source":"shallow_model = Sequential()\nshallow_model.add(Dense( 4, input_dim=4, activation = 'relu'))\nshallow_model.add(Dense( units = 10, activation= 'relu'))\nshallow_model.add(Dense( units = 3, activation= 'softmax'))\nshallow_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf863925465f3d79fd04102b8870825f7ccb75a4","scrolled":true},"cell_type":"code","source":"shallow_history = shallow_model.fit(x_train, y_train, epochs = 150, validation_data = (x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3061f0e804a4fb326d25d690f2a9aec31f8c6b2"},"cell_type":"code","source":"plt.plot(shallow_history.history['acc'])\nplt.plot(shallow_history.history['val_acc'])\nplt.title(\"Accuracy\")\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"605132bcfb1d9aa3b59bc58c0822e3c97ae72a8a"},"cell_type":"code","source":"plt.plot(shallow_history.history['loss'])\nplt.plot(shallow_history.history['val_loss'])\nplt.plot('Loss')\nplt.legend(['Train','Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5b2d0d6aa208d3a6f77e2d2ab58139dbfa58f491"},"cell_type":"markdown","source":"So our shallow model is  good accurate."},{"metadata":{"_uuid":"64eecf88ba78f8616345496654ab70a04019f698"},"cell_type":"markdown","source":"# <a id='deep'>Deep Deep learning</a>"},{"metadata":{"trusted":true,"_uuid":"77cded2a0a730f5a6c3717a10449c890e4195f73"},"cell_type":"code","source":"deep_model = Sequential()\ndeep_model.add(Dense( 4, input_dim=4, activation = 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 10, activation= 'relu'))\ndeep_model.add(Dense( units = 3, activation= 'softmax'))\ndeep_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4be5a0688349325ac9f08365c28265571770dfe0"},"cell_type":"code","source":"deep_history = deep_model.fit(x_train, y_train, epochs = 150, validation_data = (x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"700989a441f89101245ae099ebe528fe3f633431"},"cell_type":"code","source":"plt.plot(deep_history.history['acc'])\nplt.plot(deep_history.history['val_acc'])\nplt.title(\"Accuracy\")\nplt.legend(['train', 'test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e11dd866567ce68bd5b4050d06793d33ae78a622"},"cell_type":"code","source":"plt.plot(deep_history.history['loss'])\nplt.plot(deep_history.history['val_loss'])\nplt.plot('Loss')\nplt.legend(['Train','Test'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7bc4c3d21891be9ebed38cdd359b1963cf6d5aa"},"cell_type":"markdown","source":"So our deep model is more accurate than the shallow model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"25901502724492603e74ca6d306528df43fcdbf9"},"cell_type":"markdown","source":"# Stay tune as the algorithms are learning. Hold tight \n\n# Upvote if you like "},{"metadata":{"trusted":true,"_uuid":"c31866c872647caccbc1557a0e1ef39688c38cf6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}