---
title: 'Titanic Analysis with SVM+KNN+RF+Decison Tree'
author: 'Swamy S M'
date: '10th Sep 2017'
output:
  html_document:
    number_sections: true
    toc: true
    fig_width: 7
    fig_height: 4.5
    theme: readable
    highlight: tango
---

# Introduction

This is my first ever Kernel in a Kaggle Competion.  After reading and browning some of the books and goggling machine learning materials 
I have chosen to work with the Titanic dataset... 
I am new enthusiast for machine learning and data science. All your feedback and suggestion is much appreciated 


 Titanic is definitely good kick up for any Machine Learning enthusiast working few feature and minimum data.
More than that who don't know Titanic Tragedy, Jack and Rose Love story.
Titanic is tragedy story of a ship Sunk in the first Journey itself. 
This is the best example of what is going to happen if the nature gives just an hour to Human being before his death and survival,

1) Wheather he try to save himself first or the family or children?
2) Priority goes to rich folks or poor, who among poor folks survive first?
3) Smaller Family having better Survival rate than bigger?

With Above explanation Lets start the script 


#Data loading and consolidation

```{r, message = FALSE}
## Load all the library required one by one

library('ggplot2') 
library('caret') 
library('dplyr') 
library('randomForest') 
library(rpart)
library(rpart.plot)
library(car)
library(e1071)


##Lets Load raw data in the orginal form by setting stringsAsFactors = F

train.tit <- read.csv('../input/train.csv', stringsAsFactors = F)
test.tit  <- read.csv('../input/test.csv', stringsAsFactors = F)
test.tit$Survived <- NA

##Combine both test and train
full_titanic <- rbind(train.tit, test.tit)

##Check the structure
str(full_titanic)
```

#Missing value imputation

```{r, message=FALSE, warning=FALSE}

###is there any Missing obesrvation
colSums(is.na(full_titanic))

####Empty data
colSums(full_titanic=='')

##Summary shows, Age missing 263 value, Cabin too having lots of missing value..will look into them later in exploratory analysis nd Embarked missing 2

###Lets replace Embarked by blank

table(full_titanic$Embarked)
full_titanic$Embarked[full_titanic$Embarked==""]="S"
table(full_titanic$Embarked)

```


```{r, message=FALSE, warning=FALSE}
###Check the length and see how many varibles of then we can move to factor for our analysis

apply(full_titanic,2, function(x) length(unique(x)))


###will convert the below varible into factor for ananlysis

cols=c("Survived","Pclass","Sex","Embarked")
for (i in cols){
  full_titanic[,i]=as.factor(full_titanic[,i])
}
```

#Exploratory analysis or Feature engineering


##Exploratory Analysis on Pclass

```{r, message=FALSE, warning=FALSE}
## Hypothesis is that,  Rich folks survival much better than poor folks, Does any diffrence in Titanic?  

###Take a look into Visualization with P class which is the best proxy for Rich and Poor  

ggplot(full_titanic[1:891,],aes(x = Pclass,fill=factor(Survived))) +
geom_bar() +
ggtitle("Pclass v/s Survival Rate")+
xlab("Pclass") +
ylab("Total Count") +
labs(fill = "Survived")  

##No diffrences in a the Titanic too, First class Survival rate is far more better than the 3rd class  
##No doubt Rich peope have better Survival rate than the poor

# Visualize the 3-way relationship of sex, pclass, and survival
ggplot(full_titanic[1:891,], aes(x = Sex, fill = Survived)) +
geom_bar() +
facet_wrap(~Pclass) + 
ggtitle("3D View of sex, pclass, and survival") +
xlab("Sex") +
ylab("Total Count") +
labs(fill = "Survived")

##In the all the class Female Survival rate is better than Men

```

##Exploratory Analysis on Title

```{r, message=FALSE, warning=FALSE}
head(full_titanic$Name)
##Lets extract the title and check if we have predictive power in that
names <- full_titanic$Name
title <-  gsub("^.*, (.*?)\\..*$", "\\1", names)

full_titanic$title <- title

table(title)

###MISS, Mrs Master, Mr are takimg more numbers

###Better to group Other titles into bigger basket by checking gender and survival rate to aviod any overfitting


full_titanic$title[full_titanic$title == 'Mlle']        <- 'Miss' 
full_titanic$title[full_titanic$title == 'Ms']          <- 'Miss'
full_titanic$title[full_titanic$title == 'Mme']         <- 'Mrs' 
full_titanic$title[full_titanic$title == 'Lady']          <- 'Miss'
full_titanic$title[full_titanic$title == 'Dona']          <- 'Miss'

## Iam afraid creating a new varible with small data can causes a overfit
## However, My thinking is that combining below feauter into orginl variable may loss some predictive power as they are all army folks, doctor and nobel peoples 

full_titanic$title[full_titanic$title == 'Capt']        <- 'Officer' 
full_titanic$title[full_titanic$title == 'Col']        <- 'Officer' 
full_titanic$title[full_titanic$title == 'Major']   <- 'Officer'
full_titanic$title[full_titanic$title == 'Dr']   <- 'Officer'
full_titanic$title[full_titanic$title == 'Rev']   <- 'Officer'
full_titanic$title[full_titanic$title == 'Don']   <- 'Officer'
full_titanic$title[full_titanic$title == 'Sir']   <- 'Officer'
full_titanic$title[full_titanic$title == 'the Countess']   <- 'Officer'
full_titanic$title[full_titanic$title == 'Jonkheer']   <- 'Officer'


# Lets check who among Mr, Master, Miss hving a better survival rate
 ggplot(full_titanic[1:891,],aes(x = title,fill=factor(Survived))) +
  geom_bar() +
  ggtitle("Title V/S Survival rate")+
  xlab("Title") +
  ylab("Total Count") +
  labs(fill = "Survived") 

##In the titanic you are a Mr then there is less chance of survival, Miss and Mrs having beteer survival rate then Master and Officer 


### Visualize the 3-way of relationship of Title, Pclass, and Survival

ggplot(full_titanic[1:891,], aes(x = title, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass) + 
  ggtitle("3-way of relationship of Title, Pclass, and Survival") +
  xlab("Title") +
  ylab("Total Count") +
  labs(fill = "Survived")

##Master in 1st and 2nd class has 100% Survival where has Mrs and Miss having 90% chance of Survival in 1st and 2nd class 
##Note that Title is alwayes relating with Age except few cases, So I will use title in place of instted of missing vlaue age which is very critcil variable
```
##Exploratory Analysis on Family
```{r, message=FALSE, warning=FALSE}

# Lets create a Family size using Sibsp and Parch, becuase Some time if the kids are more then it would be difficult for parents to take care all   

full_titanic$FamilySize <-full_titanic$SibSp + full_titanic$Parch + 1
table(full_titanic[1:891,15])

full_titanic$FamilySized[full_titanic$FamilySize == 1]   <- 'Single'
full_titanic$FamilySized[full_titanic$FamilySize < 5 & full_titanic$FamilySize >= 2]   <- 'Small'
full_titanic$FamilySized[full_titanic$FamilySize >= 5]   <- 'Big'

full_titanic$FamilySized=as.factor(full_titanic$FamilySized)


###Lets Visualize the Survival rate by Family size 
ggplot(full_titanic[1:891,],aes(x = FamilySized,fill=factor(Survived))) +
  geom_bar() +
  ggtitle("Family Size V/S Survival Rate") +
  xlab("FamilySized") +
  ylab("Total Count") +
  labs(fill = "Survived")

###Big Family in Titnic having worst survival rate then Small and Alone

####Why Big Family has a probelm?, Check in the below visualization

ggplot(full_titanic[1:891,], aes(x = FamilySized, fill = Survived)) +
  geom_bar() +
  facet_wrap(~title) + 
  ggtitle("3D View of Fmily Size, Title and Survival rate") +
  xlab("family.size") +
  ylab("Total Count") +
  ylim(0,300) +
  labs(fill = "Survived")

####You are a Master and Mr in the Big Family then your Survival rate is absolutely nill 
  
###I am very surprised to see Single coming out to be bulk, however 
##there is chance that, they could come with friends or survents
##I though to get extract those number using same ticket number distributed


# Engineer features based on all the passengers with the same ticket
ticket.unique <- rep(0, nrow(full_titanic))
tickets <- unique(full_titanic$Ticket)

for (i in 1:length(tickets)) {
  current.ticket <- tickets[i]
  party.indexes <- which(full_titanic$Ticket == current.ticket)
  
  
  for (k in 1:length(party.indexes)) {
    ticket.unique[party.indexes[k]] <- length(party.indexes)
  }
}

full_titanic$ticket.unique <- ticket.unique


full_titanic$ticket.size[full_titanic$ticket.unique == 1]   <- 'Single'
full_titanic$ticket.size[full_titanic$ticket.unique < 5 & full_titanic$ticket.unique>= 2]   <- 'Small'
full_titanic$ticket.size[full_titanic$ticket.unique >= 5]   <- 'Big'

###Lets check the Ticket size through grpah
ggplot(full_titanic[1:891,],aes(x = ticket.size,fill=factor(Survived))) +
  geom_bar() +
  xlab("ticket.Size VS Survival") +
  ylab("Total Count") +
  labs(fill = "Survived")

###Lets check the Ticket and title size through grpah
ggplot(full_titanic[1:891,], aes(x = ticket.size, fill = Survived)) +
  geom_bar() +
  facet_wrap(~title) + 
  ggtitle("3D View of Ticket, Title and Survival rate") +
  xlab("ticket.size") +
  ylab("Total Count") +
  ylim(0,300) +
  labs(fill = "Survived")
  
##We can't see huge diffrence b/w ticket size and Family Size, May be we will use any one of them which is contributing more
```
  
##Exploratory Analysis on Embarked

```{r, message=FALSE, warning=FALSE}

###is there any association between Survial rate and where he get in   
 ggplot(full_titanic[1:891,],aes(x = Embarked,fill=factor(Survived))) +
  geom_bar() +
  ggtitle("Embarked vs Survival") +
  xlab("Title") +
  ylab("Total Count") +
  labs(fill = "Survived") 

##Lets further divide the grpah by Pclass
ggplot(full_titanic[1:891,], aes(x = Embarked, fill = Survived)) +
  geom_bar() +
  facet_wrap(~Pclass) + 
  ggtitle("Pclass vs Embarked") +
  xlab("Pclass") +
  ylab("Total Count") +
  labs(fill = "Survived")

##Haha..I don't think there is a link between Survival rate and Embarked 

##There is a lot of Missing value in Cabin, i dont think its good idea to use that
##As mentioned earlier will use Title inplace of Age 

full_titanic$ticket.size <- as.factor(full_titanic$ticket.size)
full_titanic$title <- as.factor(full_titanic$title)

##From the Explortory anlysis part we have decided to use below variables for our model building 

##"Pclass", "title","Sex","Embarked","FamilySized","ticket.size"

##Any redaundnt varible among above will drop in the course of analysis

```

#Dividing data into train and set for internal validation

```{r, message=FALSE, warning=FALSE}

###lets prepare the and keep it in proper format before modeling

feauter1<-full_titanic[1:891, c("Pclass", "title","Sex","Embarked","FamilySized","ticket.size")]
response <- as.factor(train.tit$Survived)
feauter1$Survived=as.factor(train.tit$Survived)


###For Cross validation purpose will keep 20% of data aside from my orginal train set
##This is just to check how well my data works for unseen data
set.seed(500)
ind=createDataPartition(feauter1$Survived,times=1,p=0.8,list=FALSE)
train_val=feauter1[ind,]
test_val=feauter1[-ind,]

####check the proprtion of Survival rate in orginal training data, current traing and testing data
round(prop.table(table(train.tit$Survived)*100),digits = 1)
round(prop.table(table(train_val$Survived)*100),digits = 1)
round(prop.table(table(test_val$Survived)*100),digits = 1)


###Divided the data with same proportion of survival rate, lets start model building
```
#Predictive Analysis and Cross Validation
##Decison tree

```{r, message=FALSE, warning=FALSE}

##Even Random forest for more better than Single tree, Single tree is very easy to use and illustrate
set.seed(1234)
Model_DT=rpart(Survived~.,data=train_val,method="class")


rpart.plot(Model_DT,extra =  3,fallen.leaves = T)

###Surprise, Visualize data our Single tree model is using only Title, Pclass and Ticket.size and vomited rest
###Lets Predict train data and check the accuracy of single tree

PRE_TDT=predict(Model_DT,data=train_val,type="class")
confusionMatrix(PRE_TDT,train_val$Survived)

#####There is the Accurcay using single tree, Accuracy is 0.8375
####Not at all bad using Single tree and just 3 feauters

##There is chance of overfitting in Single tree, So I will go for cross validation using '10 fold techinque'
set.seed(1234)
cv.10 <- createMultiFolds(train_val$Survived, k = 10, times = 10)

# Set up caret's trainControl object per above.
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
                       index = cv.10)

##Train the data
Model_CDT <- train(x = train_val[,-7], y = train_val[,7], method = "rpart", tuneLength = 30,
                   trControl = ctrl)


##Check the accurcay
 ##Accurcay using 10 fold cross validation of Single tree is 0.8139 
##Overfitting earlier using Single tree there our accurcay rate is 0.83

# Plot now and check the variable imporatnce, is the same as in Single tree
rpart.plot(Model_CDT$finalModel,extra =  3,fallen.leaves = T)

##Yes, there is no chane in the imporatnce of varible


###Lets cross validate the accurcay using data that kept aside for testing purpose
PRE_VDTS=predict(Model_CDT$finalModel,newdata=test_val,type="class")
confusionMatrix(PRE_VDTS,test_val$Survived)

###There it is how exactly our train data and test data matches in accuracy (0.8192) 
```
##Model 2 - Random Forest

```{r, message=FALSE, warning=FALSE}

set.seed(1234)
rf.1 <- randomForest(x = train_val[,-7],y=train_val[,7], importance = TRUE, ntree = 1000)
rf.1
varImpPlot(rf.1)

####Random Forest accurcay rate is 82.91 which is 1% better than the decison  tree
####Lets remove 2 redaundant varibles and do the modeling again
train_val1=train_val[,-4:-5]
test_val1=test_val[,-4:-5]

set.seed(1234)
rf.2 <- randomForest(x = train_val1[,-5],y=train_val1[,5], importance = TRUE, ntree = 1000)
rf.2
varImpPlot(rf.2)

###Can see the Magic now, increease in accuracy by just removing 2 varibles, its 84.03 

##Even though ranom forest is so power full we accept the model only after cross vlaidation


set.seed(2348)
cv10_1 <- createMultiFolds(train_val1[,5], k = 10, times = 10)

# Set up caret's trainControl object per above.
ctrl_1 <- trainControl(method = "repeatedcv", number = 10, repeats = 10,
                      index = cv10_1)



# Set seed for reproducibility and train
set.seed(1234)
rf.5<- train(x = train_val1[,-5], y = train_val1[,5], method = "rf", tuneLength = 3,
              ntree = 1000, trControl =ctrl_1)

rf.5

##So the Cross validation model give us the accurcay rate of .8393#

###Lets Predict the test data 

pr.rf=predict(rf.5,newdata = test_val1)

confusionMatrix(pr.rf,test_val1$Survived)

####accuracy rate is 0.8192, low compare to trained data
```





##Support Vector Machine
###Linear Support vector Machine
```{r, message=FALSE, warning=FALSE}

###Before going to model lets tune the cost Parameter

set.seed(1274)
liner.tune=tune.svm(Survived~.,data=train_val1,kernel="linear",cost=c(0.01,0.1,0.2,0.5,0.7,1,2,3,5,10,15,20,50,100))

liner.tune

###best perforamnce is when cost=3 and accuracy rate is 82.7


####Lets get a best.liner model  
best.linear=liner.tune$best.model

##Predict Survival rate using test data

best.test=predict(best.linear,newdata=test_val1,type="class")
confusionMatrix(best.test,test_val1$Survived)

##############Linear model accuracy is 0.8136
````

###Radial Support vector Machine
```{r, message=FALSE, warning=FALSE}


######Lets go to non liner SVM, Radial Kerenl
set.seed(1274)

rd.poly=tune.svm(Survived~.,data=train_val1,kernel="radial",gamma=seq(0.1,5))

summary(rd.poly)
best.rd=rd.poly$best.model

###Non Linear Kerenel giving better accuray 

##Lets Predict test data
pre.rd=predict(best.rd,newdata = test_val1)

confusionMatrix(pre.rd,test_val1$Survived)

####Accurcay of test data using Non Liner model is 0.81..still there is diffrence train and test accurcay
####it could be due we are using smaller set of sample for testing data
```

##Logistic Regression

```{r, message=FALSE, warning=FALSE}

contrasts(train_val1$Sex)
contrasts(train_val1$Pclass)

##The above shows how the varible coded among  

##Lets run Logistic regression model
log.mod <- glm(Survived ~ ., family = binomial(link=logit), 
               data = train_val1)
###Check the P value
summary(log.mod)
confint(log.mod)

###You will first have to create a vector of the predicted probabilities, as follows:
train.probs <- predict(log.mod, data=train_val1,type =  "response")
table(train_val1$Survived,train.probs>0.5)

(395+204)/(395+204+70+45)

###Logistic regression predict train data with accuracy rate of 0.83 

test.probs <- predict(log.mod, newdata=test_val1,type =  "response")
table(test_val1$Survived,test.probs>0.5)

(97+47)/(97+12+21+47)

###Accuracy rate of teat data is 0.8135..again there is gap b/w both prediction


