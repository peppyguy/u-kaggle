{"cells": [{"source": ["**BEGINNER'S GUIDE TO MERCARI IN R**\n", "\n", "I'm writing what I believe is a fairly straight forward guide to my thought process through the Mercari challenge.\n", "\n", "Table of Contents:\n", "\n", "**1. Import library/datasets**\n", "\n", "**2. Create obvious variables**\n", "\n", "**3. Explore data to Find less obvious variables**\n", "\n", "**4. Prepare the data for xgboost**\n", "\n", "**5. Run an xgboost validation model**\n", "\n", "**6. Analyze results**\n", "\n", "For those who are feeling overwhelmed by the sheer size of this dataset, I recommend slicing 10% off and working on that section of the code. I'll post a quick way to do this.\n", "\n", "I'll be updating this kernel as I think of ways to improve the efficiency or score of my model."], "cell_type": "markdown", "metadata": {"collapsed": true, "_cell_guid": "ed4798ff-6d10-482c-9e36-25afb547ca53", "_uuid": "240c19f5fc4001971b3113ffdedf050c5f0fd3d1"}}, {"outputs": [], "source": ["#################################################\n", "#################################################\n", "### IMPORT LIBRARIES AND DATA SETS\n", "#################################################\n", "#################################################\n", "\n", "library(ggplot2)\n", "library(dplyr)\n", "library(caTools)\n", "library(stringr)\n", "library(xgboost)\n", "library(quanteda)\n", "library(SnowballC)\n", "library(tm)\n", "library(gridExtra)\n", "library(corrplot)\n", "\n", "train = read.csv('../input/train.tsv', sep='\\t')\n", "test = read.csv('../input/test.tsv', sep='\\t')\n", "submission = read.csv('../input/sample_submission.csv')\n", "all = rbind(within(train,rm('train_id','price')),within(test,rm('test_id')))\n", "summary(all)\n", "\n", "#### In order to analyze the data more easily, you can split the set:\n", "\n", "#split = sample.split(train, SplitRatio = 0.1)\n", "#trainNew = subset(train,split == TRUE)\n", "\n", "## If you do this, replace 'all' and 'train' with trainNew, and have yourself some fun."], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "1b0e95bb-2397-4caf-92b5-2e5e0b85b431", "_uuid": "ff709955f40e0309af6d2c7375162258d6e6f7a0", "scrolled": true, "_kg_hide-output": true}}, {"source": ["Next you can summarize the data and look at the predictor variable names and their contents. \n", "\n", "Here you can parse lightly through things and also rename the variables to whatever your aesthetic preferences are. This part has already been covered extensively in other kernels, I'm going to focus on feature selection and modeling."], "cell_type": "markdown", "metadata": {"_cell_guid": "a2acb96b-c57e-4b30-ba6c-69ae4ce11af2", "_uuid": "fd568c9ef9126b9503ecda6381c833cc6900e571"}}, {"outputs": [], "source": ["summary(train$price)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "02d2051d-d415-4830-bcf1-3ad42352523b", "_uuid": "e43add7c20b5d4f7c2e2fc1c93b0361fbc4e5f05", "_kg_hide-input": true, "_kg_hide-output": false}}, {"source": ["You'll notice the following histogram (left) looks bad. We need to fix the skew by transforming the **price** variable.\n", "\n", "We are going to do this by way of the **log transformation** (shown right)."], "cell_type": "markdown", "metadata": {"_cell_guid": "6a370f26-0b63-40ba-8370-f8fd2feaee47", "_uuid": "35d7b8ad86b85bd55b1d7424cee6f58081d413e8"}}, {"outputs": [], "source": ["options(repr.plot.width=5, repr.plot.height=5)\n", "a = ggplot(train, aes(x=price))+ geom_histogram(binwidth=30)\n", "train$price = with(train, ifelse(price > 0, log(price), price))\n", "b = ggplot(train, aes(x=price))+ geom_histogram(binwidth=0.1)\n", "grid.arrange(a,b,ncol=2)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "0e7a2445-ab46-45e6-b975-4e6715c860b6", "_kg_hide-input": true, "_uuid": "831d018db392c18d6717ceee7284b8a6c708e580"}}, {"source": ["**brand_name**\n", "\n", "I'll begin my data manipulations with the variable **brand_name** because it's the most simple.\n", "\n", "I'll set the missing **brand_name** values to -1 in order to give them a value which separates them from the items which have brand names.\n", "\n", "Given that almost half of the values for **brand_name** are blank, and that **brand_name**, as you'll see, is so important to our model, I may try to string detect brand names from the variables **item_description** and **name**. More on this later."], "cell_type": "markdown", "metadata": {"_cell_guid": "04cd9459-8b10-41c3-b718-42de57221b9d", "_uuid": "707c8462224cfc060892f497cf8bfbd9b2e81142"}}, {"outputs": [], "source": ["##########################################\n", "### brand_name\n", "##########################################\n", "\n", "all$brand_name = as.character(all$brand_name)\n", "all$brand_name[all$brand_name == \"\"] = -1"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "a2f39260-626f-4051-b02f-cabc6afc98ec", "_uuid": "d7326948b8cdde7a108949c8c420938fb8c3d675"}}, {"source": ["**category_name**\n", "\n", "Next, I'll look at category_name, which, luckily, is a very clean looking variable, as you'll see below."], "cell_type": "markdown", "metadata": {"_cell_guid": "b71d9bc7-c886-4e77-83de-d210ff32115f", "_uuid": "1f4b4a5aabd1f3a2ae4c2edc6dfc4163757c1dad"}}, {"outputs": [], "source": ["all[1:5,'category_name']"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "d5a59588-8523-49fb-bbf8-7551e7488e26", "_uuid": "75134e9fc493bd501bd1bc0eedf18e91ca0eb90c"}}, {"source": ["**category_name (ctd.)**\n", "\n", "A nice variable - it has, for the most part, three sections, all of which are separated by **/ **.\n", "\n", "I'm going to use a function from the stringr package which splits strings off from a chosen point in an existing string. In our case it will detect **/** , and then split the string from / on.\n", "\n", "**Example:** For [1] Men/Tops/T-shirts  , it will split Men, Tops and T-shirts because they are all separated by a / .\n", "\n", "What is great about splitting strings is that I can stuff these split strings into their own variables.\n", "\n", "Note: You\u2019ll see I only cut the strings from the second and third dashes. This is because, after creating a model and testing the predictor variables, something became apparent: the first category split was so correlated to the **category_name** variable that it had no effect on my model. I rename **category_name** to **cat1** for aesthetic purposes."], "cell_type": "markdown", "metadata": {"_cell_guid": "956b79a3-9cd3-47f4-8262-4115f120e8a0", "_uuid": "ef7e54d37553fa371917b4ca4848c1f563ceb308"}}, {"outputs": [], "source": ["###############################################\n", "### category_name + cat1,cat2,cat3\n", "###############################################\n", "\n", "splitVar = str_split(all$category_name, \"/\")\n", "cat2 = sapply(splitVar,'[',2)\n", "cat3 = sapply(splitVar,'[',3)\n", "all['cat2'] = cat2\n", "all['cat3'] = cat3\n", "all$cat2[is.na(all$cat2)] = -1\n", "all$cat3[is.na(all$cat3)] = -1\n", "all['cat1'] = all$category_name\n", "all['cat1'][is.na(all$cat1)] = -1\n", "all$category_name = NULL"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b930a665-d464-4823-8387-0dccecad0ce4", "_uuid": "c2442bce20a709158a740fc5b344e1abfd67969b"}}, {"source": ["**item_description**\n", "\n", "Now I'll look at the Text, which I believe is where the separation in the quality of predictions is going to occur in this competition. The other variables are too basic, in my (maybe naive) opinion. In Text Analytics, we remove superfluous words in order to isolate the predictive words. The variables in the window below are created mainly from the detection, indexation, and length computation of specific general expressions."], "cell_type": "markdown", "metadata": {"_cell_guid": "8e2d9e87-813b-46e9-9220-93f7f4b47c12", "_uuid": "adb0fe8efb8757c47b50785fae4e7c53dcb0b042"}}, {"outputs": [], "source": ["all['descLength'] = str_length(all$item_description)\n", "all$descLength[all$descLength == 2] = -1\n", "all['descUP'] = sapply(gregexpr(\"[A-Z]\", all$item_description), length)\n", "all$descUP[all$item_description == -1] = -1\n", "all['descNC'] = sapply(gregexpr(\"[0-9]\", all$item_description), length)\n", "all$descNC[all$item_description == -1] = -1\n", "all['descUD'] = (all$descUP/all$descLength)\n", "all['descND'] = (all$descNC/all$descLength)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "570df7d7-ac54-4528-a167-dcf73ad057d0", "_uuid": "8f2d07ed2981ef81dda3c755bbda42dbd36b3de5"}}, {"source": ["As for the following window:\n", "\n", "The first command loads the variable we want to analyze into the proper format.\n", "The second command (tolower) lowercases all words.\n", "The third command (removePunctuation) removes punctuation.\n", "The fourth command (removeWords) removes... words. It also removes common (filler in terms of data analysis) words.\n", "I stuffed the newly edited item_description into the correct format and then fed it back to the main data set."], "cell_type": "markdown", "metadata": {"_cell_guid": "a44de016-7b15-4472-aeaa-7a449de963d2", "_uuid": "efdeb05f6e9c7aa10e26083f2a27f74619ea79d8"}}, {"outputs": [], "source": ["corpus = Corpus(VectorSource(all$item_description))\n", "corpus = tm_map(corpus, tolower)\n", "corpus = tm_map(corpus, removePunctuation)\n", "corpus = tm_map(corpus, removeWords, stopwords(\"english\"))\n", "dataframe <- data.frame(text=sapply(corpus, identity),stringsAsFactors=F)\n", "all$item_description = dataframe$text"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "c51aee08-1d71-47cf-96c4-4e66af45a1d8", "_uuid": "06786b8c880858c4556369bf5870ee1aefec3934"}}, {"source": ["**item_description (ctd.)**\n", "\n", "I'll go further.\n", "\n", "* First, I'll separate the items without a description from the items which have descriptions.\n", "* Next, I'll run a string along the length of item_description and measure it and register it into a new variable - **descLength**.\n", "* I'll set the variable values for all of the items without an **item_description** to -1.\n", "* I'll stuff the word count into a new variable - **descWC**.\n", "* Lastly, I'll divide the description length into the description word count and stuff this result into a new variable - **descWD1**."], "cell_type": "markdown", "metadata": {"_cell_guid": "166ad1fb-d49a-42dd-9c2d-a04b5516521c", "_uuid": "50b108847f15995b51e2e9b2b9ab1c43eef72bf1"}}, {"outputs": [], "source": ["all['item_description'] = ifelse(str_detect(all$item_description,'description yet'),-1,all$item_description)\n", "all['descWC'] = sapply(gregexpr(\"\\\\W+\", all$item_description), length) + 1\n", "all$descWC[all$item_description == -1] = -1\n", "all['descWD1'] = (all$descLength/all$descWC)\n", "all$descWD1[all$item_description == -1] = -1\n", "all['descWD2'] = tan(all$descWD1)\n", "all$descWD2[all$item_description == -1] = -1"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7319c5e8-d3c8-43f5-9b89-bd18f6ed9993", "_uuid": "9188730da9a832c347e29752651f5da2c9202069"}}, {"source": ["**name**\n", "\n", "I'll do with the variable **name** nearly the exact same thing I did above with **item_description**.\n", "\n", "Not a bad excercise, though I'll write out the code."], "cell_type": "markdown", "metadata": {"_cell_guid": "a5b3051d-8d5e-4bd9-b520-1e9f4d6be271", "_uuid": "dbe1b281218de219e701ad4e440fbe79faa2539c"}}, {"outputs": [], "source": ["all['nameLength'] = str_length(all$name)\n", "all['nameUP'] = sapply(gregexpr(\"[A-Z]\", all$name), length)\n", "all['nameNC'] = sapply(gregexpr(\"[0-9]\", all$name), length)\n", "all['nameUD'] = (all$nameUP/all$nameLength)\n", "all['nameND'] = (all$nameNC/all$nameLength)\n", "corpus = Corpus(VectorSource(all$name))\n", "corpus = tm_map(corpus, tolower)\n", "corpus = tm_map(corpus, removePunctuation)\n", "corpus = tm_map(corpus, removeWords, stopwords(\"english\"))\n", "dataframe1 <- data.frame(text=sapply(corpus, identity),stringsAsFactors=F)\n", "all$name = dataframe1$text\n", "all['nameLength'] = str_length(all$name)\n", "all['nameWC'] = sapply(gregexpr(\"\\\\W+\", all$name), length) + 1\n", "all['nameWD1'] = (all$nameLength/all$nameWC)\n", "all['nameWD2'] = tan(all$nameWD1)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "7b5abf40-a9c8-4bb8-b98b-9df289c42fa0", "_uuid": "bcebb25dc53a2b2cbe2eddd0832f49509b4f486b"}}, {"source": ["\n", "The hidden code below (which gives statistics on word counts) is taken nearly wholesale from [Troy Walters](http://www.kaggle.com/captcalculator/a-very-extensive-mercari-exploratory-analysis)\n", "\n", "My contribution was to split the set in two (below median price and above median price), and then to compare the word frequencies between the two sets (as illustrated below).\n", "\n", "**Note:** I've since split the sets in different ways to identify term frequencies. Feel free to try your own cuts."], "cell_type": "markdown", "metadata": {"_cell_guid": "4e93c9bb-2440-425a-82ad-9034cd1d187d", "_uuid": "f1026a1b56888848684eb7ee8b0348b6d2be022c"}}, {"outputs": [], "source": ["train1 = subset(train, price <= 2.833)\n", "train2 = subset(train, price > 2.833)\n", "\n", "corpus1 = corpus(as.character(train1$item_description))\n", "summary(corpus1)\n", "dfm1 <- dfm(\n", "  corpus1, \n", "  ngrams = 1, \n", "  remove = c(\"rm\", stopwords(\"english\")),\n", "  remove_punct = TRUE,\n", "  remove_numbers = TRUE,\n", "  stem = TRUE)\n", "tf1 <- topfeatures(dfm1, n = 100)\n", "\n", "corpus2 = corpus(as.character(train2$item_description))\n", "summary(corpus2)\n", "dfm2 <- dfm(\n", "  corpus2, \n", "  ngrams = 1, \n", "  remove = c(\"rm\", stopwords(\"english\")),\n", "  remove_punct = TRUE,\n", "  remove_numbers = TRUE,\n", "  stem = TRUE)\n", "tf2 <- topfeatures(dfm2, n = 100)\n", "\n", "termFrame = data.frame(term = names(tf1), freq = unname(tf1))\n", "termFrame1 = data.frame(term = names(tf2), freq = unname(tf2))\n", "termFrame = termFrame %>%\n", "  left_join(termFrame1, by = 'term')\n", "termFrame$ratio = termFrame$freq.x/(termFrame$freq.x+termFrame$freq.y)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "c4b00815-8e4f-400e-b3fc-46fe9e625c7e", "_uuid": "cfa70552e9ae65849ff0b6eadb86785245f5f5d4", "_kg_hide-input": true, "_kg_hide-output": true}}, {"source": ["The manipulations below are my introductory attempt at making use of the code. These words were chosen after dividing data sets into above average and below average pricing, and then looking for the highest and lowest frequency ratios which occur between the split sets. I've since added bigrams and trigrams."], "cell_type": "markdown", "metadata": {"_cell_guid": "8e17d388-91c5-43e6-8145-dc0ec9a61cc2", "_uuid": "c6ba028495eb62a7021dd11bc832c396b9d67c0b"}}, {"outputs": [], "source": ["termFrame1 = subset(termFrame, ratio < 0.43)\n", "options(repr.plot.width=8, repr.plot.height=5)\n", "ggplot(termFrame1, aes(x=reorder(term,ratio), y=ratio))+\n", "  geom_bar(stat='identity')+\n", "  scale_y_continuous(limits=c(0,1))+\n", "  ggtitle('Term Frequency Ratio - Above Median Pricing - item_description')+\n", "  geom_abline(intercept = 0.5, slope = 0,color=\"red\")+\n", "  xlab('Term')\n", "\n", "termFrame2 = subset(termFrame, ratio > 0.53)\n", "ggplot(termFrame2, aes(x=reorder(term,-ratio), y=ratio))+\n", "  geom_bar(stat='identity')+\n", "  scale_y_continuous(limits=c(0,1))+\n", "  ggtitle('Term Frequency Ratio - Below Median Pricing - item_description')+\n", "  geom_abline(intercept = 0.5, slope = 0,color=\"red\")+\n", "  xlab('Term')"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "80c84192-fca5-45ae-924a-fcbf8ffe17dd", "_kg_hide-input": true, "_uuid": "c917efb1c681a04c9991d8f0a19c5fa0e1a0274a"}}, {"outputs": [], "source": ["lMedian = subset(train, price <= 2.833)\n", "hMedian = subset(train, price > 2.833)\n", "\n", "corpusNL = corpus(as.character(lMedian$name))\n", "summary(corpusNL)\n", "dfmNL <- dfm(\n", "  corpusNL, \n", "  ngrams = 1, \n", "  remove = c(\"rm\", stopwords(\"english\")),\n", "  remove_punct = TRUE,\n", "  remove_numbers = TRUE,\n", "  stem = TRUE)\n", "tfNL <- topfeatures(dfmNL, n = 100)\n", "\n", "corpusNH = corpus(as.character(hMedian$name))\n", "summary(corpusNH)\n", "dfmNH <- dfm(\n", "  corpusNH, \n", "  ngrams = 1, \n", "  remove = c(\"rm\", stopwords(\"english\")),\n", "  remove_punct = TRUE,\n", "  remove_numbers = TRUE,\n", "  stem = TRUE)\n", "tfNH <- topfeatures(dfmNH, n = 100)\n", "\n", "termFrameNL = data.frame(term = names(tfNL), freq = unname(tfNL))\n", "termFrameNH = data.frame(term = names(tfNH), freq = unname(tfNH))\n", "termFrameN = termFrameNL %>%\n", "  left_join(termFrameNH, by = 'term')\n", "termFrameN$ratio = termFrameN$freq.x/(termFrameN$freq.x+termFrameN$freq.y)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "4a1d28ec-2061-45ea-ac64-918c82b7a616", "_uuid": "3a8e3b8eeeea4a5953d3769ac26fc0841da01bc3", "_kg_hide-input": true, "_kg_hide-output": true}}, {"outputs": [], "source": ["##########################################\n", "### name term frequency ratio\n", "##########################################\n", "\n", "termFrameNl = subset(termFrameN, ratio < 0.40)\n", "ggplot(termFrameNl, aes(x=reorder(term,ratio), y=ratio))+\n", "  geom_bar(stat='identity')+\n", "  scale_y_continuous(limits=c(0,0.5))+\n", "  geom_abline(intercept = 0.5,slope=0,color=\"red\")+\n", "  ggtitle('Term Frequency Ratio - Below Median Pricing - name')+\n", "  xlab('Term')\n", "\n", "termFrameNh = subset(termFrameN, ratio > 0.60)\n", "ggplot(termFrameNh, aes(x=reorder(term,-ratio), y=ratio))+\n", "  geom_bar(stat='identity')+\n", "  scale_y_continuous(limits=c(0,1))+\n", "  geom_abline(intercept = 0.5,slope=0,color=\"red\")+\n", "  ggtitle('Term Frequency Ratio - Below Median Pricing - name')+\n", "  xlab('Term')"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "1da801d7-f5b2-410c-b726-66fb27de6aba", "_kg_hide-input": true, "_uuid": "68b5c700eb65997bd65409e6f57056312fc932e2"}}, {"outputs": [], "source": ["###############################################\n", "### relevant words w.r.p. ratio of price sets\n", "###############################################\n", "\n", "##################################\n", "### item_description\n", "##################################\n", "\n", "all['box'] = (str_detect(all$item_description, 'box'))*1\n", "all['bag'] = (str_detect(all$item_description, 'bag'))*1\n", "all['come'] = (str_detect(all$item_description, 'come'))*1\n", "all['gold'] = (str_detect(all$item_description, 'gold'))*1\n", "all['icase'] = (str_detect(all$item_description, 'case'))*1\n", "all['condit'] = (str_detect(all$item_description, 'condit'))*1\n", "all['authent'] = (str_detect(all$item_description, 'authent'))*1\n", "all['origin'] = (str_detect(all$item_description, 'origin'))*1\n", "all['leather'] = (str_detect(all$item_description, 'leather'))*1\n", "all['includ'] = (str_detect(all$item_description, 'includ'))*1\n", "all['ibundl'] = (str_detect(all$item_description, 'bundl'))*1\n", "all['gb'] = (str_detect(all$item_description, 'gb '))*1\n", "\n", "##################################\n", "### name\n", "##################################\n", "\n", "all['nbundl'] = (str_detect(all$name, 'bundl'))*1\n", "all['ncase'] = (str_detect(all$name, 'case'))*1\n", "all['iphon'] = (str_detect(all$name, 'iphon'))*1\n", "all['shirt'] = (str_detect(all$name, 'shirt'))*1\n", "all['ship'] = (str_detect(all$name, 'ship'))*1\n", "all['reserv'] = (str_detect(all$name,'reserv'))*1\n", "all['ring'] = (str_detect(all$name,'ring'))*1\n", "all['diamond'] = (str_detect(all$name,'diamond'))*1"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "163124fa-2db1-448a-96e2-78ece931d685", "_uuid": "2193d3cc0b3583c65a2f12fdf919c6c774c2bc19"}}, {"source": ["**Note:** Reading through the competition, it seems a popular way to deal with specific words is to use a text analytics process called **tokenization**. I'm going to learn about this on Youtube and then attempt to bring this theory back to the notebook in the near future.\n", "\n", "**Update:** I've learned the basic concepts and coding syntax. As soon as I make a model which fits inside Kaggle's kernel size limit, I'll bring it back to this kernel.\n", "\n", "**Also note:**  Some words seen in the charts were not one-hot encoded into variables. Why? For various reasons. Example: **Lularoe** is a brand name, and so instead of creating a variable for a brand name, it is better to string detect all occurences of **'lularo'** and then assign the **brand_name** of the indexed items to **Lularoe**. Moreover, it is a bad decision to make too many variables, as the model will be clunky, which, in a kernel competition, is costly for reasons mentioned below. Other words which were one-hot encoded were not posted on the charts. This is because I performed a similar frequency ratio test except with prediction outliers which you'll read about below."], "cell_type": "markdown", "metadata": {"_cell_guid": "c7dc2430-4a50-4db3-bf35-d35dd5aefc37", "_uuid": "bc02124c744ab38caeab8b2de19f3e0995a83a52"}}, {"outputs": [], "source": ["all$brand_name[str_detect(all$name,'lularo')] = 'Lularoe'"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "b31a0a63-2574-4c8e-aeae-e783ae6f62dc", "_uuid": "913f9c4cd5dc73eb1989eb906659eef0f211ea96"}}, {"source": ["Here, I copy the data frame **all** into a new data frame just because it's nice to separate the big time manipulations to the small xgBoost preparation manipulations."], "cell_type": "markdown", "metadata": {"_cell_guid": "5cc40104-37eb-4341-ad06-cda28a22777a", "_uuid": "977563f65c9df79231ecb5b5e21df058365e284c"}}, {"outputs": [], "source": ["funTime = all\n", "\n", "features = names(funTime)\n", "for(f in features){\n", "  if(class(funTime[[f]])==\"character\"){\n", "    levels=sort(unique(funTime[[f]]))\n", "    funTime[[f]]=as.integer(factor(funTime[[f]],levels = levels))}\n", "}"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "900901b2-4cd1-4722-8006-5592f84a1792", "_uuid": "44e54a2f33e3bd6403f7f128deff16d3615a61ab"}}, {"source": ["**xgBoost preparations and modelling**\n", "\n", "Now I'll create the **xgBoost** model and make our predictions. I thought I'd make an xgBoost validation model and then analyze the results to find potential improvement pathways.\n", "\n", "**Note:** Creating a **validation** set means that I am only using part of the data to train our model, which means our model won\u2019t perform quite as good as it could with the entire **train** set. Using the entire training set, our score will drop below 0.500."], "cell_type": "markdown", "metadata": {"_cell_guid": "90a11171-b92a-4666-8cea-7d65b5337118", "_uuid": "0dd5c422765615de8007bda9222e82298e58be7c"}}, {"outputs": [], "source": ["rmseEval=function(yTrain,yPred) {\n", "  mseEval=sum((yTrain - yPred)^2)/length(yTrain)\n", "  return(sqrt(mseEval)) }"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "3126c975-dfd7-4d38-a3e8-fcfb38d0b79e", "_uuid": "5e69626caeffb3d286a15edd1a72ac280c33efd1", "_kg_hide-input": false, "_kg_hide-output": false}}, {"outputs": [], "source": ["ntrain = nrow(train)\n", "nfun = nrow(funTime)\n", "validation=funTime[1:ntrain,]\n", "validation$price=train[,'price']\n", "testXG = funTime[(ntrain+1):nfun,]\n", "split=sample.split(validation,SplitRatio=0.99)\n", "trainXG=subset(validation,split==TRUE)\n", "validXG=subset(validation,split==FALSE)\n", "yTrainXG=trainXG$price\n", "yValidXG=validXG$price\n", "trainXG = trainXG %>%\n", "  select(-price)\n", "validXG = validXG %>%\n", "  select(-price)\n", "trainXG[] = lapply(trainXG,as.numeric)\n", "validXG[] = lapply(validXG,as.numeric)\n", "testXG[] = lapply(testXG,as.numeric)\n", "xgTrain = xgb.DMatrix(as.matrix(trainXG),label=yTrainXG)\n", "xgValid = xgb.DMatrix(as.matrix(validXG),label=yValidXG)\n", "xgTest = xgb.DMatrix(as.matrix(testXG))\n", "\n", "xgPrm = list(boost='gbtree',objective='reg:linear',colsample_bytree=1,\n", "              eta=0.11,max_depth=9,min_child_weight=1,alpha=0.3,\n", "              lambda=0.4,gamma=0.2,subsample=0.8,seed=5,silent=TRUE)\n", "xgbModel = xgb.train(xgPrm,xgTrain,nrounds=300,watchlist=list(train=xgTrain,test=xgValid))\n", "ypredXgbTrain = predict(xgbModel,xgTrain)\n", "rmseEval(yTrainXG,ypredXgbTrain)\n", "ypredXgbValid = predict(xgbModel,xgValid)\n", "rmseEval(yValidXG,ypredXgbValid)\n", "ypredXgb = predict(xgbModel,xgTest)\n", "submission$price = exp(ypredXgb)\n", "\n"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "6568c502-4702-43c2-910a-e56fa3c37bb4", "_uuid": "c8984cc544bcb4b235ed0682e0723b13e742044d", "_kg_hide-output": true}}, {"outputs": [], "source": ["rmseEval(yTrainXG,ypredXgbTrain)\n", "rmseEval(yValidXG,ypredXgbValid)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "07877100-d578-4c5f-930e-fffdad939147", "_uuid": "59cd69e9006d057cc2344e2fa28325c61050df50"}}, {"source": ["**prediction visualization**\n", "\n", "Okay. With these results, I'll visualize the areas where my predictions are least accurate.\n", "\n", "What you'll notice is that my predictions for items with prices above 5 are consistently lower than what they should be, while my predictions for items with prices below 2 are consistently higher that what they should be.\n", "\n", "The next step is to find how we can fix this.\n"], "cell_type": "markdown", "metadata": {"_cell_guid": "a1048556-80cd-48d3-936e-0dad633c92a2", "_uuid": "3adaefcf3672e91c17bc558d985c965742336334"}}, {"outputs": [], "source": ["predEval = as.data.frame(ypredXgbValid)\n", "predEval$test = yValidXG\n", "predEval$error = predEval$ypredXgbValid - predEval$test\n", "\n", "big = ggplot(predEval, aes(x=test,y=ypredXgbValid)) +\n", "  geom_point(aes(colour = error)) + scale_colour_gradient2()+\n", "  expand_limits(x = 0, y = 0) +\n", "  geom_abline(intercept = 0, slope = 1)+\n", "  xlab('Price')+\n", "  ylab('Prediction')+\n", "  ggtitle('Prediction Accuracies')\n", "\n", "subHigh = subset(predEval, abs(error) > 1.5)\n", "small = ggplot(subHigh, aes(x=test,y=ypredXgbValid)) + \n", "  geom_point(aes(colour = error)) + scale_colour_gradient2()+\n", "  expand_limits(x = 0, y = 0) +\n", "  geom_abline(intercept = 0, slope = 1)+\n", "  xlab('Price')+\n", "  ylab('Prediction')+\n", "  ggtitle('Prediction Outliers')\n", "grid.arrange(big,small,ncol=2)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "96142e8b-3524-4ebe-8b5c-604212c3ced2", "_kg_hide-input": true, "_uuid": "73aa59c7696ac10b398299384fb092ca309f57f0"}}, {"source": ["**zero price items**\n", "\n", "One way I\u2019m thinking I can deal with the results illustrated above is to look at the zero price items. It seems somebody is giving away an Armani sweater - which is not only unlikely but it probably hurts our model. When you feed that item through xgBoost, it will get confused and then predict, on average, lower prices. Which leaves me with two options: to remove the zero price items or to predict their prices. I\u2019m going to predict their prices in order to show you how something like this is done."], "cell_type": "markdown", "metadata": {"_cell_guid": "d7a13aac-9007-42e0-80f3-31f314933bfc", "_uuid": "308c8fa5de071c94b385a719c3bae790adb1a69c"}}, {"outputs": [], "source": ["ntrain = nrow(train)\n", "zeroPriceIN=funTime[1:ntrain,]\n", "zeroPriceIN$price=train[,'price']\n", "\n", "zeroPrice = zeroPriceIN %>%\n", "  filter(price > 0) %>%\n", "  group_by(brand_name,cat1) %>%\n", "  summarize(sugPrice = median(price))\n", "\n", "zeroPriceIN = zeroPriceIN %>%\n", "  left_join(zeroPrice, by=c('brand_name','cat1')) %>%\n", "  mutate(price = ifelse(price == 0,sugPrice,price)) %>%\n", "  select(-sugPrice)\n", "\n", "zeroPriceIN$price = as.numeric(zeroPriceIN$price)\n", "train$price = zeroPriceIN$price"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "fcab7612-76b8-417d-adb4-90b5591e3b4d", "_uuid": "d79cf3bbeb1e12a4218d79bc77375930b7452e40"}}, {"source": ["Now that we have the zero prices fixed, let's get back to our predictior variables."], "cell_type": "markdown", "metadata": {"_cell_guid": "825c7fb0-2ade-4fe1-82c1-309e45982b1f", "_uuid": "3bdd413fb02ebf6f7da28dc36fe3edbadc38f3f2"}}, {"source": ["**correlation**\n", "\n", "I'll visualize the correlation of my variables with the dependent variable **price**, but I'll also look for correlations between the variables themselves. You'll notice strong correlations on some of the variables I created. This is unsurprising: the amount of upper case letters is, and should be, very correlated to the density of upper case letter."], "cell_type": "markdown", "metadata": {"_cell_guid": "cf5c4d21-622e-477a-83fc-627aadb06dab", "_uuid": "cfadcfc88d0345c7cfd143c3b55e3f55df23beef"}}, {"outputs": [], "source": ["validation[] = lapply(validation,as.numeric)\n", "correlations <- cor(validation)\n", "corrPrice <- as.matrix(sort(correlations[,'price'], decreasing = TRUE))\n", "corr.idx <- names(which(apply(corrPrice, 1, function(x) (x > 0.06 | x < -0.06))))\n", "corrplot(as.matrix(correlations[corr.idx,corr.idx]), type = 'upper', method='color', addCoef.col = 'black', tl.cex = 0.7,cl.cex = 0.7, number.cex=0.6)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "11dde195-93b4-4000-96db-a03b326f399a", "_uuid": "c9f815294ff6b921f72bd6f4f76f1a95ec1c2ba3"}}, {"source": ["**variable importance**\n", "\n", "To understand where I can improve, I first need to understand exactly which variables my model liked and which it didn't like."], "cell_type": "markdown", "metadata": {"_cell_guid": "8374966d-ee1f-4366-83d2-076da9aec5f9", "_uuid": "dd3b46b565224eb95b3442479cf521c8ce726684"}}, {"outputs": [], "source": ["names = names(trainXG)\n", "importance_matrix <- xgb.importance(names, model = xgbModel)\n", "options(repr.plot.width=8, repr.plot.height=8)\n", "ggplot(importance_matrix,aes(x=reorder(Feature,Gain),y=Gain))+\n", "  geom_bar(stat='identity',aes(fill = Gain > 0.003))+\n", "  scale_fill_manual(values=c('red','grey'),guide=FALSE) +\n", "  coord_flip()+\n", "  xlab('Features')+\n", "  ylab('Importance')+\n", "  ggtitle('Feature Importance')"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "97c16a05-014f-4011-a9ed-016d7af0a1de", "_uuid": "737cd6671f73f700d137300bb4ca510af727b292"}}, {"source": ["This chart brings about an interesting point. In my opinion, this is what makes this competiton enticing: the code you write has to be submitted by way of a kernel, which means you have at most a run time of 3600 seconds until the system shuts down, which means you have a tradeoff to consider: do you try and increase your predictions\u2019 accuracy by creating more variables, or by commanding more predictive rounds for your model? Like most things the answer is likely in a balanced approach.\n", "\n", "Though many of the variables I created are contributing to our model, I\u2019m going to begin removing some of the non-predictive variables and upping the rounds for my xgboost model. "], "cell_type": "markdown", "metadata": {"_cell_guid": "9877b9f1-2e2e-4d52-a059-43cae460e5c8", "_uuid": "0d842f21d9ef58e7ecea7c17a87d32bbb9700ed1"}}, {"source": ["**overfitting**\n", "\n", "Now I'll look into overfitting. Plotting and comparing my model's train and test rmse error results will give me an idea of how the model is progressing."], "cell_type": "markdown", "metadata": {"_cell_guid": "86704aa4-e0e8-4fdc-8e44-93caf16df5db", "_uuid": "63937634bc666e5d943c63fad61bd65ab8e9dabc"}}, {"outputs": [], "source": ["rmsePlot = data.frame(xgbModel$evaluation_log)\n", "plot(rmsePlot$iter,rmsePlot$train_rmse,col=\"blue\",ylim=c(0,2.5))\n", "lines(rmsePlot$iter,rmsePlot$test_rmse,col=\"red\")"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "e237f416-c366-4a85-8430-579fe97dccb7", "_uuid": "6d0fac12562a8199a832d86ecc329c8d815022fa"}}, {"source": ["Note that the train and test **rmse** are nearly stuck together throughout my model's rounds so far, which is encouraging."], "cell_type": "markdown", "metadata": {"_cell_guid": "cf8997bc-a182-4822-a51a-d534ea85ae48", "_uuid": "a73f536ed7834c5f8569f19a314efb3242b902ad"}}, {"source": ["**cross validation**\n", "\n", "This talk of overfitting should make you think of **cross validation**. When you run your model through a cross validation process, you end up with a more realistic view of your model in terms of it's accuracy. I use the caret package for cross validation processes. I'll post the code below, but I'll comment it out because it takes time. Beware of this when you cross validate. Press run, then sit back, relax, and listen to [the strokes](https://www.youtube.com/watch?v=OOTWjpuCKVE).\n", "\n", "Note: I recommend splitting the set when running cross validation, unless you really like the strokes."], "cell_type": "markdown", "metadata": {"_cell_guid": "1dba2951-b0fe-4b85-b56b-4a8731ad15ca", "_uuid": "92436f22ccea38052d2ee3e0432138aa140e5f9a"}}, {"outputs": [], "source": ["#validationCR=funTime[1:ntrain,]\n", "#validationCR$price=train[,'price']\n", "#split=sample.split(validationCR,SplitRatio=0.1)\n", "#trainX=subset(validationCR,split==TRUE)\n", "#yTrain=trainX$price\n", "#trainX = trainX %>%\n", "#  select(-price)\n", "#trainX[] = lapply(trainX,as.numeric)\n", "#dTrain = xgb.DMatrix(as.matrix(trainX),label=yTrain)\n", "\n", "#cvCtrl <- trainControl(method = \"repeatedcv\",number = 3,repeats = 2,allowParallel=T)\n", "#xgbGrid <- expand.grid(nrounds=50,\n", "#                       eta=c(0.08,0.09,0.1),\n", "#                       max_depth=9,\n", "#                       colsample_bytree=1,\n", "#                       min_child_weight=1,\n", "#                       subsample=0.4,\n", "#                       gamma=0.2)\n", "#set.seed(33)\n", "#xgbTune <- train(as.matrix(trainX),yTrain,method=\"xgbTree\",trControl=cvCtrl,\n", "#          tuneGrid=xgbGrid,verbose=T,metric=\"RMSE\")\n", "#xgbTune\n", "#plot(varImp(xgbTune))"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "18f46228-3742-4ac9-92f4-b1db3548280f", "_uuid": "caff88a4c968e28df1df8267e97be2b0566e6715"}}, {"source": ["More to come."], "cell_type": "markdown", "metadata": {"_cell_guid": "f97df078-6200-466d-9c2d-b3d4d31b4385", "_uuid": "bf7f8b89a1bcac01eab2a6d2b99f4ba13e16186f"}}, {"source": ["I'm going to be posting a new strategy based on tokenization and sparse matrices. If I can fit it here, I will. If not, it'll be in a new kernel."], "cell_type": "markdown", "metadata": {"_cell_guid": "935f6eb6-430b-4e3e-b974-851bbe0b7039", "_uuid": "ee174e418d3deed547ca9e5c47251652be54bac5"}}, {"outputs": [], "source": ["write.csv(submission,'kernelSub.csv',row.names=FALSE)"], "execution_count": null, "cell_type": "code", "metadata": {"_cell_guid": "57130cac-f099-4a94-a1ac-12dfd6cff464", "_uuid": "d10291ab6e1915595cde8603689fac114257810c", "_kg_hide-input": true, "_kg_hide-output": true}}], "nbformat_minor": 1, "nbformat": 4, "metadata": {"kernelspec": {"name": "ir", "language": "R", "display_name": "R"}, "language_info": {"file_extension": ".r", "mimetype": "text/x-r-source", "name": "R", "codemirror_mode": "r", "version": "3.4.2", "pygments_lexer": "r"}}}