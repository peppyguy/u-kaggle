{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ded05e5c-da8c-b374-604e-3f11f13c53c4"
      },
      "source": [
        "Hi, Kagglers!\n",
        "\n",
        "Hereafter I will try to reveal some basics about Instacart dataset <br>**by conducting an exploratory data analysis of given Dataset**\n",
        "\n",
        "**Brief description**\n",
        "\n",
        "The Dataset is an anonymized sample of over 3,000,000 grocery orders from more than 200,000 Instacart users. \n",
        "<br>The goal of a competition is to predict which previously purchased products will be in a user\u2019s next order. \n",
        "\n",
        "### Stay tuned, this notebook will be updated on a regular basis\n",
        "**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "dca36dbb-72e2-60c4-f2a3-6e09dd9f8d63"
      },
      "source": [
        "## Load Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "193fc41c-ec35-3975-5ae0-082fb2506abb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # dataframes\n",
        "import numpy as np # algebra & calculus\n",
        "import nltk # text preprocessing & manipulation\n",
        "# from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import seaborn as sns # plotting\n",
        "\n",
        "from functools import partial # to reduce df memory consumption by applying to_numeric\n",
        "\n",
        "color = sns.color_palette() # adjusting plotting style\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # silence annoying warnings\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "3de79f99-7f48-9743-c3e0-a4846170edee"
      },
      "source": [
        "## Datasets ER-Model (<a href=\"https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/33128#183176\">See this discussion</a>)\n",
        "![ER-Model][1]\n",
        "## Load Datasets\n",
        "### Descriptive datasets\n",
        "\n",
        "\n",
        "  [1]: https://kaggle2.blob.core.windows.net/forum-message-attachments/183176/6539/instacartFiles.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "498b354b-0b0d-4a8e-3bb7-969100366f71"
      },
      "outputs": [],
      "source": [
        "# aisles\n",
        "aisles = pd.read_csv('../input/aisles.csv', engine='c')\n",
        "print('Total aisles: {}'.format(aisles.shape[0]))\n",
        "aisles.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "990399e9-752b-fa80-4dff-a87cb6da85b1"
      },
      "outputs": [],
      "source": [
        "# departments\n",
        "departments = pd.read_csv('../input/departments.csv', engine='c')\n",
        "print('Total departments: {}'.format(departments.shape[0]))\n",
        "departments.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "987a81f3-f357-1033-4de0-0e8d7bfb76c3"
      },
      "outputs": [],
      "source": [
        "# products\n",
        "products = pd.read_csv('../input/products.csv', engine='c')\n",
        "print('Total products: {}'.format(products.shape[0]))\n",
        "products.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fa3a57da-15ea-a0bf-2d4b-d822a6e3c97a"
      },
      "source": [
        "### Combine it all together into 1 DataFrame \"GOODS\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "66eee8bf-04e5-37a8-0c02-678aa6022326"
      },
      "outputs": [],
      "source": [
        "# combine aisles, departments and products (left joined to products)\n",
        "goods = pd.merge(left=pd.merge(left=products, right=departments, how='left'), right=aisles, how='left')\n",
        "# to retain '-' and make product names more \"standard\"\n",
        "goods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n",
        "\n",
        "goods.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d6a6907a-5d90-b274-ef64-8ff17e2c30c8"
      },
      "outputs": [],
      "source": [
        "# basic group info (departments)\n",
        "plt.figure(figsize=(12, 5))\n",
        "goods.groupby(['department']).count()['product_id'].copy()\\\n",
        ".sort_values(ascending=False).plot(kind='bar', \n",
        "                                   #figsize=(12, 5), \n",
        "                                   title='Departments: Product #')\n",
        "\n",
        "\n",
        "# basic group info (top-x aisles)\n",
        "top_aisles_cnt = 15\n",
        "plt.figure(figsize=(12, 5))\n",
        "goods.groupby(['aisle']).count()['product_id']\\\n",
        ".sort_values(ascending=False)[:top_aisles_cnt].plot(kind='bar', \n",
        "                                   #figsize=(12, 5), \n",
        "                                   title='Aisles: Product #')\n",
        "\n",
        "# plot departments volume, split by aisles\n",
        "f, axarr = plt.subplots(6, 4, figsize=(12, 30))\n",
        "for i,e in enumerate(departments.department.sort_values(ascending=True)):\n",
        "    axarr[i//4, i%4].set_title('Dep: {}'.format(e))\n",
        "    goods[goods.department==e].groupby(['aisle']).count()['product_id']\\\n",
        "    .sort_values(ascending=False).plot(kind='bar', ax=axarr[i//4, i%4])\n",
        "f.subplots_adjust(hspace=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "fbe3e1b2-823e-a708-e0cf-efedbcf4794e"
      },
      "source": [
        "### To my regret, Python lacks good treemap packages - <br>That's why I embedded a link to gorgeous R visualizations from <a href=\"https://www.kaggle.com/philippsp/first-exploratory-analysis\">This Kernel</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6dc99b12-57f1-5335-59aa-22260f3cc9b7"
      },
      "source": [
        "### Visualizing the Product Portfolio\n",
        "\n",
        "**How are aisles organized within departments?**\n",
        "![within_departments][1]\n",
        "\n",
        "  [1]: https://www.kaggle.io/svf/1167770/471bab8e222cd6e1e823d080a6980e8a/__results___files/figure-html/unnamed-chunk-24-1.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "298a2d12-1a84-f869-7d5f-bf54c4b4876a"
      },
      "source": [
        "**How many unique products are offered in each department/aisle?**\n",
        "![unique_products][1]\n",
        "\n",
        "  [1]: https://www.kaggle.io/svf/1167770/471bab8e222cd6e1e823d080a6980e8a/__results___files/figure-html/unnamed-chunk-25-1.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c092bbb4-8eb7-dfd0-073d-23ad8c5b34f1"
      },
      "source": [
        "**How often are products from the department/aisle sold?**\n",
        "\n",
        "![sold_amount][1]\n",
        "\n",
        "  [1]: https://www.kaggle.io/svf/1167770/471bab8e222cd6e1e823d080a6980e8a/__results___files/figure-html/unnamed-chunk-26-1.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "560376e8-b7a7-3fd8-0df0-2434f36e4f6e"
      },
      "source": [
        "## Main Datasets (orders + order details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "a5f610b0-2845-b219-922f-f96cc7170d8c"
      },
      "outputs": [],
      "source": [
        "# load datasets\n",
        "\n",
        "# train dataset\n",
        "op_train = pd.read_csv('../input/order_products__train.csv', engine='c', \n",
        "                       dtype={'order_id': np.int32, 'product_id': np.int32, \n",
        "                              'add_to_cart_order': np.int16, 'reordered': np.int8})\n",
        "print('Total ordered products(train): {}'.format(op_train.shape[0]))\n",
        "op_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9cbe9f73-ff8f-9324-3f1e-60e24eefb03d"
      },
      "outputs": [],
      "source": [
        "# test dataset (submission)\n",
        "test = pd.read_csv('../input/sample_submission.csv', engine='c')\n",
        "print('Total orders(test): {}'.format(op_train.shape[0]))\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5f22fc6a-2f9b-b5c8-0687-b37231422f8a"
      },
      "outputs": [],
      "source": [
        "# prior dataset\n",
        "op_prior = pd.read_csv('../input/order_products__prior.csv', engine='c', \n",
        "                       dtype={'order_id': np.int32, 'product_id': np.int32, \n",
        "                              'add_to_cart_order': np.int16, 'reordered': np.int8})\n",
        "print('Total ordered products(prior): {}'.format(op_prior.shape[0]))\n",
        "op_prior.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7838a0d6-0f0b-b318-7134-6fe35f45d167"
      },
      "outputs": [],
      "source": [
        "# orders\n",
        "orders = pd.read_csv('../input/orders.csv', engine='c', dtype={'order_id': np.int32, \n",
        "                                                           'user_id': np.int32, \n",
        "                                                           'order_number': np.int32, \n",
        "                                                           'order_dow': np.int8, \n",
        "                                                           'order_hour_of_day': np.int8, \n",
        "                                                           'days_since_prior_order': np.float16})\n",
        "print('Total orders: {}'.format(orders.shape[0]))\n",
        "orders.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "737ba40d-8bf7-597b-4619-e616099515dc"
      },
      "source": [
        "### Combine (orders, order details, product hierarchy) into 1 dataframe order_details \n",
        "**(be careful, high memory consumption, about 3GB RAM itself)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4f14c566-ecf8-79c4-c3bb-4e0cf2d46081"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "# merge train and prior together iteratively, to fit into 8GB kernel RAM\n",
        "# split df indexes into parts\n",
        "indexes = np.linspace(0, len(op_prior), num=10, dtype=np.int32)\n",
        "\n",
        "# initialize it with train dataset\n",
        "order_details = pd.merge(\n",
        "                left=op_train,\n",
        "                 right=orders, \n",
        "                 how='left', \n",
        "                 on='order_id'\n",
        "        ).apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
        "\n",
        "# add order hierarchy\n",
        "order_details = pd.merge(\n",
        "                left=order_details,\n",
        "                right=goods[['product_id', \n",
        "                             'aisle_id', \n",
        "                             'department_id']].apply(partial(pd.to_numeric, \n",
        "                                                             errors='ignore', \n",
        "                                                             downcast='integer')),\n",
        "                how='left',\n",
        "                on='product_id'\n",
        ")\n",
        "\n",
        "print(order_details.shape, op_train.shape)\n",
        "\n",
        "# delete (redundant now) dataframes\n",
        "del op_train\n",
        "\n",
        "order_details.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "d51eec70-0643-24a2-7127-72acbe12bb15"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# update by small portions\n",
        "for i in range(len(indexes)-1):\n",
        "    order_details = pd.concat(\n",
        "        [   \n",
        "            order_details,\n",
        "            pd.merge(left=pd.merge(\n",
        "                            left=op_prior.iloc[indexes[i]:indexes[i+1], :],\n",
        "                            right=goods[[\n",
        "                                'product_id', \n",
        "                                 'aisle_id', \n",
        "                                 'department_id'\n",
        "                            ]].apply(partial(pd.to_numeric, \n",
        "                                             errors='ignore', \n",
        "                                             downcast='integer')),\n",
        "                            how='left',\n",
        "                            on='product_id'\n",
        "                            ),\n",
        "                     right=orders, \n",
        "                     how='left', \n",
        "                     on='order_id'\n",
        "                ) #.apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
        "        ]\n",
        "    )\n",
        "        \n",
        "print('Datafame length: {}'.format(order_details.shape[0]))\n",
        "print('Memory consumption: {:.2f} Mb'.format(sum(order_details.memory_usage(index=True, \n",
        "                                                                         deep=True) / 2**20)))\n",
        "# check dtypes to see if we use memory effectively\n",
        "print(order_details.dtypes)\n",
        "\n",
        "# make sure we didn't forget to retain test dataset :D\n",
        "test_orders = orders[orders.eval_set == 'test']\n",
        "\n",
        "# delete (redundant now) dataframes\n",
        "del op_prior, orders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "9a73df79-428e-2bbf-e5c5-b37fafe9bf12"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# unique orders, product_ordered, users\n",
        "print('Unique users: {}'.format(len(set(order_details.user_id))))\n",
        "print('Unique orders: {}'.format(len(set(order_details.order_id))))\n",
        "print('Unique products bought: {}/{}'.format(len(set(order_details.product_id)), len(goods)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "3d11aace-8209-fd18-6e9d-682afd388ee3"
      },
      "outputs": [],
      "source": [
        "# unordered products\n",
        "unordered = goods[goods.product_id.isin(list(set(goods.product_id) - set(order_details.product_id)))]\n",
        "print('\"Lonesome\" products cnt: {}/{}'.format(unordered.shape[0], len(goods)))\n",
        "unordered.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "c1978da9-416b-6e57-18f3-ec24b6f60d2d"
      },
      "source": [
        "### Popular Products (Bestsellers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "78fdea7d-3a4c-a489-848e-86fce2a091ce"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# popular products (total set, not only train)\n",
        "top = 15\n",
        "top_products = pd.merge(\n",
        "    # to see train: \n",
        "    # left=pd.DataFrame(order_details[order_details.eval_set == 'train'].groupby(['product_id'])['order_id']\\\n",
        "    left=pd.DataFrame(order_details.groupby(['product_id'])['order_id']\\\n",
        "    .apply(lambda x: len(x.unique())).sort_values(ascending=False)[:top].reset_index('product_id')),\n",
        "    right=goods,\n",
        "    how='left')\n",
        "\n",
        "f, ax = plt.subplots(figsize=(12, 10))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(top_products.product_name, top_products.order_id)\n",
        "plt.ylabel('Number of Orders, Containing This Product')\n",
        "plt.xlabel('Product Name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ad0f3b47-fe80-77c0-cb82-6b6a8d1097ff"
      },
      "source": [
        "### Most \"Frequently\" Bought Products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "325a1971-253c-9f89-55af-e0d66d8f3817"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# most \"frequently\" bought products (total set, not only train)\n",
        "# most \"frequently\" ~ time between orders (within selected customer's orders), \n",
        "# that contain that product, is the least \n",
        "#(products, which were bought by more than 100 customers, to omit outliers)\n",
        "top = 15\n",
        "customer_limit = 100\n",
        "\n",
        "temp = order_details.groupby(['product_id'])[['days_since_prior_order', 'user_id']]\\\n",
        ".aggregate({'days_since_prior_order': np.mean, 'user_id': len}).reset_index()\n",
        "\n",
        "frequent_products = pd.merge(\n",
        "    left=pd.DataFrame(temp[temp.user_id > customer_limit].sort_values(['days_since_prior_order'], \n",
        "                                                                      ascending=True)[:top]),\n",
        "    right=goods,\n",
        "    how='left')\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(frequent_products.product_name, frequent_products.days_since_prior_order)\n",
        "plt.ylabel('Average Days Between Orders, Containing This Product')\n",
        "plt.xlabel('Product Name')\n",
        "\n",
        "del temp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "bdc56d8b-c922-b9cd-cee6-0602afc1ea36"
      },
      "source": [
        "### Orders, Split by Product Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "da381b44-253f-fa70-f47d-45dd1edbbf2b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ord_by_prods = order_details.groupby(\"order_id\")[\"add_to_cart_order\"]\\\n",
        ".aggregate(np.max).reset_index()['add_to_cart_order'].value_counts()\n",
        "\n",
        "print('Most common order contains: {} products'.format(\n",
        "    ord_by_prods[ord_by_prods.values == ord_by_prods.max()].index.values[0]))\n",
        "\n",
        "# plot it\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(ord_by_prods.index, ord_by_prods.values)\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xlabel('Number of Products in Order')\n",
        "plt.xlim([0, 50])\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d13e0fb6-7453-610a-190b-8c2524852937"
      },
      "source": [
        "### Products with the Highest Reorder Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "15208d36-787d-7bd5-4d1e-931993c87912"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# consider products, purchased in more than X orders\n",
        "order_limit = 100\n",
        "top = 15\n",
        "\n",
        "mo_products = order_details.groupby('product_id')[['reordered', 'order_id']]\\\n",
        ".aggregate({'reordered': sum, 'order_id': len}).reset_index()\n",
        "mo_products.columns = ['product_id', 'reordered', 'order_cnt']\n",
        "\n",
        "mo_products['reorder_rate'] = mo_products['reordered'] / mo_products['order_cnt']\n",
        "mo_products = mo_products[mo_products.order_cnt > order_limit].sort_values(['reorder_rate'], \n",
        "                                                                           ascending=False)[:top]\n",
        "\n",
        "mo_products = pd.merge(\n",
        "    left=mo_products,\n",
        "    right=goods,\n",
        "    on='product_id')\n",
        "mo_products\n",
        "\n",
        "# plot it\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(mo_products.product_name, mo_products.reorder_rate*100)\n",
        "plt.ylabel('Reorder Rate, %')\n",
        "plt.xlabel('Product Name')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "905a2a74-6908-dc32-6f49-2c1eef852850"
      },
      "source": [
        "### Orders, Split by Day of Week"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "7dbe5278-58d6-65e4-1143-ae5180b935d5"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "order_details.groupby('order_dow')['order_id'].apply(lambda x: len(x.unique())).plot(kind='bar')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylabel('Order Count')\n",
        "plt.xlabel('Day of Week (coded)')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "ee67d014-ecef-feeb-0ffd-ce9d3d6b5238"
      },
      "source": [
        "### Orders, Split by Hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "c618f9be-849a-b25b-0243-47c4f11643ed"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "order_details.groupby('order_hour_of_day')['order_id'].apply(lambda x: \n",
        "                                                             len(x.unique())).plot(kind='bar')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylabel('Order Count')\n",
        "plt.xlabel('Hour of a Day (0-23)')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "cd427813-4840-477f-bfc7-3282ddb8df28"
      },
      "source": [
        "### Most Popular Departments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "dc31af5c-df2a-17bc-987f-cad9ee023cc0"
      },
      "outputs": [],
      "source": [
        "pop_dep = pd.merge(\n",
        "    left=order_details.groupby('department_id')['order_id'].apply(lambda x: \n",
        "                                                                  len(x.unique())).reset_index(),\n",
        "    right=goods[['department_id', 'department']].drop_duplicates(),\n",
        "    how='inner',\n",
        "    on='department_id'\n",
        ").sort_values(['order_id'], ascending=False)\n",
        "\n",
        "# plot it\n",
        "total_orders = len(set(order_details.order_id))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(pop_dep.department, pop_dep.order_id / total_orders * 100)\n",
        "plt.ylabel('% of Orders, Containing Products from Department, #')\n",
        "plt.xlabel('Department Name')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1ca155f3-3cf9-8492-0336-5b8a6a2489b2"
      },
      "source": [
        "### Most Popular Aisles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "8d06ffd3-b22c-5360-72d8-58d786e2b055"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "pop_ais = pd.merge(\n",
        "    left=order_details.groupby('aisle_id')['order_id'].apply(lambda x: len(x.unique())).reset_index(),\n",
        "    right=goods[['aisle_id', 'aisle']].drop_duplicates(),\n",
        "    how='inner',\n",
        "    on='aisle_id'\n",
        ").sort_values(['order_id'], ascending=False)[:top]\n",
        "\n",
        "# plot it\n",
        "total_orders = len(set(order_details.order_id))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.xticks(rotation='vertical')\n",
        "sns.barplot(pop_ais.aisle, pop_ais.order_id / total_orders * 100)\n",
        "plt.ylabel('% of Orders, Containing Products from Aisle, #')\n",
        "plt.xlabel('Aisle Name')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "da8e52c6-eb3d-7e5f-6186-a8ba4f933ba9"
      },
      "source": [
        "### Distribution of Order Count per User"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "0a45ae07-1051-e351-ba83-903113b3812b"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "ocpu = order_details.groupby('user_id')['order_id']\\\n",
        ".apply(lambda x: len(x.unique())).reset_index().groupby('order_id').aggregate(\"count\")\n",
        "\n",
        "print('Most common user made: {} purchases'.format(\n",
        "    ocpu[ocpu.user_id == ocpu.user_id.max()].index.values[0]))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(ocpu.index, ocpu.user_id)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylabel('User Count')\n",
        "plt.xlabel('Number of Orders, made by a User')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "0dff3460-2fb8-61ac-7547-a45f14b14579"
      },
      "source": [
        "### Days to Next Order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "4b571b54-98d2-e134-77e8-d31fbc607383"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "dtno = order_details.dropna(axis=0, \n",
        "                     subset=['days_since_prior_order']).groupby('order_id')['days_since_prior_order']\\\n",
        ".aggregate(\"mean\").reset_index().apply(np.int32).groupby('days_since_prior_order').aggregate(\"count\")\n",
        "\n",
        "print('Most frequently next orders are made once in: {} days'.format(\n",
        "    dtno[dtno.order_id == dtno.order_id.max()].index.values[0]))\n",
        "\n",
        "print('We clearly see monthly (>=30) and weekly (7) peaks')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(dtno.index, dtno.order_id)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylabel('Order Count')\n",
        "plt.xlabel('Days Passed Since Last Order')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6d25f637-0241-37b4-aa94-22a41fc43d20"
      },
      "source": [
        "### Time of last order vs. probability of reorder (also inspired by <a href=\"https://www.kaggle.com/philippsp/first-exploratory-analysis\">This Kernel</a>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "65ae46ac-bec2-8636-8df1-2529c440983d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "por = order_details.dropna(axis=0, subset=['days_since_prior_order'])\\\n",
        ".groupby('days_since_prior_order')['reordered'].aggregate(\"mean\").reset_index()\n",
        "\n",
        "print('We can see that longer lags leads to lowered probability (new items),\\\n",
        "\\nwhile same day orders tends to have more overlapped product list')\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(por.days_since_prior_order, por.reordered*100)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.ylabel('Probability of Reorder, %')\n",
        "plt.xlabel('Days Passed Since Last Order')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "8e72f508-4d27-ee59-3bdf-40e6831af45b"
      },
      "source": [
        "### To Organic or not to Organic: That is the Question (also inspired by <a href=\"https://www.kaggle.com/philippsp/first-exploratory-analysis\">This Kernel</a>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "5bb6833a-ed40-7f86-0cb7-cf03bc30a414"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# share of organic/non-organic products and correspondent orders count\n",
        "org = pd.merge(\n",
        "    left=order_details[['product_id', 'order_id']],\n",
        "    right=goods[['product_id', 'product_name']],\n",
        "    how='left',\n",
        "    on='product_id')\n",
        "\n",
        "org['organic'] = org.product_name.str.contains('organic').astype(np.int8)\n",
        "org = org.groupby('order_id')['organic'].aggregate(\"max\").value_counts()\n",
        "\n",
        "# plot it\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(org.index, org / org.sum() * 100)\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.xlabel('Order Contains Organics (Boolean)')\n",
        "plt.ylabel('% of Orders')\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "1cc9ab7c-d426-c6ef-64d0-4b73f0290d41"
      },
      "source": [
        "### To be continued... \n",
        "\n",
        "**(TODO: test set explorations, purchase ordering, different visualizations etc.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "6dbdeb0b-b945-7ebf-937b-5ff77bb6676a"
      },
      "source": [
        "### Stay tuned, this notebook will be updated on a regular basis\n",
        "**P.s. Upvotes and comments would let me update it faster and in a more smart way :)**"
      ]
    }
  ],
  "metadata": {
    "_change_revision": 0,
    "_is_fork": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}