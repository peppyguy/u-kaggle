{"cells":[{"metadata":{"_uuid":"a1aa7d0aacd7c461dad41a03c86edc871a584c81"},"cell_type":"markdown","source":"# **Analysis of Bakery Transactions**\n\n### Hello, In this kernel I try to find best  item combinations. In the next update I will add RNN for predict coffee sales per day.\n<a id=\"0\"></a> <br>\n#### **Content:**\n1. [Load and Exploring the Data](#1)\n2. [Cleaning the Data](#2)\n3. [Find most popular Items](#3)\n4. [Find the best item combinations with coffee](#4)\n"},{"metadata":{"_uuid":"cbf8f15cc20f8341994255a9a4dfe700a3335b72"},"cell_type":"markdown","source":"<a id=\"1\"></a> <br>\n## 1-Exploring the Data [^](#0)\nThis dataset contains more than 6000 transactions and the date and time data's of these transactions. There is, of course, the item list that sold. So the list of problems is here that we can maybe find a solution.\n* 1 - Maybe we can find the most popular item combination bought by people.\n* 2 - We have the date information so maybe we can use RNN to predict the item sales per day.\n* 3 - I will add more problem here if I found.\n\nOkay let's start with load the data."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Import libraries and load data with pandas as a dataframe\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\ndata = pd.read_csv('../input/BreadBasket_DMS.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"99e7463571f4df21f8d0ebf5fed094e62218db23"},"cell_type":"code","source":"# .info() is good for first look.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d82c5b153a69f7b03e3b4d572faa8a2ac9bc00fc"},"cell_type":"markdown","source":"We have 4 column."},{"metadata":{"trusted":true,"_uuid":"d264e6d07c21f96bd50f89c64d35ca1fb1ef7c50"},"cell_type":"code","source":"# .head() and .tail() will show first and last 10 items in dataframe.\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"31f1f6a5811d57615da995f55144e57a3baa50ba"},"cell_type":"code","source":"data.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae38090c96f5f13253756cfe951f6eb1f70b9956"},"cell_type":"markdown","source":"We have 21293 entries in nearly 6-month time interval. 9684 are at a different time.\nSo let's start with to find unique items in our data."},{"metadata":{"trusted":true,"_uuid":"fec0b27cadf5d3fd09cfa84581461b27e0ada7b7"},"cell_type":"code","source":"# After use .unique() we use len() to find how many unique items that we have.\nitems_unique_list = data[\"Item\"].unique()\nlen(items_unique_list)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ee862859a1dc3fb5fe4c6f03571ba9db6cc8539"},"cell_type":"markdown","source":"We can clearly see there are 95 items has been found in dataset however there can be some *NaN* values int data that we need to clear. To do this we create a basic *NaN* word list and then clear the data."},{"metadata":{"_uuid":"6cb464cd6ec55c2c5c89e76cc5b0bee46e4d2c06"},"cell_type":"markdown","source":"<a id=\"2\"></a> <br>\n## 2-Cleaning the Data [^](#0)\nOur data include some missing values. I want to use .dropna() function to drop them but their type is object(string) and they are not *NaN* they are *None*. So I found different solution to get rid of this problem. I construct a word list of possible words for missing values. Then check my data with this list. "},{"metadata":{"trusted":true,"_uuid":"3fbe382d43560436d8e1e669afef94270f486d4c"},"cell_type":"code","source":"# Here my little list :D\nword_list = [\"NaN\", \"-\", \"nan\", \"NAN\", \"None\", \"NONE\", \"none\", \" \", \"_\", \".\"]\n\n# I use the list comprehension to make this code smaller.\nfound_words = [word_list[i] for i, c in enumerate([w in items_unique_list for w in word_list]) if c == True]\n\n# Found word types is 1 so only one of thing in my list founded in our data (\"NONE\")\nlen(found_words)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de18f0a7a20298a133356e0d04dce45f545b8cb3"},"cell_type":"markdown","source":" So how many of them are \"NONE\" ?"},{"metadata":{"trusted":true,"_uuid":"394ee09ca86d0eaec99b900f46a9a142a8b64260"},"cell_type":"code","source":"len(data[data[\"Item\"] == \"NONE\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4025f58fbb62ccddd62b4e3964df43ed136177c9"},"cell_type":"code","source":"# Data include 786 missing values let's drop them\nfor f in found_words:\n    data = data.replace(to_replace=f, value=np.nan).dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbf9b091b1b7e1535d9ce4d3310607ea56816561"},"cell_type":"code","source":"# Let's look again unique Item list it must be 94.\nitems_unique_list = data[\"Item\"].unique()\nlen(items_unique_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fb25d77278f568cd8e27f77f7826384a5e160e3"},"cell_type":"markdown","source":"Data is cleared and now the item number is 94. Let's look at the top items that bought most. We will need some visualization.\nI am going to use plotly beacuse I love it <3"},{"metadata":{"_uuid":"cc90c95a98628560bd57729465704b26441a18cb"},"cell_type":"markdown","source":"<a id=\"3\"></a> <br>\n## 3-Find most popular Items  [^](#0)\nStart with import some libraries then we will do some data transform for prepare data for visualizing."},{"metadata":{"_uuid":"a1d24fcddd33e06920a0e0dbc90797b1edd7a2a6","trusted":true},"cell_type":"code","source":"from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\nimport plotly\n\nplotly.offline.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a03659268e4e0a8cc615e0628fd1a48487f16479"},"cell_type":"markdown","source":"Let's get the top ten most bought items. Then sum and add the other items as \"Others\" in our top list."},{"metadata":{"trusted":true,"_uuid":"15ab91138c9277045425ac3cfb46b3071fea2985"},"cell_type":"code","source":"# Get first 10 items from list\nhot_items = data.Item.value_counts()[:10]\n\n# Find and sum the remaining items and label it as \"Others\".\nother_items_count = data.Item.count() - hot_items.sum()\n\n# Add two of them in one series.\nitem_list = hot_items.append(pd.Series([other_items_count], index=[\"Others\"]))\n\n# Here the item list. Yes I like coffee too.\nitem_list","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e9e808ecd947824fff3c8832664e80f438ad21f9"},"cell_type":"markdown","source":"Okay, finally we can start to render some graphs."},{"metadata":{"trusted":true,"_uuid":"6f058b067b5a106957f8968a066f466b9e9987d4"},"cell_type":"code","source":"# Values include the list you see above.\nvalues = item_list.tolist()\n# Labels include top ten items name.\nlabels = item_list.index.values.tolist()\n\n# Pie is suitable I think\nfig = {\n  \"data\": [\n    {\n      \"values\": values,\n      \"labels\": labels,\n      \"domain\": {\"x\": [0, .5]},\n      \"name\": \"Top 10 Items\",\n      \"hoverinfo\":\"label+percent+name\",\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Top 10 Most Popular Items\",\n    }\n}\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc5ba8e0202bacbb879b85428ac9cb997b954776"},"cell_type":"markdown","source":"Yes, coffee is the most popular and the bread is second. So let's try to find our first problems answer. \n\n**Do people like them two as a combine or separately?**\n<a id=\"4\"></a> <br>\n## 4-Find the best item combinations with coffee [^](#0)\n\nTo find this out firstly we need to get only transactions that include coffee."},{"metadata":{"trusted":true,"_uuid":"6310c416a5db4d9494d62d4da234be96603bc67e"},"cell_type":"code","source":"# We get all transaction numbers which contain coffee.\ncoffee_transaction_list = data[data['Item'] == \"Coffee\"][\"Transaction\"].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68df089316cbb12ad091c3216e4c178b3196103c"},"cell_type":"code","source":"# Then copy our data to protect it.\ndata_copy = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8138a34333381a7d795012ba82229e19dd98f514"},"cell_type":"code","source":"# And drop all transactions which not contain coffee.\n# Note: Please comment if is there a more efficient way to do this beacuse I think this is not a good way to do this.\nfor i in range(max(data[\"Transaction\"])+1):\n    if i not in coffee_transaction_list:\n        data_copy = data_copy.drop(data_copy[data_copy.Transaction == i].index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"feb45a7d9d6c17f9e45ba8f70c45d47c3d9367ce"},"cell_type":"code","source":"# Lastly, we get our precious dataframe\ndata_copy.head(15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5d32d298915810d1ee3b157173ca57fb1d31c380"},"cell_type":"markdown","source":"Now we have a data frame which only includes transactions that contain coffee. Let's look at our top items again with this data frame. Then we can compare them."},{"metadata":{"trusted":true,"_uuid":"bb040cb1b197d8052c35806b04b1ee1e06d327b9"},"cell_type":"code","source":"# We get top ten items from two different data frame.\nhot_items_coffe_combine = data_copy.Item.value_counts()[:10]\nhot_items = data.Item.value_counts()[:10]\n\n# We need to drop coffee values beacuse we don't need it when we compare items with coffee or without coffee\nhot_items_coffe_combine = hot_items_coffe_combine.drop(labels=[\"Coffee\"])\nhot_items = hot_items.drop(labels=[\"Coffee\"])\n\n# Labels are Item names\nlabels = hot_items_coffe_combine.index.values.tolist()\n\n# And values are just values :/ \nvalues_coffe_combine = hot_items_coffe_combine.tolist()\nvalues = hot_items.tolist()\n\n# First time when I wrote this kernel I made a critical mistake.\n# We need to subtract values_coffe_combine from values to get values_without_coffee.\n# I forgot to do this step.\nvalues_without_coffee = [values[i]-v for i,v in enumerate(values_coffe_combine)]\n\ndf = pd.DataFrame({'with_coffee':values_coffe_combine, 'without_coffee':values_without_coffee})\ndf\n\n# We have 9 items (The coffee is dropped)\n# Bread           \n# Tea             \n# Cake            \n# Pastry          \n# Sandwich        \n# Medialuna       \n# Hot chocolate   \n# Cookies         \n# Brownie ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"799c7fc90f8bbda52b1d46bbb2d20a4cf6dc810e"},"cell_type":"code","source":"# To plot a graph we transform it to list\nvalues_list = df.values.tolist()\n\n# We added ratio (with_coffee / without_coffee) to all labels\nfor index, value in enumerate(values_list):\n    labels[index] = labels[index] + \"  %{:.2f}\".format(value[0] / value[1])\n\n# Here our values\nlabels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"07628c3ffb7bbab8b1e0432a23a0be7fdd975eef"},"cell_type":"markdown","source":"This graph code is too long I know but this is the best graph for this job I think."},{"metadata":{"trusted":true,"_uuid":"63529babc2e7cf25fe64b9ea0dd7161ffbc0aa12"},"cell_type":"code","source":"import plotly.plotly as py\nimport plotly.graph_objs as go\n\ntop_labels = [\"Bought With Coffee\", \"Bought Without Coffee\"]\n\ncolors = ['rgba(38, 24, 74, 0.8)', 'rgba(190, 192, 213, 1)']\n\nx_data = values_list\n\ny_data = labels\n\ntraces = []\n\nfor i in range(0, len(x_data[0])):\n    for xd, yd in zip(x_data, y_data):\n        traces.append(go.Bar(\n            x=[xd[i]],\n            y=[yd],\n            orientation='h',\n            marker=dict(\n                color=colors[i],\n                line=dict(\n                        color='rgb(248, 248, 249)',\n                        width=1)\n            )\n        ))\n\nlayout = go.Layout(\n    xaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=False,\n        zeroline=False,\n        domain=[0.15, 1]\n    ),\n    yaxis=dict(\n        showgrid=False,\n        showline=False,\n        showticklabels=False,\n        zeroline=False,\n    ),\n    barmode='stack',\n    title='Sales Information of Top Ten Items With/Without Coffee ',\n    paper_bgcolor='rgb(248, 248, 248)',\n    plot_bgcolor='rgb(248, 248, 255)',\n    margin=dict(\n        l=120,\n        r=10,\n        t=140,\n        b=80\n    ),\n    showlegend=False,\n)\n\nannotations = []\n\nfor yd, xd in zip(y_data, x_data):\n    # labeling the y-axis\n    annotations.append(dict(xref='paper', yref='y',\n                            x=0.14, y=yd,\n                            xanchor='right',\n                            text=str(yd),\n                            font=dict(family='Arial', size=14,\n                                      color='rgb(67, 67, 67)'),\n                            showarrow=False, align='right'))\n    # labeling the first percentage of each bar (x_axis)\n    annotations.append(dict(xref='x', yref='y',\n                            x=xd[0] / 2, y=yd,\n                            text=str(xd[0]),\n                            font=dict(family='Arial', size=14,\n                                      color='rgb(248, 248, 255)'),\n                            showarrow=False))\n    # labeling the first Likert scale (on the top)\n    if yd == y_data[-1]:\n        annotations.append(dict(xref='x', yref='paper',\n                                x=xd[0] / 2, y=1.1,\n                                text=top_labels[0],\n                                font=dict(family='Arial', size=16,\n                                          color='rgba(38, 24, 74, 0.8)'),\n                                showarrow=False))\n    space = xd[0]\n    for i in range(1, len(xd)):\n            # labeling the rest of percentages for each bar (x_axis)\n            annotations.append(dict(xref='x', yref='y',\n                                    x=space + (xd[i]/2), y=yd, \n                                    text=str(xd[i]),\n                                    font=dict(family='Arial', size=14,\n                                              color='rgb(248, 248, 255)'),\n                                    showarrow=False))\n            # labeling the Likert scale\n            if yd == y_data[-1]:\n                annotations.append(dict(xref='x', yref='paper',\n                                        x=space + (xd[i]/0.2), y=1.1,\n                                        text=top_labels[i],\n                                        font=dict(family='Arial', size=16,\n                                                  color='rgba(190, 192, 213, 1)'),\n                                        showarrow=False))\n            space += xd[i]\n\nlayout['annotations'] = annotations\n\nfig = go.Figure(data=traces, layout=layout)\niplot(fig, filename='bar-colorscale')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1a5f8a311776c60fcd03b12074ca1a5c46458615"},"cell_type":"markdown","source":"We can understand from this graph that people don't like bread + coffee combine. But coffee + toast seems very liked. The medialuna + coffee combine is our second popular combine. This bakery maybe make some discounts for this combines : )"},{"metadata":{"_uuid":"3f32ac4376b2abbf6b34b224e03866c7fa37ceee"},"cell_type":"markdown","source":"So here we are this is the end for now : ) . I want to try RNN on this in my next update. Please comment for any suggestion. Thank you."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}