{"cells":[{"metadata":{"_uuid":"f59cf1e3df49e9500c44018a199fc44ebac31c59"},"cell_type":"markdown","source":"# This kernel show how to extract image features using keras and low memory use."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"0b810893-251d-44da-baa7-dc3eb1bff21d","_uuid":"5cf204be84b2a4955fd1058b85d31d227aa66130","trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications import xception\nfrom keras.applications import inception_v3","execution_count":2,"outputs":[]},{"metadata":{"_cell_guid":"d00af98a-62dd-497e-9af1-3a46b10ff06f","_uuid":"7d640d781c0883836c807b4afbe68510e2503ce2"},"cell_type":"markdown","source":"Thanks https://www.kaggle.com/gaborfodor/keras-pretrained-models"},{"metadata":{"_cell_guid":"8bb562b1-0d4e-41c0-9453-949d466830d5","_uuid":"cc6b44db28f8c73e01069bb8f446e95919911707","trusted":true},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"ce693a5e-ab57-486e-bc92-a4cf1d6924cc","collapsed":true,"_uuid":"02c104ba198df0898ddfc71fbbaacdce58f733df","trusted":true},"cell_type":"code","source":"from os import listdir, makedirs\nfrom os.path import join, exists, expanduser","execution_count":4,"outputs":[]},{"metadata":{"_cell_guid":"cc54e2ad-314a-4604-9e90-e8052bdfd651","collapsed":true,"_uuid":"c197fd351d229ed45e8cceb2fa5a3d437143ee9c","trusted":true},"cell_type":"code","source":"cache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)","execution_count":5,"outputs":[]},{"metadata":{"_cell_guid":"26a9568a-c0a5-44e3-9234-60bfa5a85b71","collapsed":true,"_uuid":"5b2cc7d8deb9c491c364e672680f1ca15e8ff481","trusted":true},"cell_type":"code","source":"!cp ../input/keras-pretrained-models/*notop* ~/.keras/models/\n!cp ../input/keras-pretrained-models/imagenet_class_index.json ~/.keras/models/\n!cp ../input/keras-pretrained-models/resnet50* ~/.keras/models/","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"e8c49bfc-3282-44ea-80fb-5589108cbbe9","_uuid":"a441e47817082ffc2717266beaf9e57cc82a69ed","trusted":true},"cell_type":"code","source":"!ls ~/.keras/models","execution_count":7,"outputs":[]},{"metadata":{"_cell_guid":"0161c702-bf98-4de7-beeb-9c9dae51688f","_uuid":"9bc2b633d4a9f6b0cb8e32bb4d01b05d4ea74c5d"},"cell_type":"markdown","source":""},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nimport numpy as np\n\nmodel = VGG16(weights='imagenet', include_top=False)\nmodel.summary()","execution_count":8,"outputs":[]},{"metadata":{"_cell_guid":"8b22682b-53b8-4886-9a18-0084e5a94634","_uuid":"826bdd068d8e88b66991b0372ff15b62db64811d","trusted":true},"cell_type":"code","source":"!ls ../input/avito-demand-prediction/","execution_count":9,"outputs":[]},{"metadata":{"_cell_guid":"c35e573d-f96b-419b-bcf7-28663d635f31","collapsed":true,"_uuid":"399f809596b9bb6e89e686167fae6b90cf7ed62f","trusted":true},"cell_type":"code","source":"import zipfile","execution_count":10,"outputs":[]},{"metadata":{"_cell_guid":"558c9481-5acc-4d5d-b63f-24ac468acdbf","collapsed":true,"_uuid":"f109c10832852b8cf812935cdb661aabe08df357","trusted":true},"cell_type":"code","source":"myzip = zipfile.ZipFile('../input/avito-demand-prediction/train_jpg.zip')\nfiles_in_zip = myzip.namelist()\nfor idx, file in enumerate(files_in_zip[:5]):\n    if file.endswith('.jpg'):\n        myzip.extract(file, path=file.split('/')[3])\nmyzip.close()","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"8d570f38-a7c2-4459-bfec-049c077e0c01","_uuid":"baf4d8cc6392a66bd5cc72cd1bf333ed5be6b5a2","trusted":true},"cell_type":"code","source":"!ls *.jpg","execution_count":12,"outputs":[]},{"metadata":{"_cell_guid":"98de6b8b-d00b-4241-90df-800a4f294d90","_uuid":"f94bb3cd2fae6f0beb70036deca1ba34dbc16516","trusted":true},"cell_type":"code","source":"!ls 856e74b8c46edcf0c0e23444eab019bfda63687bb70a3481955cc6ab86e39df2.jpg/data/competition_files/train_jpg/","execution_count":13,"outputs":[]},{"metadata":{"_cell_guid":"a3f1005f-ffd6-4e6d-ac68-5a7bbe487723","collapsed":true,"_uuid":"97c6fe13649f8e09200a028a86ff2a3befbc5b03","trusted":true},"cell_type":"code","source":"img_path = './856e74b8c46edcf0c0e23444eab019bfda63687bb70a3481955cc6ab86e39df2.jpg/data/competition_files/train_jpg/856e74b8c46edcf0c0e23444eab019bfda63687bb70a3481955cc6ab86e39df2.jpg'\nimg = image.load_img(img_path, target_size=(224, 224))","execution_count":14,"outputs":[]},{"metadata":{"_cell_guid":"56f474b7-22b1-4c49-9884-e56e5c128bfa","_uuid":"1f42611ab2a4ce4cd91638f769f4c025ca32037b","trusted":true},"cell_type":"code","source":"img","execution_count":15,"outputs":[]},{"metadata":{"_cell_guid":"5ba1c6ed-449c-45b2-adcb-30f887e6363e","collapsed":true,"_uuid":"f91f59920a7b3a17e32bcf22d3add679c8b077d8","trusted":true},"cell_type":"code","source":"x = image.img_to_array(img)  # 3 dims(3, 224, 224)\nx = np.expand_dims(x, axis=0)  # 4 dims(1, 3, 224, 224)\nx = preprocess_input(x)","execution_count":16,"outputs":[]},{"metadata":{"_cell_guid":"a35b90bd-58d3-4a04-bb0b-9bae82c0a504","collapsed":true,"_uuid":"a0cda5c3da0cb66e8b972ead4efda17821eea0f8","trusted":true},"cell_type":"code","source":"features = model.predict(x)","execution_count":17,"outputs":[]},{"metadata":{"_cell_guid":"4231a279-c648-4386-9a58-e6e1cf53b09b","_uuid":"e21a7835e77694021a7e5d45f8e892291102b43d","trusted":true},"cell_type":"code","source":"features.reshape((25088,))","execution_count":18,"outputs":[]},{"metadata":{"_cell_guid":"0e006768-7034-47d4-b16b-a819475b0ac4","_uuid":"8ac3e54eee743489f918eabd2d34ffed757f9b68"},"cell_type":"markdown","source":"25088 dim feature is much bigger to use, you'd better try to use some reduce dims model like **PCA** etc, then you can merge these features to your regression model."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"959756ef66a516423a9dcfa6617cbaf4a666adc5"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}