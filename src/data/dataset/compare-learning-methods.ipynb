{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"Import data"},{"metadata":{"trusted":true,"_uuid":"812ad84cfd5bc58d8e4a7412e2a0bb2a4ce087df"},"cell_type":"code","source":"data = pd.read_csv(\"../input/voice.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f9cb4093853187c26ce8255384881f0b3933703"},"cell_type":"markdown","source":"Review the data"},{"metadata":{"trusted":true,"_uuid":"1e978d8d970920ff4e9d16ca15ac50f49537ad37"},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b0b275abae8c96289bd836c66a0cdc2210292d6"},"cell_type":"markdown","source":"Convert \"male\" to 1, \"female\" to 0"},{"metadata":{"trusted":true,"_uuid":"0585c6566818f8ce2286683f488032b74f1308e2"},"cell_type":"code","source":"data.label = [1 if each == \"male\" else 0 for each in data.label]\ndata.head() # check if binary conversion worked","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"68c662c2a10aefa79581ea03da92b0a29b17d4e6"},"cell_type":"markdown","source":"Extract gender and features data"},{"metadata":{"trusted":true,"_uuid":"185b73548a18a97334b565b7cdca45c70d911f82"},"cell_type":"code","source":"gender = data.label.values\nfeatures = data.drop([\"label\"], axis = 1)\nfeatures = (features-features.min())/(features.max()-features.min()) # normalization","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e54fd1411e1799b6b0a36f3081872e73d0f7facf"},"cell_type":"markdown","source":"Split data for train and test purpose"},{"metadata":{"trusted":true,"_uuid":"3289b11a06890665271064d6c7248f19c3be616a"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(features, gender, test_size = 0.2, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf4338452af53707459bd14e7f28d6bd5565d3ae"},"cell_type":"markdown","source":"Import necessary libraries"},{"metadata":{"trusted":true,"_uuid":"6039e694f913c089bdd1a327ff3bad544f56545f"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nlist_names = []\nlist_accuracy = []","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aeeff5610ecbf918b01501f9bf4489d0fb322ed6"},"cell_type":"markdown","source":"LOGISTIC REGRESSION"},{"metadata":{"trusted":true,"_uuid":"7ffc5b6eff1588af8d0245e10f4dc1cf6ec16f6c"},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nLR_accuracy = lr.score(x_test, y_test)*100\nLR_accuracy = round(LR_accuracy, 3)\n\nprint(\"LR_accuracy is %\", LR_accuracy)\n\nlist_names.append(\"Logistic Regression \")\nlist_accuracy.append(LR_accuracy)\n\n# Confusion Matrix\ny_pred_RF = lr.predict(x_test)\nRF_cm = confusion_matrix(y_test, y_pred_RF)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(RF_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Logistic Regression Classifier')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45fb44c549e9c4fcb9daaa3e6d351429fd787ca0"},"cell_type":"markdown","source":"K-NN CLASSIFIER"},{"metadata":{"trusted":true,"_uuid":"cf288ebe411c50e3bf21a6139b2262f9af162836"},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nKnn = KNeighborsClassifier(n_neighbors = 8)\nKnn.fit(x_train, y_train)\nKnn_accuracy = Knn.score(x_test, y_test)*100\nKnn_accuracy = round(Knn_accuracy, 3)\n\nprint(\"Knn_accuracy is %\", Knn_accuracy)\n\nlist_names.append(\"K-nn \")\nlist_accuracy.append(Knn_accuracy)\n\n# Confusion Matrix\ny_pred_Knn = Knn.predict(x_test)\nKnn_cm = confusion_matrix(y_test, y_pred_Knn)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(Knn_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the K-nn Classifier')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9626ed410bbbd7411d0b3a39af59491c4c17fe0b"},"cell_type":"markdown","source":"SUPPORT VECTOR MACHINE (SVM)"},{"metadata":{"trusted":true,"_uuid":"1ac3852bccbd7bb361bb10f3a4ce53a32194f00d"},"cell_type":"code","source":"from sklearn.svm import SVC\n\nsvm = SVC(random_state=1)\nsvm.fit(x_train, y_train)\nSVM_accuracy = svm.score(x_test, y_test)*100\nSVM_accuracy = round(SVM_accuracy, 3)\n\nprint(\"SVM_accuracy is %\", SVM_accuracy)\n\nlist_names.append(\"SVM \")\nlist_accuracy.append(SVM_accuracy)\n\n# Confusion Matrix\ny_pred_SVM = svm.predict(x_test)\nSVM_cm = confusion_matrix(y_test, y_pred_SVM)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(SVM_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Support Vector Machine (SVM)')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"036b6af998e0731cb9e187ead13361b351926530"},"cell_type":"markdown","source":"NAIVE BAYES"},{"metadata":{"trusted":true,"_uuid":"ea6592fa8c9d726500c42a3b563534a9a7b6b684"},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\n\nnb = GaussianNB()\nnb.fit(x_train, y_train)\nNaiveBayes_acuracy = nb.score(x_test, y_test)*100\nNaiveBayes_acuracy = round(NaiveBayes_acuracy,3)\n\nprint(\"NaiveBayes_acuracy is %\", NaiveBayes_acuracy)\n\nlist_names.append(\"Naive Bayes \")\nlist_accuracy.append(NaiveBayes_acuracy)\n\n# Confusion Matrix\ny_pred_NB = nb.predict(x_test)\nNB_cm = confusion_matrix(y_test, y_pred_NB)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(NB_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Naive Bayes')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7adca4bebd684605e644784be95ddf4a3e30693"},"cell_type":"markdown","source":"DECISION TREE"},{"metadata":{"trusted":true,"_uuid":"016d6c8460f351782c1ef793ce08a3b711aa7fb4"},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(x_train, y_train)\nDecisionTree_accuracy = dt.score(x_test, y_test)*100\nDecisionTree_accuracy = round(DecisionTree_accuracy,3)\n\nprint(\"DecisionTree_accuracy is %\", DecisionTree_accuracy)\n\nlist_names.append(\"Decision Tree \")\nlist_accuracy.append(DecisionTree_accuracy)\n\n# Confusion Matrix\ny_pred_DT = dt.predict(x_test)\nDT_cm = confusion_matrix(y_test, y_pred_DT)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(DT_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Decision Tree')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"692bf5028e0e8fc34cf18b090e6a32904ef59a0a"},"cell_type":"markdown","source":"RANDOM FOREST"},{"metadata":{"trusted":true,"_uuid":"862d7855ed8d6daec2c039a4f0ca38808b6f923f"},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier(n_estimators = 10, random_state = 1)\nrf.fit(x_train, y_train)\nRandomForest_accuracy = rf.score(x_test, y_test)*100\nRandomForest_accuracy = round(RandomForest_accuracy, 3)\n\nprint(\"RandomForest_accuracy is %\", RandomForest_accuracy)\n\nlist_names.append(\"Random Forest \")\nlist_accuracy.append(RandomForest_accuracy)\n\n# Confusion Matrix\ny_pred_RF = rf.predict(x_test)\nRF_cm = confusion_matrix(y_test, y_pred_RF)\n\nf, ax = plt.subplots(figsize = (5,5))\nsns.heatmap(RF_cm, annot = True, linewidth = 0.5, linecolor = \"black\", fmt = \".0f\", ax = ax)\nplt.title('Confusion Matrix of the Random Forest')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"True\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eda3ee114ecda4ef9fe64c4b53c2db5dd1272de8"},"cell_type":"markdown","source":"COMPARISON OF THE MACHINE LEARNING METHODS"},{"metadata":{"trusted":true,"_uuid":"23e60d4b4ffc86aa4a042c11665f3ca56071a99b"},"cell_type":"code","source":"x = list_names\ny = list_accuracy\n    \nfig = plt.figure(figsize=(12,10))\nwidth = 0.4 # the width of the bars \nind = np.arange(len(x))  # the x locations for the groups\nplt.ylim([90,99])\nplt.bar(x, y, width)\nplt.xticks(ind, rotation=90, fontsize = 16)\nplt.yticks(fontsize = 16)\nplt.grid(alpha=0.4)\nplt.ylabel(\"ACCURACY (%)\", fontsize = 16)\nplt.title(\"COMPARISON of the ACCURACY of the MACHINE LEARNING METHODS\", fontsize = 16, pad = 20)  \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}