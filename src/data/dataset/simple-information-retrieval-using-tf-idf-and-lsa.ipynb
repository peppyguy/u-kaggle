{"cells":[{"metadata":{"_uuid":"5f95e212b851fbbb7df4d6f1b53599884b3731be"},"cell_type":"markdown","source":"## Table of Content <a id=\"toc\"></a>\n* [Global Variables](#gv)\n* [1. Data Preprocessing](#data_preprocessing)\n    * [1.1 Importing Data and Separating Data of Our Interest](#1.1)\n    * [1.2 Creating Preprocessing Function and Applying it on Our Data](#1.2)\n    * [1.3 Creating TF-IDF Matrix](#1.3)\n* [2. Apply SVD to TF-IDF Matrix](#apply_svd)\n    * [2.1 Create Term and Document Representation](#2.1)\n    * [2.2 Visulize Those Representation](#2.2)\n* [3 Information Retreival Using LSA](#ir_lsa)\n* [4 References](#references)"},{"metadata":{"trusted":true,"_uuid":"fdcda8e32cccecfea55139961ade8691757b9566"},"cell_type":"code","source":"# Global Variables \nK = 2 # number of components\nquery = 'nice good price'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d09beab03f60b5751a78aac9bbd0d1dbf69a7305"},"cell_type":"markdown","source":"##  1. Data Preprocessing <a id=\"data_preprocessing\"></a>"},{"metadata":{"_uuid":"4a6517b047dad67861a5c67e317d5cb67d0cd237"},"cell_type":"markdown","source":"### 1.1 Importing Data and Separating Data of Our Interest <a id=\"1.1\"></a>"},{"metadata":{"trusted":true,"_uuid":"5139af95b1e8a2e95d6c932feeb1450bb06dd805"},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Data filename\ndataset_filename = \"../input/Womens Clothing E-Commerce Reviews.csv\"\n\n# Loading dataset\ndata = pd.read_csv(dataset_filename, index_col=0)\n\n# We are reducing the size of our dataset to decrease the running time of code\ndatax = data.loc[data['Clothing ID'] == 1078 , :]\n\n\n# Delete missing observations for variables that we will be working with\nfor x in [\"Recommended IND\",\"Review Text\"]:\n    datax = datax[datax[x].notnull()]\n\n# Keeping only those features that we will explore\ndatax = datax[[\"Recommended IND\",\"Review Text\"]]\n\n# Resetting the index\ndatax.index = pd.Series(list(range(datax.shape[0])))\n    \nprint('Shape : ',datax.shape)\ndatax.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5ee3c8b515e0fe16b782c06200bfec562df5bc9"},"cell_type":"markdown","source":"### 1.2 Creating Preprocessing Function and Applying it on Our Data <a id=\"1.2\"></a>"},{"metadata":{"trusted":true,"_uuid":"2c50f748bf9ecb996c35fce87eb492b552c13854"},"cell_type":"code","source":"from nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nimport nltk\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nnltk.download('wordnet')\n\nwordnet_lemmatizer = WordNetLemmatizer()\ntokenizer = RegexpTokenizer(r'[a-z]+')\nstop_words = set(stopwords.words('english'))\n\ndef preprocess(document):\n    document = document.lower() # Convert to lowercase\n    words = tokenizer.tokenize(document) # Tokenize\n    words = [w for w in words if not w in stop_words] # Removing stopwords\n    # Lemmatizing\n    for pos in [wordnet.NOUN, wordnet.VERB, wordnet.ADJ, wordnet.ADV]:\n        words = [wordnet_lemmatizer.lemmatize(x, pos) for x in words]\n    return \" \".join(words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d00a4e0511807d8a760781112e28d4be98e4567a"},"cell_type":"code","source":"datax['Processed Review'] = datax['Review Text'].apply(preprocess)\n\ndatax.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c19525e27d26e6a8b699a71cfd6982eb57f8ddb0"},"cell_type":"markdown","source":"### 1.3 Creating TF-IDF Matrix <a id=\"1.3\"></a>"},{"metadata":{"trusted":true,"_uuid":"b7c41047518ae454b4959f3255769bc02dd4ec67"},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer = TfidfVectorizer()\nTF_IDF_matrix = vectorizer.fit_transform(datax['Processed Review'])\nTF_IDF_matrix = TF_IDF_matrix.T\n\nprint('Vocabulary Size : ', len(vectorizer.get_feature_names()))\nprint('Shape of Matrix : ', TF_IDF_matrix.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6f6eb1290e1f92bb6104f2ba70127e277abbf0b"},"cell_type":"markdown","source":"## 2. Apply SVD to TF-IDF Matrix <a id=\"apply_svd\"></a>"},{"metadata":{"_uuid":"6921c2e1e184f0c22bf10ecca6855a3556ddb48a"},"cell_type":"markdown","source":"### 2.1 Create Term and Document Representation  <a id=\"2.1\"></a>"},{"metadata":{"trusted":true,"_uuid":"0913100c9c12d69aee347955c82a48aedb722fe4"},"cell_type":"code","source":"import numpy as np\n\n# Applying SVD\nU, s, VT = np.linalg.svd(TF_IDF_matrix.toarray()) # .T is used to take transpose and .toarray() is used to convert sparse matrix to normal matrix\n\nTF_IDF_matrix_reduced = np.dot(U[:,:K], np.dot(np.diag(s[:K]), VT[:K, :]))\n\n# Getting document and term representation\nterms_rep = np.dot(U[:,:K], np.diag(s[:K])) # M X K matrix where M = Vocabulary Size and N = Number of documents\ndocs_rep = np.dot(np.diag(s[:K]), VT[:K, :]).T # N x K matrix ","execution_count":null,"outputs":[]},{"metadata":{"id":"FseHPcSsGRTG","colab_type":"text","_uuid":"e2dfc63325fbd4ccec389e5bdecd6453e1ccd0eb"},"cell_type":"markdown","source":"### 2.2 Visulize Those Representation <a id=\"2.2\"></a>"},{"metadata":{"id":"g-oPbgCeFfws","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"5d0e997e-4cac-4780-f9ea-7940bd34adf1","trusted":true,"_uuid":"bd9f19a7bc124f0d7a9f6780f566fde7bf716622"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.scatter(docs_rep[:,0], docs_rep[:,1], c=datax['Recommended IND'])\nplt.title(\"Document Representation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"yT-NgwjaA6nG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"ff01cfc6-2a6c-4f2d-e73d-b0a2fa08a1d2","trusted":true,"_uuid":"f7f86d0720ea6257c7cfda1e35d9cf0dcc04f33e"},"cell_type":"code","source":"plt.scatter(terms_rep[:,0], terms_rep[:,1])\nplt.title(\"Term Representation\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7adc9fbcac6f39738f6200bac7d99ee6e2d0b6f"},"cell_type":"markdown","source":"## 3 Information Retreival Using LSA <a id=\"ir_lsa\"></a>"},{"metadata":{"trusted":true,"_uuid":"90c3cf2db0659576729ba052dfe9acda60c9aea4"},"cell_type":"code","source":"# This is a function to generate query_rep\n\ndef lsa_query_rep(query):\n    query_rep = [vectorizer.vocabulary_[x] for x in preprocess(query).split()]\n    query_rep = np.mean(terms_rep[query_rep],axis=0)\n    return query_rep","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b91c1d053574b84cb6d8dff76dd45de9f9bf8019","scrolled":false},"cell_type":"code","source":"from scipy.spatial.distance import cosine\n\nquery_rep = lsa_query_rep(query)\n\nquery_doc_cos_dist = [cosine(query_rep, doc_rep) for doc_rep in docs_rep]\nquery_doc_sort_index = np.argsort(np.array(query_doc_cos_dist))\n\nprint_count = 0\nfor rank, sort_index in enumerate(query_doc_sort_index):\n    print ('Rank : ', rank, ' Consine : ', 1 - query_doc_cos_dist[sort_index],' Review : ', datax['Review Text'][sort_index])\n    if print_count == 4 :\n        break\n    else:\n        print_count += 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d50ba7127a6ad1f8bb906f027c530416d82b91dd"},"cell_type":"markdown","source":"##  4. References <a id=\"references\"></a>\n* [Latent Semantic Analysis (Tutorial)](https://www.engr.uvic.ca/~seng474/svd.pdf)"}],"metadata":{"colab":{"name":"AI - Project - 3","version":"0.3.2","provenance":[],"collapsed_sections":["3U9Bp1h1yg6H","Siy0qO2sBk3A","AcmwI7ycBu36","F9ulboWcyoDF","WAAD_hlyE_nQ","JKfAiRKTMwSg","D9SJcwIKRors","aeYMp5Lch2hq","Z1GfGn6DZhcp","J68QTlqAoWU_","bfg_V2ZjEB6K","FseHPcSsGRTG","erlg5cOSGWt-"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU","language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}