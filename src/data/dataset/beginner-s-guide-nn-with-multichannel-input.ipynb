{"cells":[{"metadata":{"_uuid":"595d357e1d9a22ed268c8cf2d8c70ee35bd40036","_cell_guid":"599e0de3-312a-46f4-9d6f-092a6195309c","collapsed":true},"cell_type":"markdown","source":"# <center> Beginner's guide: NN with multichannel input  in Keras</center>\n\n_Author: Kirill Vlasov_\n\n--------\n\n# Introduction\nIn this article we will not discuss types of Neural Network. We will try to build network with multichannel input, because this case is so difficult for novice.  \n  \n\n__Plan:__\n- Explanation of model’s usefulness\n- How to develop a neural network with multichannel input in Keras.\n- Practice: using this approach in <a href=\"https://www.kaggle.com/c/donorschoose-application-screening\">DonorsChoose Competition</a>\n\nLet's start!\n\n# Explanation of model’s usefulness\nImagine, we have a dataset of images and we need to solve the problem of classification. Probably, we will develop a convolutional neural network. What are you going to do, in order to supplement meta data (texts, some categorical features and etc.) in model?  \nObviously, we need different types of NN for different types of data, e.g. RNN, CNN and etc. But NN with multichannel input allows to create ONE NN, which could merge all different types of needed NNs. It could divide different flows of calculation, and then merge them together inside one joint NN.\n  \n# How to develop a neural network with multichannel input in Keras.\n\n- Firts of all, we define the type of each data and choose apropriate type of NN for each type of data. \n- Then, we develop each NN.\n- By class _concatenate_ of module _layers.merge_ in _Keras_ we merge all outputs of these different NNs\n- Enjoy! :) \n \n__That's all!__\n  \n# Practice: using this approach in DonorsChoose Competition </a>\n\n  \n## 0. Importing Libraries"},{"metadata":{"_uuid":"9272c277feec50a9db24191cf111288835c72c7e","_cell_guid":"cc97888a-c5bd-40c4-94e4-59c6033ed958","trusted":false,"collapsed":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import StandardScaler\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tqdm import tqdm_notebook\nimport re\nimport nltk\nfrom nltk.stem import SnowballStemmer\n\nfrom keras.preprocessing.text import Tokenizer\n\nfrom keras.layers import Dense, Activation, Dropout, Flatten, Input\nfrom keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\nfrom keras.models import Model, Sequential \nfrom keras.layers.recurrent import LSTM\n\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom keras.layers.merge import concatenate\nfrom keras.utils import plot_model\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"057b44ef33dd214a06acaeb685145cb7f8be60c2","_cell_guid":"33e27d2f-3ecc-4183-9d14-c55db3b6d9a0"},"cell_type":"markdown","source":"## 1. Loading and preprocessing data"},{"metadata":{"_uuid":"a7752e4c1a35456297fdfb0985f6791f039320f4","_cell_guid":"a8c57673-e12f-4689-9278-7a808db474ae","trusted":false,"collapsed":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv', low_memory=False, index_col='id')\ntest = pd.read_csv('../input/test.csv', low_memory=False, index_col='id')\n\nres = pd.read_csv('../input/resources.csv', low_memory=False, index_col='id')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a8d4cac34750764a1dc5968ce0101f4c1b4c09d","_cell_guid":"a78f046e-8a37-4dc0-a1de-fd534f9a9062"},"cell_type":"markdown","source":"### 1.1. Concatination of train and test"},{"metadata":{"_uuid":"3c2f2c133e52b334e62a844b43976e931efdb79a","_cell_guid":"856e4260-feff-4b22-9acc-ecf5ffd0edcd","collapsed":true,"trusted":false},"cell_type":"code","source":"train['is_train'] = 1\ntest['is_train'] = 0","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"106065a39cb35d134c349d6b4fac2eebc234ad74","_cell_guid":"1c4c8df5-2c9a-4f79-aba9-116fef516f39","collapsed":true,"trusted":false},"cell_type":"code","source":"df = pd.concat([train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"38c37cf4c6ae504211011f640a18c6d25f016a90","_cell_guid":"928bc38f-fcdd-498e-b1d9-fd06ea0f9fcf"},"cell_type":"markdown","source":"### 1.2. Generate features from 'res.csv'"},{"metadata":{"_uuid":"353a95e10f04b278980660ac1514b8cf532512c0","_cell_guid":"88159521-2536-49a5-930b-e0b1ebe8295a","collapsed":true,"trusted":false},"cell_type":"code","source":"sum_res = pd.pivot_table(res, index=res.index, aggfunc='sum', values=['price', 'quantity'])\nmean_res = pd.pivot_table(res, index=res.index, aggfunc='mean', values=['price', 'quantity'])\nmedian_res = pd.pivot_table(res, index=res.index, aggfunc='median', values=['price', 'quantity'])\n\ndf = pd.merge(df, sum_res,left_index=True, right_index=True)\ndf = pd.merge(df, mean_res,left_index=True, right_index=True, suffixes=('_sum', ''))\ndf = pd.merge(df, median_res,left_index=True, right_index=True, suffixes=('_mean', '_median'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2178a8af306337d835d7d1aa8b7724b52042a6ae","_cell_guid":"7f3d1713-6742-4a0e-a2f5-f1d5b4c15721"},"cell_type":"markdown","source":"### 1.3. Type of features"},{"metadata":{"_uuid":"635bc0ec177b1d19c3a77fabb616afa2449e60fd","_cell_guid":"0e0ff6da-565f-441e-a06c-8fba9c0fd31a","trusted":false,"collapsed":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bef0b9bfcd754f3f78cd3ab8c3f77bad00732fa7","_cell_guid":"b75307a0-da36-4af9-a39a-f0d39fb7179d","collapsed":true,"trusted":false},"cell_type":"code","source":"cat_feature = ['school_state', 'teacher_prefix', \n               'project_subject_categories', 'project_subject_subcategories', 'project_grade_category']\n\ntarget = 'project_is_approved'\n\ntext_feature = ['project_title', 'project_resource_summary', 'project_essay_1', 'project_essay_2', 'project_essay_3',\n       'project_essay_4' ]\n\nreal_feature = ['teacher_number_of_previously_posted_projects', 'price_sum', 'quantity_sum', 'price_mean', 'quantity_mean',\n       'price_median', 'quantity_median' ]\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"367294aa339660dd198857f56e1e165701bdfee0","_cell_guid":"54b10802-63fc-4869-adc9-674ea43b69b1"},"cell_type":"markdown","source":"### 1.4. Preprocessing of features \n__Categorical__  \nWe may just facrorize features of this type"},{"metadata":{"_uuid":"75c0fe1387ae9b6d2f372ad09009ad0f3103ee32","_cell_guid":"563fd978-1c81-40c2-92c1-71a30a061aa7","collapsed":true,"trusted":false},"cell_type":"code","source":"for i in cat_feature:\n    df[i] = pd.factorize(df[i])[0]\n\ntrn_cat = df[cat_feature].values[:182080]\ntst_cat = df[cat_feature].values[182080:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7ffc042ba7a88d21dd2ad697b687bb0d6c3ba99","_cell_guid":"efd60470-8f72-421c-873f-d29be83facdc"},"cell_type":"markdown","source":"__Real__  \nDon't forget about _Scalling_"},{"metadata":{"_uuid":"2d3dfc9590de0f2b8983992159960849c3b16f88","_cell_guid":"fdf17bbb-d773-4c5f-9a1c-fd50def722bd","collapsed":true,"trusted":false},"cell_type":"code","source":"SS = StandardScaler()\ndf_scale = SS.fit_transform(df[real_feature])\n\ntrn_real = df_scale[:182080]\ntst_real = df_scale[182080:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b49562a1790f475009fa4dee228b75e1e6e30fd","_cell_guid":"9839b71c-2b78-4ad2-a987-c04654ba6772"},"cell_type":"markdown","source":"__Text__  \nProcessing of text data easily"},{"metadata":{"_uuid":"bea34f69045c990d69a9c9816e662c067b179890","_cell_guid":"9430c0fe-5f59-4604-bb86-1985b70c94f6","collapsed":true,"trusted":false},"cell_type":"code","source":"df_text = df[text_feature].fillna(' ')\ndf_text['full_text'] = ''\nfor f in text_feature:\n    df_text['full_text'] = df_text['full_text'] + df_text[f]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e1b73d863a32639dbdce40d81640f64b58f78f84","_cell_guid":"275a9433-3043-4698-a517-cf298396670e","collapsed":true,"trusted":false},"cell_type":"code","source":"stemmer = SnowballStemmer('english')\n\ndef clean(text):\n    return re.sub('[!@#$:]', '', ' '.join(re.findall('\\w{3,}', str(text).lower())))\n\ndef stem(text):\n    return ' '.join([stemmer.stem(w) for w in text.split()])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"523e517e217e6fb433c12b7a3313d902d5da9602","_cell_guid":"5c64c8f1-df6c-4f27-813a-52b10528de0d","collapsed":true,"trusted":false},"cell_type":"code","source":"df_text['full_text'] = df_text['full_text'].apply(lambda x: clean(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6cbde2e2ab0f89d029228aa5ed32ffc5d10eb7b7","_cell_guid":"3ece29f2-4a8d-4c12-8604-72d74869a42c","collapsed":true,"trusted":false},"cell_type":"code","source":"#df_text['full_text'] = df_text['full_text'].apply(lambda x: stem(x)) - don't think about it :)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c331bf05cdd4d1eb5eb31ae1447be273523bcf7f","_cell_guid":"4ee936d8-3a53-4aef-b0ef-4021ffae747f","trusted":false,"collapsed":true},"cell_type":"code","source":"max_words = 500 #more words for more accuracy\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(df_text['full_text'])\n\ntrn_text = tokenizer.texts_to_matrix(df_text['full_text'][:182080], mode='binary')\ntst_text = tokenizer.texts_to_matrix(df_text['full_text'][182080:], mode='binary')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d894ea2bc04a362419cbfa2193da7c3905f7c89f","_cell_guid":"06728fe9-6979-4eeb-bbb8-f8346f48fadf"},"cell_type":"markdown","source":"__Target__"},{"metadata":{"_uuid":"e9403c7e93377554d52fb306c3a3b44549d985cf","_cell_guid":"268a4ea2-83b7-48c1-b428-330174e68e1b","collapsed":true,"trusted":false},"cell_type":"code","source":"y = df[target].values[:182080]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5fce0b3a0161c67be738bb8701b00706d4c66c8b","_cell_guid":"ec0574e1-eb23-4a66-8cc0-2bf81850a89a"},"cell_type":"markdown","source":"## 2. Modeling! \n### 2.1. Parameters"},{"metadata":{"_uuid":"168f2eab4120a664441b60094d19710e5ee63c8e","_cell_guid":"ee567d4d-d6a9-48a5-b7cc-f3ec252ede99","collapsed":true,"trusted":false},"cell_type":"code","source":"len_cat = trn_cat.shape[1]\nlen_real = trn_real.shape[1]\nlen_text = trn_text.shape[1]\n\n\nsize_embedding = 5000","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4452f9287de9004d7114ef6fd7033805b4f31585","_cell_guid":"b879dbc6-4cfa-4448-9891-ce693bb5aa1d"},"cell_type":"markdown","source":"### 2.2. Architecture"},{"metadata":{"_uuid":"c1a5975e61a427c836bb7d5a085b2a35349b3eff","_cell_guid":"29d6414d-eb95-4776-a236-ae18d1c99673","collapsed":true,"trusted":false},"cell_type":"code","source":"# categorical channel \ninputs1 = Input(shape=(len_cat,))\ndense_cat_1 = Dense(256, activation='relu')(inputs1)\ndense_cat_2 = Dense(128, activation='relu')(dense_cat_1)\ndense_cat_3 = Dense(64, activation='relu')(dense_cat_2)\ndense_cat_4 = Dense(32, activation='relu')(dense_cat_3)\nflat1 = Dense(32, activation='relu')(dense_cat_4)\n\n\n\n# real channel\ninputs2 = Input(shape=(len_real,))\ndense_real_1 = Dense(256, activation='relu')(inputs2)\ndense_real_2 = Dense(128, activation='relu')(dense_real_1)\ndense_real_3 = Dense(64, activation='relu')(dense_real_2)\ndense_real_4 = Dense(32, activation='relu')(dense_real_3)\nflat2 = Dense(32, activation='relu')(dense_real_4)\n\n\n# text chanel\ninputs3 = Input(shape=(len_text,))\nembedding3 = Embedding(size_embedding, 36)(inputs3)\nconv3 = Conv1D(filters=32, kernel_size=8, activation='relu')(embedding3)\ndrop3 = Dropout(0.1)(conv3)\npool3 = MaxPooling1D(pool_size=2)(drop3)\nflat3 = Flatten()(pool3)\n\n# merge\nmerged = concatenate([flat1, flat2, flat3])\n\n# interpretation\ndense1 = Dense(200, activation='relu')(merged)\ndense2 = Dense(20, activation='relu')(dense1)\noutputs = Dense(1, activation='sigmoid')(dense2)\nmodel = Model(inputs=[inputs1, inputs2, inputs3], outputs=outputs)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5cc6714af53e6c5f78cab2a69b50d2a86031f7f","_cell_guid":"10f67cac-1a10-43fa-81b0-feeecb8cb5fd"},"cell_type":"markdown","source":"### 2.4. Metric  \nThx Stackoverflow for realization"},{"metadata":{"_uuid":"9fcb51c32095d8704dd7c2d7e0f27ca9673926cc","_cell_guid":"adcff888-b02a-4950-9fd0-44b34ff1f9d9","collapsed":true,"trusted":false},"cell_type":"code","source":"# AUC for a binary classifier\ndef auc(y_true, y_pred):   \n    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n    binSizes = -(pfas[1:]-pfas[:-1])\n    s = ptas*binSizes\n    return K.sum(s, axis=0)\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# PFA, prob false alert for binary classifier\ndef binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # N = total number of negative labels\n    N = K.sum(1 - y_true)\n    # FP = total number of false alerts, alerts from the negative class labels\n    FP = K.sum(y_pred - y_pred * y_true)    \n    return FP/N\n#-----------------------------------------------------------------------------------------------------------------------------------------------------\n# P_TA prob true alerts for binary classifier\ndef binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n    y_pred = K.cast(y_pred >= threshold, 'float32')\n    # P = total number of positive labels\n    P = K.sum(y_true)\n    # TP = total number of correct alerts, alerts from the positive class labels\n    TP = K.sum(y_pred * y_true)    \n    return TP/P","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77a251488b0a929a3708ce4e6e7ce28695af07be","_cell_guid":"29f72816-b356-449f-89ca-47478f689292"},"cell_type":"markdown","source":"### 2.3. Compilation"},{"metadata":{"_uuid":"d112c121f144134718a9ff9ba7ca6d378b60f7d1","_cell_guid":"98914160-7ad3-4089-8d8a-63c61b8629f4","collapsed":true,"trusted":false},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', auc])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"145aca20c8c592a27acfcb8c5ec52ec74fc4e455","_cell_guid":"c3e9af28-f616-4571-9c90-d1884ace0929"},"cell_type":"markdown","source":"### 2.4. Fitting"},{"metadata":{"_uuid":"11dd7b41e082eb26ae7fea7c54754f8eaf764434","_cell_guid":"2d2de78e-d028-4be2-954c-f5176b50f413","collapsed":true,"trusted":false},"cell_type":"code","source":"batch_size = 1000\nmodel.fit([trn_cat, trn_real, trn_text], y, batch_size=batch_size, epochs=3, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27ae23925b4c0497d82e126a36420fdb36428afd","_cell_guid":"0c2b1ec7-b282-42c1-a98f-04b88b11255b"},"cell_type":"markdown","source":"### 2.5. Submitting"},{"metadata":{"_uuid":"2c8a061e2e58b58d428116b1dc32546f1c8b9280","_cell_guid":"bb557438-6ba5-4984-9b3d-97a65818fe9b","collapsed":true,"trusted":false},"cell_type":"code","source":"submit = model.predict([tst_cat, tst_real, tst_text], batch_size=batch_size,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"524270cd696ddec8bc35ff2a9f7969a25e84f4c3","_cell_guid":"ce6e2624-7a24-4ec7-a574-5c83d0159143","collapsed":true,"trusted":false},"cell_type":"code","source":"submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"438d6f4c44de8979604ea0fbac435778c7f812de","_cell_guid":"77d66c87-782d-451f-b565-89239ac29000","collapsed":true,"trusted":false},"cell_type":"code","source":"submission['project_is_approved'] = submit\nsubmission.to_csv('mi_nn.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a03f15dc624ab8135794e4bd4f4c9d5ad3d4acf","_cell_guid":"169c47b1-4da9-42de-a503-b87612a831dc"},"cell_type":"markdown","source":"## 3.Comparison with non-multichannel type of NN"},{"metadata":{"_uuid":"38a236616af3b36b4fb1e4c69c98abded0f3f8b5","_cell_guid":"951c8393-6e78-4144-b797-2a97ae43fe5e","trusted":false,"collapsed":true},"cell_type":"code","source":"trn_all = np.hstack((trn_cat, trn_real, trn_text))\ntrn_all.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b48fac07b54a14929ed395751bc040ce9d5b58cb","_cell_guid":"e4c76f98-d1cb-4c3c-91eb-2ed6af686f06","trusted":false,"collapsed":true},"cell_type":"code","source":"model2 = Sequential()\nmodel2.add(Dense(256, input_shape=(trn_all.shape[1],), activation='relu'))\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"904ecdbb81d04a095e4c8374fea9440461e4e31a","_cell_guid":"397e69af-8832-4cf6-9e75-67b6cbb49cfc","collapsed":true,"trusted":false},"cell_type":"code","source":"model2.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy', auc])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b138b95229b6085c17fe4efc418c480452a7760c","_cell_guid":"1f7fc08e-ed92-44fc-88f3-0d761a9e145b","collapsed":true,"trusted":false},"cell_type":"code","source":"batch_size = 2000\nmodel2.fit(trn_all, y, batch_size=batch_size, epochs=3, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"26e535947b6c6431e41f2e31477092a91220549e","_cell_guid":"cef41503-0c38-4148-a295-2e59ff69df4d"},"cell_type":"markdown","source":"# Conclusion\nCertainly, computing power of Kaggle's kernel doesn't allow to build more sophisticated models, but in practice we may experiment with NN with multichannel input to achieve better results. Finally, NN with multichannel input are more flexible and let you work with different types of data. \n\n\n\n# Links\n- <a href = \"https://keras.io\" > Keras Documentation </a>\n- <a href = \"https://machinelearningmastery.com/develop-n-gram-multichannel-convolutional-neural-network-sentiment-analysis/\" >How to Develop an N-gram Multichannel Convolutional Neural Network for Sentiment Analysis </a>\n- <a href = https://towardsdatascience.com/neural-network-architectures-156e5bad51ba> Neural Network Architectures </a>\n"},{"metadata":{"_uuid":"b1073ab5948ef2d5ac0060e1b1f7d4303fec4893","_cell_guid":"ed9bb8f0-6f3a-45cc-85b1-a4da298f57c5","collapsed":true,"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}