{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# <a id=\"0\"></a> Contents\n1. [Overview](#1)\n1. [Importing Modules, Reading the Dataset and Defining an Evaluation Table](#3)\n1. [Defining a Function to Calculate the Adjusted $R^{2}$ ](#3)\n1. [Creating a Simple Regression](#4)\n    1. [Let's Show the Results](#5)\n1. [Examining and Adding More Features](#6)\n   1. [Checking Out the Correlation Among Explanatory Variables](#7)\n   1. [Complex Model - 1](#8)\n   1. [Complex Model - 2](#9)\n1. [Polynomial Regression](#10)  \n1. [KNN Regression](#11)   \n1. [Conclusion](#12)"},{"metadata":{"_uuid":"2618a56cc8d9d7b5d2b7fbcca6e33c09d107a846"},"cell_type":"markdown","source":"# <a id=\"1\"></a> Overview\n<hr/>\nWelcome to my Kernel! In this kernel I use various regression methods and try to predict the house prices by using them. As you can guess, there are various methods to suceed this and each method has pros and cons. I think regression is one of the most important methods because it gives us more insight about the data. When we ask ***why***, it is easier to interpret the relation between the response and explanatory variables. \n\nHere, I start with a very simple model and continue with more complex ones. I try to find the most useful model and during this I also use visuals to be able to understand the data better. \n\nIf you have a question or feedback, do not hesitate to write and if you like this kernel, please <b><font color=\"red\">do not forget to </font><font color=\"green\">UPVOTE </font></b> ðŸ™‚ \n<br/>\n<img src=\"https://i.imgur.com/kCNAFTN.jpg?1\" title=\"source: imgur.com\" />"},{"metadata":{"_uuid":"351a6fa94567dc140b2531cf001c6e3eae30cede"},"cell_type":"markdown","source":"# <a id=\"2\"></a> Importing Modules, Reading the Dataset and Defining an Evaluation Table\n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"_uuid":"3668e1cc3d1f9c85bb910c4512c92d2a52b57aab"},"cell_type":"markdown","source":"In order to make some analysis, we need to set our environment up. To do this, I firstly imported some modules and read the data. The below output is the head of the data but if you want to see more details, you might try removing ***#*** signs in front of the ***df.describe()*** and ***df.info()***.  \n\nFurther, I defined an empty dataframe. This dataframe includes Mean Squared Error (MSE), R-squared and Adjusted R-squared which are the important metrics to compare different models. Having a R-squared value closer to one and smaller MSE means a better fit. In the following sections, I will fill this dataframe with my results."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Importing the modules \nimport numpy as np\nimport pandas as pd \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import Axes3D\n%matplotlib inline\n\nevaluation = pd.DataFrame({'Model': [],\n                           'Details':[],\n                           'Mean Squared Error (MSE)':[],\n                           'R-squared (training)':[],\n                           'Adjusted R-squared (training)':[],\n                           'R-squared (test)':[],\n                           'Adjusted R-squared (test)':[]})\n\n# Reading Data \ndf = pd.read_csv('../input/kc_house_data.csv')\n#df.describe()\n#df.info()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f7ddce1d3bc2081cd267d949635e507f1c469f5f"},"cell_type":"markdown","source":"# <a id=\"3\"></a> Defining a Function to Calculate the Adjusted $R^{2}$\n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"_uuid":"2433b0c95875503e8bc07ff3d537d44502d4f12e"},"cell_type":"markdown","source":"The R-squared increases when the number of features increase. Because of this, sometimes a more robust evaluator is preferred to compare the performance between different models. This evaluater is called adjusted R-squared and it only increases, if the addition of the variable reduces the MSE. The definition of the adjusted $R^{2}$ is:\n\n$\\bar{R^{2}}=R^{2}-\\frac{k-1}{n-k}(1-R^{2})$,\n\nwhere n is the number of observations and k is the number of parameters. "},{"metadata":{"trusted":true,"_uuid":"2a7590089c0a309d20737a18c84579eca49c62b0"},"cell_type":"code","source":"def adjustedR2(r2,n,k):\n    return r2-(k-1)/(n-k)*(1-r2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"74510b5648577407f3fa127c5e37a82525cd3856"},"cell_type":"markdown","source":"# <a id=\"4\"></a> Creating a Simple Regression \n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"_uuid":"1a40aa787755f3ffa96b0e4bc32586e6419c8007"},"cell_type":"markdown","source":"When we model a linear relationship between a response and just **one** explanatory variable, this is called **simple linear regression**. I want to predict house prices and then, our response variable is price. However, for a simple model we also need to select a feature. When I look at the columns of the dataset, **living area (sqft)** seemed the most important feature. When we examine the  <a href=#7>correlation matrix</a>, we may observe that price has the highest correlation coefficient with living area (sqft) and this also supports my opinion. Thus, I decided to use **living area (sqft)** as feature but if you want to examine the relationship between price and another feature, you may prefer the other feature."},{"metadata":{"trusted":true,"_uuid":"1b8d1baa63beba3b46cabc815e566631b6131dd7"},"cell_type":"code","source":"#Â splitting data\ntrain_data,test_data = train_test_split(df,train_size = 0.8,random_state=3)\n# Linear Model \nlr = linear_model.LinearRegression()\nX_train = np.array(train_data['sqft_living'], dtype=pd.Series).reshape(-1,1)\ny_train = np.array(train_data['price'], dtype=pd.Series)\n# fitting the linear model\nlr.fit(X_train,y_train)\n\n# Evaluate the simple model\nX_test = np.array(test_data['sqft_living'], dtype=pd.Series).reshape(-1,1)\ny_test = np.array(test_data['price'], dtype=pd.Series)\n\npred = lr.predict(X_test)\nmsesm = format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f')\nrtrsm = format(lr.score(X_train, y_train),'.3f')\nrtesm = format(lr.score(X_test, y_test),'.3f')\n\nprint (\"Average Price for Test Data: {:.3f}\".format(y_test.mean()))\nprint('Intercept: {}'.format(lr.intercept_))\nprint('Coefficient: {}'.format(lr.coef_))\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Simple Model','-',msesm,rtrsm,'-',rtesm,'-']\nevaluation","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce095a1e73c44936202c3c7f6fd2ec334425bfe7"},"cell_type":"markdown","source":"## <a id=\"5\"></a> Let's Show the Results"},{"metadata":{"_uuid":"bf7a85fa539b7b8ec42316f7e94b67c5e695e31c"},"cell_type":"markdown","source":"Because we have just **two** dimensions at the simple regression, it is easy to determine it. The below chart determines the result of the simple regression. It does not look like a perfect fit but when we work with real world datasets, having a perfect fit is not easy."},{"metadata":{"trusted":true,"_uuid":"2947943b51a82e7f0c386679a213f02c5252c4ac"},"cell_type":"code","source":"plt.figure(figsize=(6.5,5))\nplt.scatter(X_test,y_test,color='darkgreen',label=\"Data\", alpha=.1)\nplt.plot(X_test,lr.predict(X_test),color=\"red\",label=\"Predicted Regression Line\")\nplt.xlabel(\"Living Space (sqft)\", fontsize=15)\nplt.ylabel(\"Price ($)\", fontsize=15)\nplt.xticks(fontsize=13)\nplt.yticks(fontsize=13)\nplt.legend()\n\nplt.gca().spines['right'].set_visible(False)\nplt.gca().spines['top'].set_visible(False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d9d01bb10c345c51c21b4d775095436e53c6b634"},"cell_type":"markdown","source":"# <a id=\"6\"></a> Examining and Adding More Features\n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"_uuid":"c8c3016e2fa13d01215ce2fbc014190964e13735"},"cell_type":"markdown","source":"In the previous section I used a simple linear regression and found a poor fit. In order to improve this model I am planing to add more features but we should be careful about the overfit which can be seen by the difference between the training and test evaluation metrics. When we have more than one feature in a linear regression, it is defined as multiple regression. Then, it is time to check the correlation matrix before fitting a mutiple regression."},{"metadata":{"trusted":true,"_uuid":"a8e52b8956be743bff54d7815aafa927013c9ede","_kg_hide-input":true},"cell_type":"code","source":"sns.set(style=\"white\", font_scale=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05515a92ccea03d5a6b3ac25f521c9ff717fe72c"},"cell_type":"markdown","source":"## <a id=\"7\"></a> Checking Out the Correlation Among Explanatory Variables"},{"metadata":{"_uuid":"a8e48879cd3346288e5e419a835cf3bd00381d03"},"cell_type":"markdown","source":"First, I want to recall some information. Having too many features in a model is not always a good thing because it might cause overfit and worser results when we want to predict values for a new dataset. Thus, if a feature does not improve your model a lot, not adding it may be a better choice.\n\nAnother important thing is correlation, if there is very high correlation between two features, keeping both of them is not a good idea most of the time. For instance, sqt_above and sqt_living are highly correlated. This can be estimated when you look at the definitions at the dataset and checked to be sure by looking at the correlation matrix. However, this does not mean that you should remove one of the highly correlated features. For instance: bathrooms and sqrt_living. They are highly correlated but I do not think that the relation among them is the same as the relation between sqt_living and sqt_above."},{"metadata":{"trusted":true,"_uuid":"75fa3cf3dd756a4f05657b3fd62242d4307c1256","_kg_hide-input":true},"cell_type":"code","source":"features = ['price','bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n            'view','condition','grade','sqft_above','sqft_basement','yr_built',\n            'yr_renovated','zipcode','sqft_living15','sqft_lot15']\n\nmask = np.zeros_like(df[features].corr(), dtype=np.bool) \nmask[np.triu_indices_from(mask)] = True \n\nf, ax = plt.subplots(figsize=(16, 12))\nplt.title('Pearson Correlation Matrix',fontsize=25)\n\nsns.heatmap(df[features].corr(),linewidths=0.25,vmax=1.0,square=True,cmap=\"BuGn_r\", \n            linecolor='w',annot=True,mask=mask,cbar_kws={\"shrink\": .75})","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9205c30676daae4db2aac74fca01abc8bb43a957"},"cell_type":"markdown","source":"## <a id=\"8\"></a> Complex Model - 1\n#### [Return Contents](#0)"},{"metadata":{"trusted":true,"_uuid":"fcd023eceeb0c92852be68397f2f32bf225bc839"},"cell_type":"code","source":"f, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=train_data['bedrooms'],y=train_data['price'], ax=axes[0])\nsns.boxplot(x=train_data['floors'],y=train_data['price'], ax=axes[1])\naxes[0].set(xlabel='Bedrooms', ylabel='Price')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].set(xlabel='Floors', ylabel='Price')\n\nf, axe = plt.subplots(1, 1,figsize=(12.18,5))\nsns.boxplot(x=train_data['bathrooms'],y=train_data['price'], ax=axe)\naxe.set(xlabel='Bathrooms / Bedrooms', ylabel='Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d14da10f3390bcf9ae706accfcf9e8c9fad6a6e"},"cell_type":"code","source":"fig=plt.figure(figsize=(19,12.5))\nax=fig.add_subplot(2,2,1, projection=\"3d\")\nax.scatter(train_data['floors'],train_data['bedrooms'],train_data['bathrooms'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\nBathrooms / Bedrooms')\nax.set(ylim=[0,12])\n\nax=fig.add_subplot(2,2,2, projection=\"3d\")\nax.scatter(train_data['floors'],train_data['bedrooms'],train_data['sqft_living'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\nsqft Living')\nax.set(ylim=[0,12])\n\nax=fig.add_subplot(2,2,3, projection=\"3d\")\nax.scatter(train_data['sqft_living'],train_data['sqft_lot'],train_data['bathrooms'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\n sqft Living',ylabel='\\nsqft Lot',zlabel='\\nBathrooms / Bedrooms')\nax.set(ylim=[0,250000])\n\nax=fig.add_subplot(2,2,4, projection=\"3d\")\nax.scatter(train_data['sqft_living'],train_data['sqft_lot'],train_data['bedrooms'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\n sqft Living',ylabel='\\nsqft Lot',zlabel='Bedrooms')\nax.set(ylim=[0,250000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa32c503643f2c129189b3f9df968420d87e1df7"},"cell_type":"code","source":"# Linear model with more features\nfeatures1 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','zipcode']\ncomplex_model_1 = linear_model.LinearRegression()\ncomplex_model_1.fit(train_data[features1],train_data['price'])\n\nprint('Intercept: {}'.format(complex_model_1.intercept_))\nprint('Coefficients: {}'.format(complex_model_1.coef_))\n\npred1 = complex_model_1.predict(test_data[features1])\nmsecm1 = format(np.sqrt(metrics.mean_squared_error(y_test,pred1)),'.3f')\nrtrcm1 = format(complex_model_1.score(train_data[features1],train_data['price']),'.3f')\nartrcm1 = format(adjustedR2(complex_model_1.score(train_data[features1],train_data['price']),train_data.shape[0],len(features1)),'.3f')\nrtecm1 = format(complex_model_1.score(test_data[features1],test_data['price']),'.3f')\nartecm1 = format(adjustedR2(complex_model_1.score(test_data[features1],test_data['price']),test_data.shape[0],len(features1)),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Complex Model-1','-',msecm1,rtrcm1,artrcm1,rtecm1,artecm1]\nevaluation.sort_values(by = 'R-squared (test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7163826c32feb75f8fbf12a0262382defc1ef438"},"cell_type":"markdown","source":"## <a id=\"9\"></a> Complex Model - 2\n#### [Return Contents](#0)"},{"metadata":{"trusted":true,"_uuid":"0f0141a5ef51c04c4b70549fe114ce2fcf14beeb"},"cell_type":"code","source":"f, axes = plt.subplots(1, 2,figsize=(15,5))\nsns.boxplot(x=train_data['waterfront'],y=train_data['price'], ax=axes[0])\nsns.boxplot(x=train_data['view'],y=train_data['price'], ax=axes[1])\naxes[0].set(xlabel='Waterfront', ylabel='Price')\naxes[1].yaxis.set_label_position(\"right\")\naxes[1].yaxis.tick_right()\naxes[1].set(xlabel='View', ylabel='Price')\n\nf, axe = plt.subplots(1, 1,figsize=(12.18,5))\nsns.boxplot(x=train_data['grade'],y=train_data['price'], ax=axe)\naxe.set(xlabel='Grade', ylabel='Price')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4ef7608090f7ea71d4653d85ae9511bbe4f2a364"},"cell_type":"code","source":"fig=plt.figure(figsize=(9.5,6.25))\nax=fig.add_subplot(1,1,1, projection=\"3d\")\nax.scatter(train_data['view'],train_data['grade'],train_data['yr_built'],c=\"darkgreen\",alpha=.5)\nax.set(xlabel='\\nFloors',ylabel='\\nBedrooms',zlabel='\\n Year Built')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"acc6eeac4dbc720cbbb1559b732e17155b865056"},"cell_type":"code","source":"features2 = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n             'grade','yr_built','zipcode']\ncomplex_model_2 = linear_model.LinearRegression()\ncomplex_model_2.fit(train_data[features2],train_data['price'])\n\nprint('Intercept: {}'.format(complex_model_2.intercept_))\nprint('Coefficients: {}'.format(complex_model_2.coef_))\n\npred2 = complex_model_2.predict(test_data[features2])\nmsecm2 = format(np.sqrt(metrics.mean_squared_error(y_test,pred2)),'.3f')\nrtrcm2 = format(complex_model_2.score(train_data[features2],train_data['price']),'.3f')\nartrcm2 = format(adjustedR2(complex_model_2.score(train_data[features2],train_data['price']),train_data.shape[0],len(features2)),'.3f')\nrtecm2 = format(complex_model_2.score(test_data[features2],test_data['price']),'.3f')\nartecm2 = format(adjustedR2(complex_model_2.score(test_data[features2],test_data['price']),test_data.shape[0],len(features2)),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Complex Model-2','-',msecm2,rtrcm2,artrcm2,rtecm2,artecm2]\nevaluation.sort_values(by = 'R-squared (test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"497e19b22df6a73661b66c4fbb27f36eaee5dfc5"},"cell_type":"markdown","source":"# <a id=\"10\"></a> Polynomial Regression\n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"trusted":true,"_uuid":"d93b04336bb61c90ca470310d3b3c47f58fec094"},"cell_type":"code","source":"polyfeat = PolynomialFeatures(degree=2)\nX_trainpoly = polyfeat.fit_transform(train_data[features2])\nX_testpoly = polyfeat.fit_transform(test_data[features2])\npoly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n\npredp = poly.predict(X_testpoly)\nmsepoly1 = format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred)),'.3f')\nrtrpoly1 = format(poly.score(X_trainpoly,train_data['price']),'.3f')\nrtepoly1 = format(poly.score(X_testpoly,test_data['price']),'.3f')\n\npolyfeat = PolynomialFeatures(degree=3)\nX_trainpoly = polyfeat.fit_transform(train_data[features2])\nX_testpoly = polyfeat.fit_transform(test_data[features2])\npoly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n\npredp = poly.predict(X_testpoly)\nmsepoly2 = format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred)),'.3f')\nrtrpoly2 = format(poly.score(X_trainpoly,train_data['price']),'.3f')\nrtepoly2 = format(poly.score(X_testpoly,test_data['price']),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['Polynomial Regression','degree=2',msepoly1,rtrpoly1,'-',rtepoly1,'-']\nevaluation.loc[r+1] = ['Polynomial Regression','degree=3',msepoly2,rtrpoly2,'-',rtepoly2,'-']\nevaluation.sort_values(by = 'R-squared (test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d07b139ea0a455852227fc47099dd03c7e541f2e"},"cell_type":"markdown","source":"# <a id=\"11\"></a> KNN Regression \n#### [Return Contents](#0)\n<hr/>"},{"metadata":{"trusted":true,"_uuid":"83a2fe657df3cc80e690c35288e2fcebfcaa8743"},"cell_type":"code","source":"knnreg = KNeighborsRegressor(n_neighbors=15)\nknnreg.fit(train_data[features2],train_data['price'])\npred = knnreg.predict(test_data[features2])\n\nmseknn1 = format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f')\nrtrknn1 = format(knnreg.score(train_data[features2],train_data['price']),'.3f')\nartrknn1 = format(adjustedR2(knnreg.score(train_data[features2],train_data['price']),train_data.shape[0],len(features2)),'.3f')\nrteknn1 = format(knnreg.score(test_data[features2],test_data['price']),'.3f')\narteknn1 = format(adjustedR2(knnreg.score(test_data[features2],test_data['price']),test_data.shape[0],len(features2)),'.3f')\n\nknnreg = KNeighborsRegressor(n_neighbors=25)\nknnreg.fit(train_data[features2],train_data['price'])\npred = knnreg.predict(test_data[features2])\n\nmseknn2 = format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f')\nrtrknn2 = format(knnreg.score(train_data[features2],train_data['price']),'.3f')\nartrknn2 = format(adjustedR2(knnreg.score(train_data[features2],train_data['price']),train_data.shape[0],len(features2)),'.3f')\nrteknn2 = format(knnreg.score(test_data[features2],test_data['price']),'.3f')\narteknn2 = format(adjustedR2(knnreg.score(test_data[features2],test_data['price']),test_data.shape[0],len(features2)),'.3f')\n\n\nknnreg = KNeighborsRegressor(n_neighbors=27)\nknnreg.fit(train_data[features2],train_data['price'])\npred = knnreg.predict(test_data[features2])\n\nmseknn3 = format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f')\nrtrknn3 = format(knnreg.score(train_data[features2],train_data['price']),'.3f')\nartrknn3 = format(adjustedR2(knnreg.score(train_data[features2],train_data['price']),train_data.shape[0],len(features2)),'.3f')\nrteknn3 = format(knnreg.score(test_data[features2],test_data['price']),'.3f')\narteknn3 = format(adjustedR2(knnreg.score(test_data[features2],test_data['price']),test_data.shape[0],len(features2)),'.3f')\n\nr = evaluation.shape[0]\nevaluation.loc[r] = ['KNN Regression','n_neighbors=15',mseknn1,rtrknn1,artrknn1,rteknn1,arteknn1]\nevaluation.loc[r+1] = ['KNN Regression','n_neighbors=25',mseknn2,rtrknn2,artrknn2,rteknn2,arteknn2]\nevaluation.loc[r+2] = ['KNN Regression','n_neighbors=27',mseknn3,rtrknn3,artrknn3,rteknn3,arteknn3]\nevaluation.sort_values(by = 'R-squared (test)', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b02ebdaf3872558184c20f8e5081458b9faea5c6"},"cell_type":"markdown","source":"# <a id=\"12\"></a> Conclusion\n#### [Return Contents](#0)\n<hr/>\nWhen we look at the evaluation table, **Polynomial Regression** is the best. However, each model might be useful depending to the situation."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}