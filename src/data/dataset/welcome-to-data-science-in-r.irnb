{"cells":[{"metadata":{"_uuid":"4dc233022959a6f54b1d07c68ef89d8477bf37be","_cell_guid":"813f0dfc-fb16-41e1-b87d-d667bddc8d70"},"cell_type":"markdown","source":"# Introduction\n\nCongrats on starting your data science journey! Machine learning is a powerful tool, and this tutorial will help you start using it, as well as introduce you to some important concepts.\n_____________________\n### What will I learn?\nBy time you finish this tutorial, you will:\n\n* Understand what a machine learning model is\n* Build a machine learning model to predict house prices\n* Learn how to evaluate and improve your model\n\n### What do I need to know before I get started?\nThis tutorial will assume that you're familiar with some very basic R concepts, like functions and arguments. If you're brand new to programming, I recommend you work through [this tutorial series](https://www.kaggle.com/rtatman/getting-started-in-r-first-steps/), which doesn't assume any background, before getting started.\n### What will I need to do?\nAs you complete this tutorial, there will be a number of exercises for you to complete. The exercises are in [a seperate notebook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook/), so you can keep all your work in one place. \n\n___\n<center> \n__Ready? Let's get started! :D__\n\n\n___"},{"metadata":{"_uuid":"d61ecec96c2bff75310568d2ff606504dd1e9cf2","_cell_guid":"7721baf6-6b1a-4b55-aca5-3c2454b3f265"},"cell_type":"markdown","source":"____\n\n# Table of Contents\n\n* [How models work](#How-models-work)\n* [Starting your machine learning project](#Starting-your-machine-learning-project)\n* [Running your first model](#Running-your-first-model)\n* [How do we know if our model is good?](#How-do-we-know-if-our-model-is-good?)\n* [Underfitting/overfitting and improving your model](#Underfitting/overfitting-and-improving-your-model)\n* [A different type of model: Random forests](#A-different-type-of-model:-Random-forests)\n\n_____\n"},{"metadata":{"_uuid":"aa5fb2e38745512f07818caf775954cda1d8543c","_cell_guid":"8a3dc199-581d-4afb-866f-b9a688de255c"},"cell_type":"markdown","source":"# How models work\n\nWe make a lot of predictions in our everyday life. For example, I might predict that my phone will run out of battery during the day if I don't charge it the night before. Or I might predict that it will rain if the sky is overcast and I hear thunder. What prediction we make in a specific situation depends on our past experiences and conditions at the time we make our prediction. Machine learning models work a lot like people do: they build on examples they've been seen previously to predict what the outcome will be given a specific set of conditions.\n\nFor this lesson, we'll be looking at something a little more high-stakes than whether your phone will run out of battery before you get home: **can you figure out how much a house will sell for?**\n\nWe're going to be focusing on a specific type of machine learning model called decision trees. There are many different kinds of machine learning models, each with its own strengths and weaknesses, but decision trees are a good choice to start with because they're flexible, easy for a human to understand and form the basic building block for some very powerful models.\n\n____\n\nLet's start out with the simplest possible decision tree. \n\n![First Decision Trees](http://i.imgur.com/7tsb5b1.png)\n\nIt divides houses into only two categories. You predict the price of a new house by finding out which category it's in, and the prediction is the historical average price from that category.\n\nThis captures the relationship between house size and price. We use data to decide how to break the houses into two groups,  and then again to determine the predicted price in each group.  This step of capturing patterns from data is called **fitting** or **training** the model. The data used to **fit** the model is called the **training data**.  After the model has been fit, you can apply it to new data to **predict** prices of additional homes.\n\n> **How does the tree know what splits to make?** There are several different approaches to building decision trees. The \nThe most common is to pick the feature and value that will split our data into sub-groups that are as homogenous as possible. So if you're trying to predict the weight of a set of birds made up of ostriches and hummingbirds, it makes sense to split the dataset based on the species of the birds since the weights of the ostriches are closer to each other than to the weights of the hummingbirds.\n\n---\n\nAssuming your decision tree works in a sensible way, which of the two trees shown here do you think you might get from **fitting** this especially simple decision tree?\n\n![First Decision Trees](http://i.imgur.com/prAjgku.png)\n\n---\n\nThe decision tree on the left (Decision Tree 1) probably makes more sense, because it captures the reality that houses with more bedrooms tend to sell at higher prices than houses with fewer bedrooms.  The biggest shortcoming of this model is that it doesn't capture most factors affecting home price, like number of bathrooms, lot size, location, etc. \n\nYou can capture more factors using a tree that has more \"splits.\" These are called \"deeper\" trees. A decision tree that also considers the total size of each house's lot might look like this: \n![Depth 2 Tree](http://i.imgur.com/R3ywQsR.png)\n\nYou predict the price of any house by tracing through the decision tree, always picking the path corresponding to that house's characteristics. The predicted price for the house is at the bottom of the tree.  The point at the bottom where we make a prediction is called a **leaf.**   \n\nThe splits and values at the leaves will be determined by the data, so it's time for you to check out the data you will be working with.\n\n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_uuid":"cb26ccb08527c01b370e059cf587ae648f19009f","_cell_guid":"017f6fe7-d3d1-49c1-a5b3-7698e472a9c0"},"cell_type":"markdown","source":"# Starting your machine learning project\n\nYou will build a simple model and then continually improve it as you go through the Machine Learning Track. It is easiest to keep one browser tab (or window) for the tutorials you are reading, and a separate browser window with the code you are writing. You will continue writing code in the same place even as you progress through the sequence of tutorials.\n\n** The starting point for your project is [here](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook/).  Open that link in a new tab. Then hit the \"Fork Notebook\" button towards the top of the screen.**\n\n![Imgur](https://i.imgur.com/GRtMTWw.png)\n\n### Working in Kaggle Notebooks\nYou will be coding in a \"notebook\" environment. These allow you to easily see your code and its output in one place.  A couple tips on the Kaggle notebook environment:\n\n1) It is composed of \"cells.\"  You will write code in the cells. Add a new cell by clicking on a cell, and then using the buttons in that look like this. ![Imgur](https://i.imgur.com/Lscji3d.png) The arrows indicate whether the new cell goes above or below your current location. <br><br>\n2) Execute the code in the current cell with the keyboard shortcut Control-Enter.\n\n---\n### Your Data\n\nYou will see examples predicting home prices using data from Melbourne, Australia. You will then write code to build a model predicting prices in the US state of Iowa. The Iowa data is pre-loaded in [your workbook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook/).\n\nFrom the notebook tab where you are writing code, pull up descriptions of the **data fields** for your data by clicking on Input Files on the top left of the notebook:\n![Imgur](https://i.imgur.com/KDfKRwH.png)\n\nThe left sidebar shows your data is broken into three files. We will use a file called **train.csv**.  But, don't worry about this for now. \n\nInstead, scroll down to see a list of the types of information available in this dataset. \n\n\nOnce you've looked at the contents of your data, return to the coding interface by clicking on the *Input Files* link again, which now has a minus sign next to it.\n\n---\n### Read our data into R\n\nThe first thing you'll want to do is familiarize yourself with the data.  You'll use the Tidyverse library for this. To use the library, we're going to have to load it into R.\n\n> **Tidyverse**: A collection of R packages built around the central idea that data should be formatted with each variable as a column, each observation as a row, and each type of observational unit as a seperate table. You can find more information [here](https://www.tidyverse.org/packages/). "},{"metadata":{"_kg_hide-output":true,"_uuid":"92261902919433e77d384952f8154d8afe913a64","trusted":false,"_cell_guid":"57787c9b-f96d-4709-b9c3-6dae4ab01377"},"cell_type":"code","source":"# load in packages we'll use\nlibrary(tidyverse) # utility functions\nlibrary(rpart) # for regression trees\nlibrary(randomForest) # for random forests\n\n# read the data and store data in DataFrame titled melbourne_data\nmelbourne_data <- read_csv(\"../input/melb_data.csv\") ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b2d920f69ddc89cd99ba22bfecfea887c9eb7733","_cell_guid":"92392c5c-2071-48b2-884b-585d842ce2a2"},"cell_type":"markdown","source":"Above, we read our data into a special type of data frame called a tibble. Data frames are the fundamental data structure in R. They hold the type of data you might think of as a table. This is similar to a sheet in Excel, or a table in a SQL database. Let's start by looking at a basic data overview with our example data from Melbourne and the data you'll be working with from Iowa.\n\n> **Tibbles** are just data frames with some extra features that make them easier to work with. You can do everything with a tibble that you can do with a regular data frame, and they automatically take care of a lot of things that tend to trip folks up. If you absolutely, positively have to have a pl data frame, read your data in with the function read.csv() rather than the function read_csv().\n\nThe example will use data at the file path **`../input/melb_data.csv`**.  Your data will be available in your notebook at **`../input/train.csv`** (which is already typed into the sample code for you).\n\nNow that we have our data in R, let's summarize it!"},{"metadata":{"_uuid":"562d12ee10d79f4d2c6aabca956fdd97e65a62d0","trusted":false,"_cell_guid":"cf5a9405-2264-4644-96e4-57d755c86019"},"cell_type":"code","source":"# print a summary of the data in Melbourne data\nsummary(melbourne_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac2dd38f73971cc9ee7fac443fa8d7f32d5f755d","_cell_guid":"cea3b1ca-2403-4c96-a20a-79ef99cfd3f6"},"cell_type":"markdown","source":"### Interpreting the summary\n\nThat's a lot of output! Each little chunk of output (e.g. \"X1\", \"Suburb\", \"Address\", \"Rooms\") tell us about a specific column in our dataframe. The information you're given for each column depends on the type of data that's in that column. If it's not numeric, like the \"Suburb\" column, it will just tell you some general information about the class of the data in the column.\n\nIf the column *is* numeric, though, it will list information about the mean, median, 25th and 75th quartiles, minimum and maximum. You can use this information to quickly answer some simple questions about your dataset. For example:\n\n* What is the median year in which the houses in this dataset were built?\n* What was the maximum number or rooms?\n\n_____________\n\n### Your turn: \n\nHead over to [the workbook for this lesson](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook/) and summarize the iowa_data data frame that's already been read in for you.\n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_kg_hide-output":true,"_cell_guid":"0c05185a-20eb-4160-baee-46ebdada2402","_uuid":"5358d090691ef529e8af91fa9b836f5ab0897d21","trusted":false,"_kg_hide-input":true},"cell_type":"code","source":"# The Melbourne data has some missing values (some houses for which some variables \n# weren't recorded.) We'll learn to handle missing values in a later tutorial.  \n# Your Iowa data doesn't have missing values in the predictors you use. \n# So we will take the simplest option for now, and drop those houses from our data. \n# Don't worry about this much for now, though the code is:\n\n# dropna drops missing values (think of na as \"not available\")\nmelbourne_data <- na.omit(melbourne_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56777f562e08528f2e23743c7ec1d5fe52d6ae00","_cell_guid":"eb5e0826-8ee3-42b3-910d-e034d6173987"},"cell_type":"markdown","source":"# Running your first model\n\nSo far we've: \n\n* learned about the general idea behind decision trees\n* read in & summarized our data\n\nNow we're finally ready to get to the good stuff: building our own machine learning model! \n\n### Choosing the Prediction Target\n\nYou have the code to load your data, and you know how to index it. You are ready to choose which column you want to predict. This column is called the **prediction target**. For this example, we'll be predicting the \"Price\" variable.\n\n### Choosing Predictors\nNext we select the predictors. Sometimes, you will want to use all of the variables except the target.\n\nIt's possible to model with non-numeric variables, but we'll start with a narrower set of numeric variables.  In the example data, we'll be using the number of rooms, the number of bathrooms, how big the lot is, how big the building is, the year it was built and where the lot is. \n\n---\n### Building Your Model\n\nThe steps to building and using a model are:\n* **Define:** What type of model will it be?  A decision tree?  Some other type of model? Some other parameters of the model type are specified too.\n* **Fit:** Capture patterns from provided data. This is the heart of modeling.\n* **Predict:** Just what it sounds like\n* **Evaluate**: Determine how accurate the model's predictions are.\n\nWe're going to use the rpart() function from the rpart package to build our decision tree. This is where we're going to use the prediction target and predictors we picked earlier. We're going to pass them to the rpart() function using a specific formula syntax that looks like this:\n\n> prediction_target ~ predictor1 + predictor2 + preditor3\n\nThis tells the function that we want to predict the prediction_target variable based on the values of predictor1, predictor2, and predictor3. You can use just the names of the columns, but be sure to tell R to look for the columns in a specific data frame by passing the name of the data frame to the data argument."},{"metadata":{"_uuid":"30f03e7e83032a58090a9a2e9d1ec90c70f3fc30","trusted":false,"_cell_guid":"8a62f855-3266-416c-89bb-51c01b888a11"},"cell_type":"code","source":"# train a decision tree based on our dataset \nfit <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea +\n             YearBuilt + Lattitude + Longtitude, data = melbourne_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"70b8171f67bd6ebb125043dd483d32ced7c6782c","_cell_guid":"18f93d2a-8973-4e87-aa04-58c51ebe8011"},"cell_type":"markdown","source":"If we're curious about what the model is doing, we can actually look at the tree it has built. "},{"metadata":{"_uuid":"67e5ee931af17d0dcbc228c790200fc884db4df7","trusted":false,"_cell_guid":"c262b3ca-e41f-4312-b7d2-9d4ec32f60b0"},"cell_type":"code","source":"# plot our regression tree \nplot(fit, uniform=TRUE)\n# add text labels & make them 60% as big as they are by default\ntext(fit, cex=.6)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e2aa21c4cf105833df640ffb32b9968d30fae570","_cell_guid":"b25df79b-5304-494e-90a5-d7df78dd8933"},"cell_type":"markdown","source":"We can now use our fitted model to predict the prices of some houses, using the predict() function."},{"metadata":{"_uuid":"a60a6bb2e9c70cfff4b2f8c2ec0f25d892c61460","trusted":false,"_cell_guid":"55664948-71ce-4504-8bba-ef937dc5932b"},"cell_type":"code","source":"print(\"Making predictions for the following 5 houses:\")\nprint(head(melbourne_data))\n\nprint(\"The predictions are\")\nprint(predict(fit, head(melbourne_data)))\n\nprint(\"Actual price\")\nprint(head(melbourne_data$Price))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a08c19cd9390f13e251902c078ae6cabcc641a8e","_cell_guid":"d5e0521b-473a-4c4b-87f0-1b3744030f42"},"cell_type":"markdown","source":"___\n### Your turn:\nHead over to [your workbook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook) and train a decision tree on a different set of training data.\n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_uuid":"5d835d4974e64890a558193d5740fe74041c1f64","_cell_guid":"d1755585-05f7-455d-a611-62aaee2c39c2"},"cell_type":"markdown","source":"# How do we know if our model is good?\n\nYou've built a model. But how good is it?\n\nYou'll need to answer this question for almost every model you build. In most (though not necessarily all) applications, the relevant measure of model quality is predictive accuracy. In other words, we want to know if the model's predictions are close to what actually happened.\n\nOne way that you could measure this is by making predictions with the same data you used to train your model by comparing those predictions to the actual target values in the training data. This approach has a critical shortcoming, which you will see in a moment (and which you'll subsequently see how to solve).\n\nEven with this simple approach, you'll need to summarize the model quality into a form that someone can understand. If you have predicted and actual home values for 10000 houses, you will inevitably end up with a mix of good and bad predictions. Looking through such a long list would be difficult and it would be hard to summarize your findings.\n\nThere are many metrics for summarizing model quality, but we'll start with one called Mean Absolute Error (also called MAE). Let's break down this metric starting with the last word, error.\n\nThe prediction error for each house is: \n\n> error=actual−predicted\n\nSo, if a house cost 150,000 dollars and you predicted it would cost 100,000 dollars the error is 50,000 dollars.\n\nWith the MAE metric, we take the absolute value of each error. This converts each error to a positive number. We then take the average of those absolute errors. This is our measure of model quality. In plain English, it can be said as\n\n> On average, our predictions are off by about X.\n\nWe can get the MAE for our model using the mae() function, from the modelr package. The mae() function takes in a model and the dataset to test it against. \n"},{"metadata":{"_uuid":"d53e1b5644f734d94a1ab075d5cc3427e017ec2d","trusted":false,"_cell_guid":"965e3c9d-c655-4124-84e8-9b0e617ac57b"},"cell_type":"code","source":"# package with the mae function\nlibrary(modelr)\n\n# get the mean average error for our model\nmae(model = fit, data = melbourne_data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"79e8d49a386b2e7b5f902f4d53f2fde5aef57c2e","_cell_guid":"36a32585-0b5b-4097-aa0b-7f9e5d9e3038"},"cell_type":"markdown","source":"### The Problem with \"In-Sample\" Scores\n\nThe measure we just computed can be called an \"in-sample\" score. We used a single set of houses (called a data sample) for both building the model and for calculating it's MAE score. This is bad.\n\nImagine that, in the large real estate market, door color is unrelated to home price. However, in the sample of data you used to build the model, it may be that all homes with green doors were very expensive. The model's job is to find patterns that predict home prices, so it will see this pattern, and it will always predict high prices for homes with green doors. \n\nSince this pattern was originally derived from the training data, the model will appear accurate in the training data. But this pattern likely won't hold when the model sees new data, and the model would be very inaccurate (and cost us lots of money) when we applied it to our real estate business.\n\nModels' practical value come from making predictions on new data, so we should measure performance on data that wasn't used to build the model. The most straightforward way to do this is to exclude some of our data from the model-building process, and then use those to test the model's accuracy on data it hasn't seen before. This data is called validation data.\n\nWe can split our dataframe into testing and training data very easily using the resample_partition() function from the modelr package. "},{"metadata":{"_uuid":"3fd871ea8f45faca07617a013697f2a9cd4e9fcd","trusted":false,"_cell_guid":"72f05a57-af82-4e94-b24a-77adc84a09d0"},"cell_type":"code","source":"# split our data so that 30% is in the test set and 70% is in the training set\nsplitData <- resample_partition(melbourne_data, c(test = 0.3, train = 0.7))\n\n# how many cases are in test & training set? \nlapply(splitData, dim)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2093807ed32c0def29680702bad656a9be9af622","_cell_guid":"02066ddb-55a1-47ac-906e-1a3f8679ff15"},"cell_type":"markdown","source":"We can then fit a new model using our training data and test it using our testing data."},{"metadata":{"_uuid":"053389169fc5ea93d87bcba12a0fd5b9e5a3a951","trusted":false,"_cell_guid":"a900c294-c19b-47b5-9c48-b7280818e369"},"cell_type":"code","source":"# fit a new model to our training set\nfit2 <- rpart(Price ~ Rooms + Bathroom + Landsize + BuildingArea +\n             YearBuilt + Lattitude + Longtitude, data = splitData$train)\n\n# get the mean average error for our new model, based on our test data\nmae(model = fit2, data = splitData$test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ff256fd3eabbfb9c9d1288a3b4137eff4aee596","_cell_guid":"17632dc2-23d6-40b0-9560-1685b22e0692"},"cell_type":"markdown","source":"As you can see, our error is slightly higher now. However, we can also be more certain that it wasn't artificially lowered by by testing on the training data.\n\n___\n### Your turn:\nHead over to [your workbook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook) and evaluate the model you made earlier. Then try splitting your data in to testing and training data, training a model with the training portion and testing with the testing portion.\n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_uuid":"9ec7ab2ae6f17f74bd5880db0a916c605d92b558","_cell_guid":"9917bf9d-3456-4482-9399-0627a9b53b2e"},"cell_type":"markdown","source":"# Underfitting/overfitting and improving your model\n\nNow that you have a trustworthy way to measure model accuracy, you can experiment with alternative models and see which gives the best predictions.  But what alternatives do you have for models?\n\n### Experimenting With Different Models\n\nYou can see in rpart's [documentation](https://www.rdocumentation.org/packages/rpart/versions/4.1-11/topics/rpart) that the decision tree model has many options (more than you'll want or need for a long time). \n\nOne important option is \"maxdepth\" which allows you to set the maximum depth of any node of the final tree. The depth of a node is the total number of nodes you have to go through to get from the root node to the leaf node, including the leaf node.\n\n> The **root node** is the single node at the top of the tree that all the other nodes can eventually be traced back to. A **leaf node** is a node at the bottom of the tree that doesn't have any other nodes below it. \n\nSo in this (relatively shallow) tree, the maximum depth is 2. The maximum depth of a tree is also known as the tree's height. So this is a relatively shallow tree that has a height of 2 because its deepest node has a depth of two. \n\n![Depth 2 Tree](http://i.imgur.com/R3ywQsR.png)\n\nIn practice, it's not uncommon for a tree to have a height of 10.  As the depth of the nodes increase, the dataset gets sliced up into leaves with fewer houses.  If a tree only had 1 split, it divides the data into 2 groups. If each group is split again, we would get 4 groups of houses.  Splitting each of those again would create 8 groups.  If we keep doubling the number of groups by adding more splits at each level, we'll have \\\\(2^{10}\\\\) groups of houses by the time we get to the 10th level. (That's 1024 leaves!)  \n\nWhen we divide the houses amongst many leaves, we also have fewer houses in each leaf.  Leaves with very few houses will make predictions that are quite close to those homes' actual values, but they may make very unreliable predictions for new data (because each prediction is based on only a few houses).\n\nThis is a phenomenon called **overfitting**, where a model matches the training data almost perfectly, but does poorly in validation and other new data.  On the flip side, if we make our tree very shallow, it doesn't divide up the houses into very distinct groups.  \n\nAt an extreme, if a tree divides houses into only 2 or 4, each group still has a wide variety of houses. Resulting predictions may be far off for most houses, even in the training data (and it will be bad in validation too for the same reason). When a model fails to capture important distinctions and patterns in the data, so it performs poorly even in training data, that is called **underfitting**.  \n\nSince we care about accuracy on new data, which we estimate from our validation data, we want to find the sweet spot between underfitting and overfitting.  Visually, we want the low point of the (red) validation curve in\n\n![underfitting_overfitting](http://i.imgur.com/2q85n9s.png)\n\n### Example\nThere are a few alternatives for controlling the tree depth, and many allow for some routes through the tree to have greater depth than other routes.  But the *maxdepth* argument provides a very sensible way to control overfitting vs underfitting.  The more leaves we allow the model to make, the more we move from the underfitting area in the above graph to the overfitting area.\n\nWe can use a utility function to help compare MAE scores from different values for *maxdepth*:\n\n"},{"metadata":{"_uuid":"d24fb64d461ada4e206a851334a9f55ea4286869","trusted":false,"_cell_guid":"2711cab6-f466-4a8c-9230-e7aa268a85ae"},"cell_type":"code","source":"# a function to get the maximum average error for a given max depth. You should pass in\n# the target as the name of the target column and the predictors as vector where\n# each item in the vector is the name of the column\nget_mae <- function(maxdepth, target, predictors, training_data, testing_data){\n    \n    # turn the predictors & target into a formula to pass to rpart()\n    predictors <- paste(predictors, collapse=\"+\")\n    formula <- as.formula(paste(target,\"~\",predictors,sep = \"\"))\n    \n    # build our model\n    model <- rpart(formula, data = training_data,\n                   control = rpart.control(maxdepth = maxdepth))\n    # get the mae\n    mae <- mae(model, testing_data)\n    return(mae)\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d5a62a2bd22c594f61e1d97bb9642c3971366a4","_cell_guid":"a832e751-6751-4379-a781-90323ef1b1ea"},"cell_type":"markdown","source":"We can use a for-loop to compare the accuracy of models built with different values for *maxdepth.*  In this case, the lowest MAE is actually 5. \n\nYou may notice that after a certain depth the MAE levels out. This is because, given this dataset and our current stopping condition, 6 is the maximum number of nodes that rpart will create a tree with. Rpart has some built-in safegaurds to prevent overfitting that won't generate a deeper tree for this dataset."},{"metadata":{"_uuid":"eaf41d967ad7764d8dda48d4316959167239c073","trusted":false,"_cell_guid":"85945eb1-712b-4c79-8395-2aff1f58faae"},"cell_type":"code","source":"# target & predictors to feed into our formula\ntarget <- \"Price\"\npredictors <-  c(\"Rooms\",\"Bathroom\",\"Landsize\",\"BuildingArea\",\n                 \"YearBuilt\",\"Lattitude\",\"Longtitude\")\n\n# get the MAE for maxdepths between 1 & 10\nfor(i in 1:10){\n    mae <- get_mae(maxdepth = i, target = target, predictors = predictors,\n                  training_data = splitData$train, testing_data = splitData$test)\n    print(glue::glue(\"Maxdepth: \",i,\"\\t MAE: \",mae))\n}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7921256bc65530f2f70ea12f0ddd6703c001bd70","_cell_guid":"5fbd1bfa-0c93-4b67-934d-7501addefab7"},"cell_type":"markdown","source":"# Conclusion\n\nHere's the takeaway: Models can suffer from either:\n- **Overfitting:** capturing spurious patterns that won't recur in the future, leading to less accurate predictions, or \n- **Underfitting:** failing to capture relevant patterns, again leading to less accurate predictions. \n\nWe use **validation** data, which isn't used in model training, to measure a candidate model's accuracy. This lets us try many candidate models and keep the best one. "},{"metadata":{"_uuid":"28e1e30c1750ae9936fc6c6da5775cbd50efdfb7","_cell_guid":"d545f84e-3e23-41d3-9fd4-55044878674b"},"cell_type":"markdown","source":"______\n### Your turn:\n\nIn the near future, you'll be efficient writing functions like `get_mae` yourself, but for now you can use the one I wrote above; it's already been copied into [your workbook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook). You'll use a for loop that tries different values of *maxdepth* and calls the *get_mae* function on each to find the ideal number of leaves for your Iowa data.\n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_uuid":"6176c9a88a6eaf03f6c594133d3411452c273443","_cell_guid":"0eee778b-39d6-494b-8049-51430389cb27"},"cell_type":"markdown","source":"# A different type of model: Random forests\n\nDecision trees leave you with a difficult decision. A deep tree with lots of leaves will overfit because each prediction is coming from historical data from only the few houses at its leaf. But a shallow tree with few leaves will perform poorly because it fails to capture as many distinctions in the raw data.\n\nEven today's most sophisticated modeling techniques face this tension between underfitting and overfitting. But, many models have clever ideas that can lead to better performance. One example is the cleverly named Random Forest.\n\nThe random forest uses many trees, and it makes a prediction by average the predictions of each component tree. It generally has much better predictive accuracy than a single decision tree and it works well with default parameters. If you keep modeling, you can learn more models with even better performance, but many of those are sensitive to getting the right parameters. \n\nOne of the nice thing about R is that the syntax you use to build models across different packages is pretty consistent. All we need to change in order to use a random forest instead of a plain decision tree is to load in the correct library & change the function we use from rpart() to randomForest(), like so:"},{"metadata":{"_kg_hide-output":false,"_uuid":"da54e7ed7ee0a047d836c4a3657a94dc1a53de3e","trusted":false,"_cell_guid":"a188aeb6-e2c0-4671-b6c8-903f7b7697c7"},"cell_type":"code","source":"# fit a random forest model to our training set\nfitRandomForest <- randomForest(Price ~ Rooms + Bathroom + Landsize + BuildingArea +\n             YearBuilt + Lattitude + Longtitude, data = splitData$train)\n\n# get the mean average error for our new model, based on our test data\nmae(model = fitRandomForest, data = splitData$test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c4456fe265533ddb4e19452141177a008bae0388","_cell_guid":"639dbac2-a9ca-4ff5-b3a4-abb89ac6af25"},"cell_type":"markdown","source":"### Conclusion \nThere is likely room for further improvement, but this is a big improvement over our previous best decision tree, which was around 320,000 dollars off. There are parameters which allow you to change the performance of the Random Forest much as we changed the maximum depth of the single decision tree. But one of the best features of Random Forest models is that they generally work reasonably even without this tuning.\n\nYou'll soon learn the XGBoost model, which provides better performance when tuned well with the right parameters (but which requires some skill to get the right model parameters).\n\n___\n\n### Your turn:\nHead over to [your workbook](https://www.kaggle.com/rtatman/welcome-to-data-science-in-r-workbook) and fit a randomForest on your data. You should see a big improvement over your best Decision Tree models.  \n___\n<center> \n__[Back to the Table of Contents](#Table-of-Contents)__\n\n------"},{"metadata":{"_uuid":"a671432dd73d19d8c18e7e79533ebf3725eaa1e3","_cell_guid":"7241e737-2647-45e4-a868-f610233ae675"},"cell_type":"markdown","source":"# Conclusion\n\nNice work! Now that you've got your feet wet with machine learning, you're ready to train new models on new datasets. If you're looking to enter a competition, you can [check out this kernel, that will walk you through putting together your submission file](https://www.kaggle.com/rtatman/preparing-a-competition-submission-file-in-r/).\n\nUnfortunately, not all data is as clean as the examples we've been using here. In the next lesson in this series, we'll learn how to use R and the Tidyverse to clean and interact with datasets in a fast, reproducible way."}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"mimetype":"text/x-r-source","name":"R","pygments_lexer":"r","version":"3.4.2","file_extension":".r","codemirror_mode":"r"}},"nbformat":4,"nbformat_minor":1}