{"nbformat_minor": 1, "cells": [{"cell_type": "markdown", "source": ["# Introduction\n", "\n", "The fact that the Porto Seguro competition is a binary classification task (the customer filed a claim or did not) makes it an excellent opportunity to brush up on two fundamental modelling and evaluation tasks for binary classifiers:\n", "\n", "1. Logistic Regression\n", "2. The ROC curve\n", "\n", "Logistic regression is a derivative of linear regression where we are interested in making binary predictions or probability predictions on the interval [0, 1] with a threshold probability to determine where we split between 0 and 1. \n", "The ROC curve or \"receiver operating characteristic\" curve is an evaluation method we can use to assess the efficacy of a binary classification algorithm (\"Receiver Operating Characteristic\", n.d.) as well as choose the optimal threshold based on our tolerance for false negatives and desire for true positives. "], "metadata": {"_uuid": "753c257ba3921ff5c430e4cca350ef0937ef27f2", "_cell_guid": "92858133-491d-465c-a09d-8ab3902a7d6e"}}, {"cell_type": "markdown", "source": ["# A Simple Example"], "metadata": {"_uuid": "7b72a80cb1b48ade86252d5569c56bfe1ddee847", "_cell_guid": "145e3677-f37d-4a87-bddb-0f7aad6d5365"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7aed800556d86afac625a0c68f976e172668dc2d", "_cell_guid": "92ce55f4-c81b-48ce-bb2d-52408faa0f22"}, "outputs": [], "source": ["suppressPackageStartupMessages(library(tidyverse))\n", "suppressPackageStartupMessages(library(caret))\n", "suppressPackageStartupMessages(library(verification))\n", "library(repr)\n", "\n", "options(repr.plot.height = 5, repr.plot.width = 6)"]}, {"cell_type": "markdown", "source": [" Before we dig into the Porto data set, let's refresh our memory and take in some theory using  very contrived data. Let's say that we have a small data set on insurance claims consisting of only two variables - a binary variable (0 or 1) indicating whether or not a driver filed a claim and a driver age variable. This fake data set will be quite small for illustrative purposes."], "metadata": {"_uuid": "6d286a024becd471f3d36285362e7440e0ba1c87", "_cell_guid": "b27ca010-bd7d-40f2-92bf-a43b27fecb94"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "50954a4d2dd4d100727668880e822054aecd5d76", "_cell_guid": "45e1f504-a2e5-4b84-bfd6-9006fed23517"}, "outputs": [], "source": ["# generate fake insurance dataset\n", "set.seed(12)\n", "insurance <- data.frame(\n", "    claim = c(rep(1, 20), rep(0, 20)),\n", "    age = c(rnorm(20, mean = 25, sd = 5), rnorm(20, mean = 37, sd = 7)))"]}, {"cell_type": "markdown", "source": ["Let's see what these data look like when plotted:"], "metadata": {"_uuid": "666a731ddb7a5a1d6b3d09ad2ad1df5463c51650", "_cell_guid": "362db402-5756-4f45-bcc2-613b4d05dcf4"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "afc6203e4fde445c5a6c734fa345e8f1fc4548ed", "_cell_guid": "3bc3a6c6-af33-4ed8-b223-f4567826b3d1"}, "outputs": [], "source": ["# plot the insurance data\n", "ggplot(data = insurance, aes(x = age, y = claim)) +\n", "    geom_point(color = 'grey50') + \n", "    theme_bw()"]}, {"cell_type": "markdown", "source": ["From this plot we can see that those at the younger end of the age spectrum have filed more claims than those at the upper end of the age spectrum. This goes along with our intuition that older drivers are generally more experienced and less likely to be involved in an accident. Of course there is no perfect separation. Some drivers under 30 have not filed a claim while other drivers over 30 have. Nevertheless note that such clear delineation is not likely to occur in the real world. This is a very contrived example to make a point. \n", "\n", "You are already familiar with linear regression in which we try to model a continuous variable as a linear combination of features. What if we tried to run linear regression with this binary dependent variable as a function of driver age? Would it work? Let's find out.        "], "metadata": {"_uuid": "a1eefd4e5cf42f83c11fd68551369a9200d9dd37", "_cell_guid": "48583533-02c3-4f13-940b-4b06c471afab"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "fe7b2c8cadc27ebf2b2df6cff2ebe64bad059568", "_cell_guid": "0a6fea37-3be7-414c-839b-85341a813b3d"}, "outputs": [], "source": ["# regress claim on age\n", "lmmod <- lm(claim ~ age, data = insurance)\n", "\n", "# plot the data and the regression line\n", "ggplot(data = insurance, aes(x = age, y = claim)) +\n", "    geom_point(color = 'grey50') + \n", "    geom_abline(intercept = coef(lmmod)[1], slope = coef(lmmod)[2], color = 'red') + \n", "    theme_bw()"]}, {"cell_type": "markdown", "source": ["This kind of works, but it's quite awkward. The regression line has captured the fact that older drivers are less likely to file a claim as indicated by the negative slope. But how would we actually decide how to make the classification? We could choose some arbitrary point on the regression line and classify everything above that line as a 1 (claim filed) and everything below it as a 0 (no claim filed). But which point should we choose? Secondly, what about the part of the regression line that goes below 0 on the y axis? A negative value is completely nonsensical in this context. The same is true for any prediction above 1. \n", "\n", "We want to know the probability that the dependent variable is 1 given X:\n", "\n", "$$P(y = 1 \\mid X)$$,\n", "\n", "where X represents the features. For short, let's just call it:\n", "\n", "$$P(x)$$\n", "\n"], "metadata": {"_uuid": "6a0335221f29b465d32a9f48fdc530b041db8428", "_cell_guid": "8e246606-6519-4dbf-8555-027f93ec3e37"}}, {"cell_type": "markdown", "source": ["This problem can be solved by combinin the log-odds, the logistic function and the sigmoid function. Let's begin with odds and how they relate to probabilities. One area where you may have encountered odds before is horse racing. Given a probability, we can convert to odds by taking that probability and dividing by 1 minus that probability. This is a ratio of the probability that the event occurs over the probability that the event does not occur:\n", "\n", "$$\\frac{P(x)}{1-P(x)}$$\n", "\n", "Next, note that the log-odds is simpy the natural log of the odds function:\n", "\n", "$$\\log\\left({\\frac{P(x)}{1-P(x)}}\\right)$$\n", "\n", "This function is commonly called the 'logit' function. For logistic regression, we assume that we can express the log-odds, or logit, of the dependent variable as a linear combination of the independent variables (Zumel, 2011):\n", "\n", "$$\\log\\left({\\frac{P(x)}{1-P(x)}}\\right) = \\beta_0X_0 + \\beta_1X_1 + ... +  B_jX_j$$\n", "\n", "Finally, the last piece of the puzzle is the sigmoid function (\"Sigmoid Function\", n.d.):\n", "\n", "$$\\frac{1}{1+e^{-x}}$$\n", "\n", "\n", "Let's put the sigmoid into code:"], "metadata": {"_uuid": "a22c3201324256d2e9e2a163ae2dfd1055af39e8", "_cell_guid": "8b946ed0-a714-4f01-9952-b1a478892e6a"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "f5e31163d965c28499f53b7052af3dd4c2979f1e", "_cell_guid": "fc7cc070-2dc0-4cfb-8f20-bcdb11a701e2"}, "outputs": [], "source": ["sigmoid <- function(x) { \n", "    \n", "    1 / (1 + exp(-x)) \n", "    \n", "}"]}, {"cell_type": "markdown", "source": ["Then we plot the sigmoid for values of x between -5 and 5 for every 0.5 step."], "metadata": {"_uuid": "167e2b9ac8f6b163fbc301eb1e6d37962a719621", "_cell_guid": "3e963d8e-be1e-49a1-bf60-11a0ddd6cde3"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "0b491dac4ff6ce66b47d09f54bdd02b3216e7395", "_cell_guid": "0f64d03b-e86a-4851-a36f-007bf12f0106"}, "outputs": [], "source": ["data.frame(x = seq(-5, 5, 0.5), y = sigmoid(seq(-5,5, 0.5))) %>%\n", "    ggplot(aes(x = x, y = y)) + \n", "    geom_line(color = 'red', size = 0.3) + \n", "    geom_vline(xintercept = 0, linetype = 'dashed') + \n", "    labs(y = 'sigmoid(x)', title = 'The Sigmoid Function') + \n", "    theme_bw()"]}, {"cell_type": "markdown", "source": ["Notice how well this fits between 0 and 1. Also no matter how far we go along the x-axis in either direction, the function never actually reaches 0 or 1; it is asymptotic. Compare this plot to the one above. Wouldn't it be nice if we could somehow fit something like this sigmoid curve to that data? It turns out that the sigmoid function is the inverse of the log odds function. If you'd like to see the mathematical derivation of this you can find it [here](http://karlrosaen.com/ml/notebooks/logistic-regression-why-sigmoid/). \n", "\n", "So from our equation above,\n", "\n", "$$\\log\\left({\\frac{P(x)}{1-P(x)}}\\right) = \\beta_0X_0 + \\beta_1X_1 + ... +  B_jX_j$$\n", "\n", "We can derive the following by taking the inverse:\n", "\n", "$$P(x) = \\frac{1}{1+e^{-\\beta_0X_0 + \\beta_1X_1 + ... +  B_jX_j}}$$\n", "\n", "Therefore, once we model the the log-odds as a linear combination of the features, we can pass the results through the sigmoid function to obtain probabilities. \n", "\n", "The generalized linear model handles this for us. All we have to do is specify the link function that it will use in estimation. The glm will then handle the fitting of the data, which is done by [maximum likelihood](http://mathworld.wolfram.com/MaximumLikelihood.html).  We do so as follows:\n"], "metadata": {"_uuid": "19fd3e77f258b34cb0442f3a76f089032b611017", "_cell_guid": "c31cdf14-a136-4635-a981-1667b604a028"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "17edda2350cbb6541a76f0ce4f104fbfe94a1dff", "_cell_guid": "1f1aac96-81ef-457c-b26f-a27815d592cc"}, "outputs": [], "source": ["# estimate the logistic regression model\n", "logmod <- glm(claim ~ age, data = insurance, family = binomial(link = 'logit'))\n", "\n", "# make predictions on the training data\n", "insurance$preds <- predict(logmod, type = 'response')\n", "\n", "# plot results\n", "ggplot(data = insurance, aes(x = age, y = claim)) + \n", "    geom_point(color = 'grey50') + \n", "    geom_line(aes(x = age, y = preds), color = 'red', size = 0.3) + \n", "    theme_bw()"]}, {"cell_type": "markdown", "source": ["Notice that the curve fit to the data by the model resembles the sigmoid function except that it is reflected about x = 0.5 (and shifted right) due to the relationship between `claim` and `age`. Also the, curve never exceeds 1 or falls below 0, so we can interpret the predicted responses as probabilities. "], "metadata": {"_uuid": "1c58be4ce02ac1aae21373a998ba3dc3c097b299", "_cell_guid": "0e2ba356-e4f5-4a9e-90f6-246bcdb05521"}}, {"cell_type": "markdown", "source": ["# The Porto Competition\n", "\n", "Ok enough theory and fake data. Let's get to the Porto Seguro competition. We are going to apply logistic regression to the training data to model claims. In this case the competition hosts are asking for predicted probabilities that each of the customers in the test data filed a claim. We are given 56 anonymized features which we can use to model claims and make predictions. First let's get the data:"], "metadata": {"_uuid": "e02c8f1f24ec30644970c06fed72e07a5b0036f0", "_cell_guid": "766a7962-227f-4813-b25f-cb077b93fef8"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "62b9cc99084a784a872e59f102f23134734c727c", "_cell_guid": "1ba64a92-216a-4f50-8432-aa789229e5c9"}, "outputs": [], "source": ["dtrain <- read_csv('../input/train.csv', col_types = cols())"]}, {"cell_type": "markdown", "source": ["We need to do some preprocessing before we build the model. Although the data for this competition are anonymized, we do know that any variable name ending in `_cat` is an unordered categorical variable and that everything ending in `_bin` is a binary variable. Evereything else is considered to be continous. We will want to turn the categorical features into factor variables and then perform one-hot encoding (or dummy variable encoding). If we don't, we will be regressing the `target` variable on numeric data that is largely meaningless. Before we do this however, we need to do something about the missing values lest they screw up our encoding. Missing data is this dataset are written as -1 rather than the standard `NA`. We want to convert these -1's to NA so that any missing categorical data doesn't get encoded as an additional factor level. "], "metadata": {"_uuid": "46d0c1cd9221247388c41453ee393f0564550c3d", "_cell_guid": "9b9c84ce-fb20-4788-96ee-c2e1dd9f8910"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "893d9a2ac0876a6bdc0455bc17ee1f0b348078f4", "_cell_guid": "7cbef1c9-8aa0-43f8-b862-2a24388672c9"}, "outputs": [], "source": ["# Set missing values to NA \n", "dtrain[dtrain == -1] <- NA\n", "\n", "# collect the categorical variable names\n", "cat_vars <- names(dtrain)[grepl('_cat$', names(dtrain))]\n", "\n", "# convert categorical features to factors\n", "dtrain <- dtrain %>%\n", "    mutate_at(.vars = cat_vars, .funs = as.factor)\n", "\n", "# One hot encode the factor variables\n", "dtrain <- model.matrix(~ . - 1, data = dtrain)"]}, {"cell_type": "markdown", "source": ["Now that that's done, let's split our data into a train and test set. We want a test set with which to build our ROC curve (more on that later) and test the accuracy of our model. Here I split the data, making the training data only 20% of the total observations to cut down on the model training time in this example. You can (and should) certainly use more. "], "metadata": {"_uuid": "77e559bd8fd988de8868c3a2caa8f1311b7ffe8c", "_cell_guid": "6896589e-e23d-4620-aa4e-32dda1556aca"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5c17f7955558440b1e476eea72e391c49b8a143e", "_cell_guid": "7e8ceb16-f981-44fa-a790-81834953ad01"}, "outputs": [], "source": ["# set seed for reproducibility\n", "set.seed(123)\n", "\n", "# making a train index\n", "train_index <- sample(c(TRUE, FALSE), replace = TRUE, size = nrow(dtrain), prob = c(0.2, 0.8))\n", "\n", "# split the data according to the train index\n", "training <- as.data.frame(dtrain[train_index, ])\n", "testing <- as.data.frame(dtrain[!train_index, ])"]}, {"cell_type": "markdown", "source": ["Often when running logistic regression on larger data sets where we've done a lot of factor encoding we may run into issues with linear dependence among the features. If we try to fit a logistic regression where this is the case, we will get a rank-deficient fit. To alleviate this, we can use the `findLinearCombos` function from the caret package to locate the offending features. Here I run the function and then remove the features as suggested in the `remove` element of the resulting list. "], "metadata": {"_uuid": "3fd1bc4a65570c1e21039460ead5158bcd936e8a", "_cell_guid": "9c94e399-b176-41ff-a3ac-abf6bf16a83b"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "22809f6675630246b539841555d2ba3d85ae3a5c", "_cell_guid": "e993dfb0-a4f2-4b85-8379-67f1d32a103d"}, "outputs": [], "source": ["# find any linear combos in features\n", "lin_comb <- findLinearCombos(training)\n", "\n", "# take set difference of feature names and linear combos\n", "d <- setdiff(seq(1:ncol(training)), lin_comb$remove)\n", "\n", "# remove linear combo columns\n", "training <- training[, d]"]}, {"cell_type": "markdown", "source": ["After doing so, I still ran into a problem with the `ps_ind_02_cat4` feature, which is the binary encoding the the fourth factor level in the `ps_ind_02_cat` feature in the original training data. I've been unable as of yet to determine why this one is a problem, but I am just removing it for now. "], "metadata": {"_uuid": "791c077d5c1a902a3b614dcb1f6c4e9b8df32bc8", "_cell_guid": "0371c583-d1c0-4061-98b7-02c81f87f951"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "e6e1efb28c27d0eb52d0ee6454d67d7447402295", "_cell_guid": "122119ef-dc0a-4d9c-a29f-1c887cc98cb1"}, "outputs": [], "source": ["training <- training[, setdiff(names(training), 'ps_ind_02_cat4')]"]}, {"cell_type": "markdown", "source": ["Now we will build our model. For now we are skipping two things - data exploration and feature engineering - in order to focus on the topic at hand. Here we use the `glm` function to to build the model. We do this in much the same way as the `lm` function except that we need to provide the link function that will convert the results to the logit function. "], "metadata": {"_uuid": "889029bbd5d09c9668c220d48ae5c54727cc1edd", "_cell_guid": "1f615d1c-bd4e-479a-9446-4d8b44698a7b"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "afbd078917fda77ba4ff32af1a7f9d558dd2778f", "_cell_guid": "ae325529-15d4-4e09-86e8-d736d65a5541"}, "outputs": [], "source": ["# estimate logistic regression model on training data\n", "logmod <- glm(target ~ . - id, data = training, family = binomial(link = 'logit'))"]}, {"cell_type": "markdown", "source": ["This takes a few minutes, but once its done we have our results and we can use it to make probability predictions like so:"], "metadata": {"_uuid": "7ce3de82ed85c780f3899b6e475152e46d5bee23", "_cell_guid": "295b9b12-a138-4b33-b901-3b41126efbf3"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "fe64a7761ff9da2edc049af9b3988a44e2d73d53", "_cell_guid": "2b6dee2c-5a8e-41db-bf55-1ebf554adcd7"}, "outputs": [], "source": ["# make predictions on the test set\n", "preds <- predict(logmod, newdata = testing, type = \"response\")"]}, {"cell_type": "markdown", "source": ["Now we have our predictions, which are a vector of probabilities that each customer filed a claim. Let's take a quick look and see what we've got."], "metadata": {"_uuid": "0aea69cf25039f66eb7cce3a4a8ff0e56ca8a78a", "_cell_guid": "23fe69de-9d2c-404b-878c-433759cbb243"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "fa4a2b189d0da06773a6aa0dd4faddfd1fab58a5", "_cell_guid": "a23829f5-e41e-4d51-9179-41162c858be4"}, "outputs": [], "source": ["# plot histogram of predictions\n", "data.frame(preds = preds) %>%\n", "    ggplot(aes(x = preds)) + \n", "    geom_histogram(bins = 50, fill = 'grey50') +\n", "    labs(title = 'Histogram of Predictions') +\n", "    theme_bw()\n", "\n", "# print range of predictions\n", "print(round(range(preds),2))\n", "\n", "# print median of predictions\n", "print(median(preds))"]}, {"cell_type": "markdown", "source": ["The predictions range from 0 to 0.54 with a median of only 0.037."], "metadata": {"_uuid": "16b3c3a9e80159f5e2ac144b68e06a987b3b8a2d", "_cell_guid": "6a79a6d3-c3c8-44de-b7c6-68e7f55ea4b2"}}, {"cell_type": "markdown", "source": ["# The ROC Curve\n", "\n", "As stated in the introduction, one very common way of assessing the usefulness of a binary classifier is the ROC curve as well as the area under the ROC curve (AUC). The ROC curve is a simple plot that shows the tradeoff between the true positive rate and the false positive rate of a classifier for various choices of the probability threshold. Before we get started on building our own ROC curve and assessing the quality of our logistic regression model, let's take a look at an example borrowed from the University of Nebraska Medical Center's website [here](http://gim.unmc.edu/dxtests/roc3.htm).\n", "\n", "![ROC Curve](http://gim.unmc.edu/dxtests/roccomp.jpg)\n", "<center>(credit UNMC)</center><br>\n", "\n", "\n", "Here we see three ROC curves that are labelled as 'Excellent', 'Good', and 'Worthless'. These represent the results of three different classifiers of various usefulness. The x-axis show the false positive rate (FPR) from 0 to 1 and the y-axis shows the true positive rate (TPR) from 0 to 1. The plotted lines show, for various cutpoints or choices of threshold, what the these rates are. The closer the curve gets to the top left corner the better the classifier. Notice that a perfect classifier would yield a true positive rate of 1 and a false positive rate of 0. In such an ideal case, the ROC curve would be a straight line from (0,0) to (0,1) and a horizontal line from (0,1) to (1,1). This is why the area under the curve is used as a singular measure for assessing the usefulness of a classifier. For a perfect classifier the area under the ROC curve would be 1:\n", "\n", "$$1TPR \\times 1 FPR$$\n", "\n", "Notice that blue classifer labeled 'worthless'. It is essentially the 45 degree line or the line that starts at (0,0) and has slope 1. This classifier has an area under curve of 0.5 and is considered not of use because it is no better than random guessing. If our curve goes under the 45 degree line (i.e. the AUC is less than 0.5) then we know we've done something wrong because then our model would perform worse than random guessing!\n", "\n", "That's the general idea. Let's build our own ROC curve for our predictions for the Porto competition that we just generated. The first thing that we need to do is determine how many cutpoints that we want to use. I'll keep this small in number for sake of example. Because our predictions range from 0 to 0.54, we'll select cut points within this range. Here I am choosing thresholds of 0.3, 0.2, 0.1, 0.05, 0.04, 0.03, 0.02, and  0.01. Fore each one of these cut points were are going to classify everything above the cut point as the positive class (1 in this case) and everything below as the negative class (0 in this case). Here I do so, putting the results into a dataframe. "], "metadata": {"_uuid": "e224b33333302b12ff20b682e632f0900a460561", "_cell_guid": "5d9334aa-3169-4bcd-a586-ba7c22bb1af8"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "638a9be1e054d804a1a9b6556d4a7f1843da5a04", "_cell_guid": "9d957b64-0dc7-48b6-b7ab-592b70a3e3a0"}, "outputs": [], "source": ["roc_data <- data.frame(\n", "    p0.3 = ifelse(preds > 0.3, 1, 0),\n", "    p0.2 = ifelse(preds > 0.2, 1, 0),\n", "    p0.1 = ifelse(preds > 0.1, 1, 0),\n", "    p0.05 = ifelse(preds > 0.05, 1, 0),\n", "    p0.04 = ifelse(preds > 0.04, 1, 0),\n", "    p0.03 = ifelse(preds > 0.03, 1, 0),\n", "    p0.02 = ifelse(preds > 0.02, 1, 0),\n", "    p0.01 = ifelse(preds > 0.01, 1, 0))"]}, {"cell_type": "markdown", "source": ["Now that we've done that, we need to calculate the true positive rate and false positive rate for each threshold. Because we'll need to caclulate these multiple times, I've created function to calculate the true positive rate, `tpr()`, and the false positive rate `fpr()`. "], "metadata": {"_uuid": "5957b450a9eadc2d0ee05d732107b428344ca68e", "_cell_guid": "ec302b67-b88f-44af-903e-267d834a1591"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "b722f9767b3aa777b362c16f7f09d4adbd83a50f", "_cell_guid": "c55dbae3-6e94-4477-a386-6994d3ede38e"}, "outputs": [], "source": ["# true positive (hit) rate\n", "tpr <- function(pred, actual) {\n", "    res <- data.frame(pred, actual)\n", "    sum(res$actual == 1 & res$pred == 1) / sum(actual == 1)\n", "}\n", "\n", "# false positive rate\n", "fpr <- function(pred, actual) {\n", "    res <- data.frame(pred, actual)\n", "    sum(res$actual == 0 & res$pred == 1) / sum(actual == 0)\n", "}"]}, {"cell_type": "markdown", "source": ["Next we get the true labels from the test data and save them to a variable named `actual` for convenience. "], "metadata": {"_uuid": "05f9d51f6a85b6ae327f0d8a272248e3b869bd42", "_cell_guid": "08f7feb8-05d3-44b5-8df9-f7eb5b0fe001"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "2f3994c0974c6624c9959cb824f95ad428a6d9fe", "_cell_guid": "d905416a-8368-43fe-aa1c-93e476147bc4"}, "outputs": [], "source": ["# get actual values from testing data\n", "actual <- testing$target"]}, {"cell_type": "markdown", "source": ["Now we take the ROC data frame and reshape it from 'wide' to 'long' format using the threshold values as the key. We do this so that we can use `dplyr`'s `group_by()` function and `summarize` function, passing in our `tpr()` and `fpr()` functions to get the true positive rate and the false positive rates for each threshold value. "], "metadata": {"_uuid": "cc89425bc71cd58a727f64d54963b07825d367a6", "_cell_guid": "cc7ca303-870b-4919-b7ea-f2238212e0d0"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "9679ac34a21f1db381d811c9ab4056515c486a17", "_cell_guid": "49ef40f7-67d5-4a57-be79-97d831a64fd3"}, "outputs": [], "source": ["# reshape to long format and get fpr and tpr for each threshold\n", "roc_data <- roc_data %>% \n", "    gather(key = 'threshold', value = 'pred') %>% \n", "    group_by(threshold) %>%\n", "    summarize(tpr = tpr(pred, actual = actual), \n", "              fpr = fpr(pred, actual = actual))"]}, {"cell_type": "markdown", "source": ["Now that the data are in the correct format, all we have to do is plot it. We plot a line with the false positive rates on the x-axis and the true positive rates on the y-axis. Then we add a 45 degree line and scale the x and y axes to insure that they go from 0 to 1 exactly. "], "metadata": {"_uuid": "544d465c8d9b6cc0a1145b43283175665c5d6304", "_cell_guid": "c730f36a-8297-49be-9607-22034cf289b9"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "5903d330c14253a912910c4bbafd6b7f8062f0e3", "_cell_guid": "0e963dc6-1eb0-4bb0-a861-f550987bdf8e"}, "outputs": [], "source": ["# set x and y tick marks\n", "breaks <-  c(0, 0.2, 0.4, 0.6, 0.8, 1)\n", "\n", "# get labels for plotting break points\n", "labels <- substr(roc_data$threshold, start = 2, stop = 5)\n", "\n", "# plot the ROC curve\n", "ggplot(data = roc_data, aes(x = fpr, y = tpr)) + \n", "    geom_line() + \n", "    geom_text(aes(label = labels), nudge_x = 0.05) + \n", "    geom_abline(intercept = 0, slope = 1, linetype = 'dashed') + \n", "    scale_x_continuous(limits = c(0, 1), breaks = breaks) + \n", "    scale_y_continuous(limits = c(0,1), breaks = breaks) + \n", "    labs(x = 'False Positive Rate', y = 'True Positive Rate', title = 'ROC Curve') + \n", "    theme_bw()\n", "\n"]}, {"cell_type": "markdown", "source": ["Finally we get to see the results of our classification model. The plot shows that our model has a ROC curve that has a higher AUC than the 45 degree line. That's great - we've created a model that does better than random guessing. \n", "\n", "That was an awful lot of work and code to make our ROC plot. I wanted to go through the exercise of doing it from scratch because I feel that doing so greatly improves our understanding of how things work. There are actually several R packages that have functions to plot ROC curves. One of those is the `verification` package, which has the function `roc.plot()`. We can call the function, passing in our actual values, predicted values, and a vector of thresholds to plot like so:"], "metadata": {"_uuid": "7072a7ba3f88d4009260aa1ea1fffbc7f504f6d6", "_cell_guid": "08ff9a35-7694-4d2e-be18-b5f3fbbd2cec"}}, {"cell_type": "code", "execution_count": null, "metadata": {"_uuid": "7a0e6861e28231313a0654dff21f4c80917c86c0", "_cell_guid": "44a63338-25ed-44df-bacf-036721334861"}, "outputs": [], "source": ["roc.plot(\n", "    testing$target, \n", "    preds, \n", "    threshold = seq(0, max(preds), 0.01), \n", "    plot.thres = c(0.03, 0.05, 0.1))"]}, {"cell_type": "markdown", "source": ["This generates a ROC curve nearly indentical to the one we created in `ggplot2`. \n", "\n", "# Conclusion\n", "\n", "That's it for this kernel. We've gone through the inner working of the logistic regression model and the ROC curve and as a result I hope that you have a better understanding of them. For the Porto competition, logistic regression will certainly not perform as well as other black box classifiers like xgboost and neural networks. However, unlike those types of models, logistic regression yields results that are easy to interpret and explain.\n", "\n", "The ROC curve is not only useful for logistic regression results. In fact we can use the ROC curve and the AUC to assess the performance of any _binary_ classifier. "], "metadata": {"_uuid": "18b486a3759d9053bc12efb62b4b99972fbd8f8f", "_cell_guid": "e81808b4-82f2-45b2-b476-6bb43d1c7b2c"}}, {"cell_type": "markdown", "source": ["### References\n", "\n", "James, G., Witten, D., Hastie, T., & Tibshiarani, R. An Introduction to Statistical Learning. New York, NY: Springer.\n", "\n", "Receiver Operating Characteristic. n.d. In _Wikipedia._ Retrieved October 2, 2017, from https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n", "\n", "Sigmoid Function. n.d. In _Wikipedia._ Retreived October 2, 2017, from https://en.wikipedia.org/wiki/Sigmoid_function\n", "\n", "Rosaen, K. (2016, May 15). The Sigmoid Function in Logistic Regression. [Blog post]. Retrieved from \n", "http://karlrosaen.com/ml/notebooks/logistic-regression-why-sigmoid/\n", "\n", "Zumel, A. (2011, September 14). The Simpler Derivation of Logistic Regression. [Blog post]. Retrieved from http://www.win-vector.com/blog/2011/09/the-simpler-derivation-of-logistic-regression/\n", "\n"], "metadata": {"_uuid": "972e71ed58de0e2938916773f2d0d86219025eb7", "_cell_guid": "f0f16e2d-f007-4402-b7c1-aa2d280b945c"}}], "metadata": {"kernelspec": {"display_name": "R", "name": "ir", "language": "R"}, "language_info": {"file_extension": ".r", "codemirror_mode": "r", "version": "3.4.2", "name": "R", "mimetype": "text/x-r-source", "pygments_lexer": "r"}}, "nbformat": 4}