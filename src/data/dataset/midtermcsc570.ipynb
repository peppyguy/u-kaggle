{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nnp.random.seed(42)\nimport tensorflow as tf\ntf.set_random_seed(42)\n\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.models import Model \nfrom keras.utils import to_categorical\nfrom keras.layers import Dense, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Input \nfrom keras.callbacks import TensorBoard, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report\nfrom keras.optimizers import SGD\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom keras.datasets import fashion_mnist\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb373d883fa3245b9995e1c4e7bb3011c20e137d"},"cell_type":"code","source":"def load_data(channels=0):\n    # The data, shuffled and split between train and test sets:\n    (train_X, train_y), (test_X, test_y) = fashion_mnist.load_data()\n    \n    train_X = train_X.astype('float32')\n    test_X = test_X.astype('float32')\n    train_X /= 255\n    test_X /= 255\n    \n    # # if using ImageDataGenerator a channel is required, default is last element\n    train_X = train_X.reshape(train_X.shape[0], 28,28,1)\n    test_X = test_X.reshape(test_X.shape[0], 28,28,1)\n\n    train_y = to_categorical(train_y)\n    test_y = to_categorical(test_y)\n\n    return {\"train_X\": train_X, \"train_y\": train_y,\n            \"val_X\": test_X[:5000, :], \"val_y\": test_y[:5000, :],\n            \"test_X\": test_X[5000:, :], \"test_y\": test_y[5000:, :]}\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def build_network(keep_prob=0.2, optimizer='adam'):\n    inputs = Input(shape=(28,28,1), name=\"input\")\n\n    # convolutional block 1\n    conv1 = Conv2D(64, kernel_size=(3,3), activation=\"relu\", name=\"conv_1\")(inputs)\n    batch1 = BatchNormalization(name=\"batch_norm_1\")(conv1)\n    pool1 = MaxPooling2D(pool_size=(2, 2), name=\"pool_1\")(batch1)\n\n    # convolutional block 2\n    conv2 = Conv2D(32, kernel_size=(3,3), activation=\"relu\", name=\"conv_2\")(pool1)\n    batch2 = BatchNormalization(name=\"batch_norm_2\")(conv2)\n    pool2 = MaxPooling2D(pool_size=(2, 2), name=\"pool_2\")(batch2)\n\n     # convolutional block 3\n    #conv3 = Conv2D(32, kernel_size=(3,3), activation=\"relu\", name=\"conv_3\")(pool2)\n    #batch3 = BatchNormalization(name=\"batch_norm_3\")(conv3)\n    #pool3 = MaxPooling2D(pool_size=(2, 2), name=\"pool_3\")(batch3)\n\n    # fully connected layers\n    flatten = Flatten()(pool2)\n    fc1 = Dense(512, activation=\"relu\", name=\"fc1\")(flatten)\n    d1 = Dropout(rate=keep_prob, name=\"dropout1\")(fc1)\n    fc2 = Dense(256, activation=\"relu\", name=\"fc2\")(fc1)\n    d2 = Dropout(rate=keep_prob, name=\"dropout2\")(fc2)\n\n    # output layer\n    output = Dense(10, activation=\"softmax\", name=\"softmax\")(fc2)\n\n    # finalize and compile\n    model = Model(inputs=inputs, outputs=output)    \n    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2d1f1bc002a7173b744e1837ed6e6db1caf3baac"},"cell_type":"code","source":"def create_callbacks(name):\n    tensorboard_callback = TensorBoard(log_dir= \"tensorboard_log\" + name, write_graph=True, write_grads=False)\n    checkpoint_callback = ModelCheckpoint(filepath=\"model-weights-\" + name + \".{epoch:02d}-{val_loss:.6f}.hdf5\", monitor='val_loss',\n                                          verbose=0, save_best_only=True)\n    return [tensorboard_callback]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b26781fafc9221e92ba6b306b9ebe6d5a162517"},"cell_type":"code","source":"def print_model_metrics(model, data):\n    loss, accuracy = model.evaluate(x=data[\"test_X\"], y=data[\"test_y\"])\n    print(\"\\n model test loss is \"+str(loss)+\" accuracy is \"+str(accuracy))\n\n    y_softmax = model.predict(data[\"test_X\"])  # this is an n x class matrix of probabilities\n    y_hat = y_softmax.argmax(axis=-1)  # this will be the class number.\n    test_y = data[\"test_y\"].argmax(axis=-1)  # our test data is also categorical\n    print(classification_report(test_y, y_hat))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1f09a6c4c49875e6fee4f78715ae9de1468bb239"},"cell_type":"code","source":"def create_datagen(train_X, val_X):\n    train_generator = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.02,\n        height_shift_range=0.02,\n        horizontal_flip=True)\n    train_generator.fit(train_X)\n    \n    val_generator = ImageDataGenerator(\n        rotation_range=20,\n        width_shift_range=0.02,\n        height_shift_range=0.02,\n        horizontal_flip=True)\n    val_generator.fit(val_X)\n    \n    return train_generator, val_generator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a01da9fc1619cbb441ab45a86bac2973d7a6f992"},"cell_type":"code","source":"def fit_model(model, train_generator, val_generator, batch_size, epochs, name):\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch=train_generator.n // batch_size,\n        epochs=epochs,\n        validation_data=val_generator,\n        validation_steps=val_generator.n // batch_size,\n        callbacks=create_callbacks(name=name),\n        verbose=1)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a05bacc1fa6f52c68da3b514c248d17d7d28e1e"},"cell_type":"code","source":"def eval_model(model, val_generator, batch_size):\n    scores = model.evaluate_generator(val_generator, steps=val_generator.n // batch_size)\n    print(\"Loss: \" + str(scores[0]) + \" Accuracy: \" + str(scores[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9314a2c3e83d7046ca97d0af3894e9522b74cac1"},"cell_type":"code","source":"IMG_HEIGHT = 28\nIMG_WIDTH = 28\nCHANNELS = 1  # RGB\ndata = load_data(CHANNELS)\ntrain_generator, val_generator = create_datagen(data[\"train_X\"], data[\"val_X\"])\ncallbacks = create_callbacks(name=\"midterm_run2\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cd6b91ca8c00ee2ffdd7283259e741ebd494bd97"},"cell_type":"code","source":"model = build_network()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d87180adaa090ec6f562b2d4293f8c660617bcd"},"cell_type":"code","source":"print(model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"551686dac155652dda695d265b1166d1495671ba"},"cell_type":"code","source":"model.fit_generator(train_generator.flow(data[\"train_X\"], data[\"train_y\"], batch_size=32),\n                        steps_per_epoch=len(data[\"train_X\"]) // 32,\n                        epochs=200,\n                        validation_data=(data[\"val_X\"], data[\"val_y\"]),\n                        verbose=1,\n                        #callbacks=callbacks\n                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"232cf6c5f6631491d1cf9bd2a6a4fd8f2bd6443f","_kg_hide-output":false},"cell_type":"code","source":"model.save(\"midterm_run2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa50a06a261462ded22cda7a3ef541fc9c579f7f"},"cell_type":"code","source":"eval_model(model, val_generator, 32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"296ab587487c9bd6d79337c178aaaf1695c6997d"},"cell_type":"code","source":"print_model_metrics(model, data)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}