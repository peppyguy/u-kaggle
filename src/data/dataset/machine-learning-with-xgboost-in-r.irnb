{"cells":[{"metadata":{"_cell_guid":"327e8b29-04c3-4282-8d74-a9c040a4a64c","_uuid":"e89b312e06e5a05bebcace9645e76056a14ffc99"},"cell_type":"markdown","source":"XGBoost (which stands for eXtreme Gradient Boosting) is an especialy efficent implimentation of gradient boosting. In practice, XGBoost is a very powerful tool for classification and regression. In particular, it has proven to be very powerful in Kaggle competitions, and winning submissions will often incorporate it. In this tutorial, you'll learn how to take a new dataset and use XGBoost to make predictions. \n\n____\n\n### What will I learn?\n\nBy the time you finish this tutorial, you will learn:\n\n* What XGBoost is\n* How to prepare your data\n* How to train and tune a model using XGBoost\n* How to visualize & explore your model\n    \n### What do I need to know before I get started?\n\nYou may find some of the discussion here hard to understand if you don't have a basic familiaritywith the R language before you begin. I would recommend [this series of lessons](https://www.kaggle.com/rtatman/getting-started-in-r-first-steps/) if you've never used R or never programmed before.\n\n### What will I need to do?\n\nAs you work through this tutorial, you'll have a number of exercises to complete. You are of course free to fork this notebook and do them here, but the easiest option is to fork a version of [this workbook for this lesson](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r-workbook/).\n\n____\n\n## Table of Contents\n\n* [What is XGBoost?](#What-is-XGBoost?)\n* [Setting up our environment](#Setting-up-our-environement)\n* [Preparing our data & selecting features](#Preparing-our-data-&-selecting-features)\n* [Training our model](#Training-our-model)\n* [Tuning our model](#Tuning-our-model)\n* [Examining our model](#Examining-our-model)\n_____"},{"metadata":{"_cell_guid":"5ad34d24-185d-42a3-ac82-6d1a273337b8","_uuid":"63f44af55abc83e1cfcaf9e97c9bdef1b3f0b25e"},"cell_type":"markdown","source":"# What is XGBoost?\n____\n\nXGBoost is an implementation of the **Gradient Boosted Decision Trees** algorithm.  What is **Gradient Boosted Decision Trees**?  We'll walk through a diagram.\n\n![xgboost image](https://i.imgur.com/e7MIgXk.png)\n\nWe go through cycles that repeatedly builds new models and combines them into an **ensemble** model.  We start the cycle by taking an existing model and calculating the errors for each observation in the dataset.  We then build a new model to predict these errors.  We add predictions from this error-predicting model to the \"ensemble of models.\"  \n\nTo make a prediction, we add the predictions from all previous models.  We can use these predictions to calculate new errors, build the next model, and add it to the ensemble.\n\nThere's one piece outside that cycle.  We need some base prediction to start the cycle. In practice, the initial predictions can be pretty naive. Even if it's predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.\n\nThis process may sound complicated, but the code to use it is straightforward. We'll fill in some additional explanatory details in the **model tuning** section below.\n"},{"metadata":{"_cell_guid":"2d90bbd8-4c3f-45d4-9750-2a7e0068f36a","_uuid":"f0c1148ba3009ec0bce51f7df9f92490baf63f0a"},"cell_type":"markdown","source":"# Setting up our environment\n____\n\nBefore we get going, we're going to need to get our environment set up. First, let's read in the libraries we're going to use."},{"metadata":{"_cell_guid":"2922ef79-3375-463a-87f3-a25f3a837205","_uuid":"bfc6336dd056b6c8a9bbd0f0d176964d336177fe","trusted":false},"cell_type":"code","source":"# libraries we're going to use\nlibrary(xgboost) # for xgboost\nlibrary(tidyverse) # general utility functions","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e5ec47f1-aa5d-4635-923e-38888f822ee4","_uuid":"f1071f1ea6377fd97c8dd1657b434c9b7c81d3ff"},"cell_type":"markdown","source":"Now, let's read in our data. For this tutorial, we're going to be using a dataset from the Food and Agriculture Organization of the United Nations that contains information on various outbreaks of animal diseases. We're going to try to predict which outbreaks of animal diseases will lead to humans getting sick. "},{"metadata":{"_cell_guid":"95527d9f-e424-4942-b1d2-985a3ad94af9","_uuid":"85dc1543e960620c036616c1179a85890bd58e9f","trusted":false},"cell_type":"code","source":"# read in our data & put it in a data frame\ndiseaseInfo <- read_csv(\"../input/Outbreak_240817.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"23dfd7dc-ec31-41c1-9b1e-ff9a77a118bd","_uuid":"a4f0679e0af9867e1a551764e9b30bd84816fbd6"},"cell_type":"markdown","source":"Before we get down to business, I'm going to shuffle our dataset. I'm doing this so that when I split our data into a testing set and training set using the row numbers, I know that I'll get a random sample of data in both the testing and training set."},{"metadata":{"_cell_guid":"12ee715e-f306-4aa9-9690-1424f58c4e95","_uuid":"66d85ab6ef2dddbd1787e097260f2f9b9db26e52","trusted":false},"cell_type":"code","source":"# set a random seed & shuffle data frame\nset.seed(1234)\ndiseaseInfo <- diseaseInfo[sample(1:nrow(diseaseInfo)), ]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e7fbf09a-ea10-4828-bb01-7b6eb2670add","_uuid":"94c4b19758b80d1ae8741be5082542eb2f33d071"},"cell_type":"markdown","source":"# Preparing our data & selecting features\n\n____\n\n<center>\n**If you're not interested in the data cleaning steps, you can [jump right to using XGBoost](#Training-our-model).**\n"},{"metadata":{"_cell_guid":"7f61cd78-486e-4e92-a34d-bdee93f854ee","_uuid":"8895a5813779fce365183218b3b6d5784b1c35bb"},"cell_type":"markdown","source":"___\n\nOne stumbling block when getting started with the xgboost package in R is that you can't just pass it a dataframe. The core xgboost function requires data to be a matrix.\n\n> A **matrix** is like a dataframe that only has numbers in it. A **sparse matrix** is a matrix that has a lot zeros in it. XGBoost has a built-in datatype, DMatrix, that is particularly good at storing and accessing sparse matrices efficiently.\n\nHowever, our data isn't currently in a matrix. In fact, many of our features aren't numeric at all! Let's check out the first few rows our dataframe and see what it looks like."},{"metadata":{"_cell_guid":"fc75a628-725c-4171-8a9c-72d5428b4876","_uuid":"e403fcfdb33f41738378fef52f58384ba170e854","trusted":false},"cell_type":"code","source":"# print the first few rows of our dataframe\nhead(diseaseInfo)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f19fc99b-442e-4a13-ab6b-0d8aafc56d5b","_uuid":"0de432c30bf585ece90266e3db396b9f3b2c1e6b"},"cell_type":"markdown","source":"As you can see, our data will need some cleaning before it's ready to be put in a matrix. To prepare our data, we have a number of steps we need to complete:\n\n* Remove information about the target variable from the training data\n* Reduce the amount of redundant information\n* Convert categorical information (like country) to a numeric format\n* Split dataset into testing and training subsets\n* Convert the cleaned dataframe to a Dmatrix\n\n### Remove information about the target variable from the training data\n\nFirst, let's remove the columns that have information on our target variable. Knowing what the target label is supposed to be will certainly help us make accurate predictions, but a model that relies on the correct labels for classification won't be very helpful or interesting. (Accidentally including the target labels in your training dataset is one example of [leakage](https://www.kaggle.com/wiki/Leakage).)\n\nIn this dataset, the information on human sickness is in four columns called \"humansGenderDesc\", \"humansAge\", \"humansAffected\" and \"humansDeaths\". We can get rid of all of these at once by dropping columns that have names starting with \"human\"."},{"metadata":{"_cell_guid":"cd20bd63-b54e-499b-a62e-c4c6252f299c","_uuid":"d2c06908b0b4478df68f975d4fd6900283f33a4d","trusted":false},"cell_type":"code","source":"# get the subset of the dataframe that doesn't have labels about \n# humans affected by the disease\ndiseaseInfo_humansRemoved <- diseaseInfo %>%\n    select(-starts_with(\"human\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f756d00-5079-449f-9fda-51664a88025b","_uuid":"e537fb1a91584ccafc280d8a25468c21259293b5"},"cell_type":"markdown","source":"Now we're gotten rid of the columns with information on our target variable. But we still do need to know the labels for training and evaluating our model. \n\nLet's create a new vector with the labels. To do this, I'm looking in the column \"humansAffected\" and, for each row, seeing if that row is NA. (If no humans were affected, that column has \"NA\" in it). This gets me a boolean vector. Finally, I reverse the booleans, so that TRUE switches to FALSE, and FALSE switches to TRUE. (Since is.na() gave us true when there *weren't* any humans affected, and I want to know if there were any.)\n\nIf you have a column with the labels in it, you can just go ahead and use that."},{"metadata":{"_cell_guid":"1bb78a68-a660-42c9-8c5f-d1fba6b39dd0","_uuid":"a0de2bb024714c680939b2501f4cac6d4f4a49d4","trusted":false},"cell_type":"code","source":"# get a boolean vector of training labels\ndiseaseLabels <- diseaseInfo %>%\n    select(humansAffected) %>% # get the column with the # of humans affected\n    is.na() %>% # is it NA?\n    magrittr::not() # switch TRUE and FALSE (using function from the magrittr package)\n\n# check out the first few lines\nhead(diseaseLabels) # of our target variable\nhead(diseaseInfo$humansAffected) # of the original column","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f9543a8d-dc68-46c7-b475-cb3b6963ae0a","_uuid":"c560cf3a20e978400035b0fc13b4f29b004e3b7b"},"cell_type":"markdown","source":"### Reduce the amount of redundant information\n\nWe also want to make sure we remove columns that have redundant information in them or that we don't want to use to make predictions. So, for example, I don't want to include latitude and longitude in our training data because I'm also planning on including what country each observation is from and \"latitude\" and \"longitude\" and \"country\" all encode the same information: geographic location. \n\nI also want to remove variables that could be very informative due to chance. So, for example, each observation in this dataset has a numeric ID associated with it. It could be that ID's that end with 8 are more likely to be associated with diseases that spread to humans due to pure chance. We wouldn't want to predict that giving a new disease that is given an ID ending with 8 means its more likely to spread to humans, though!\n\nFinally, I want to remove all the non-numeric variables, since a matrix can only hold numeric variables. (If you try to create a matrix from a dataframe with non-numeric variables in it, it will convert them all to “NA” and give you some warning messages.)\n\n> **What counts a numeric variable?** A variable is numeric if it only contains numbers. This includes booleans (TRUE or FALSE), since TRUE is equal to 1, and FALSE is equal to 0. You can check if the columns of a dataframe are numeric by checking out the structure using the str() function and then making sure that each variable has \"num\", for numeric, next to it."},{"metadata":{"_cell_guid":"61655103-88aa-4e14-b3eb-f39342327322","scrolled":true,"_uuid":"c4850687d7420be040c60dc28adcbb0cc9d65e55","trusted":false},"cell_type":"code","source":"# select just the numeric columns\ndiseaseInfo_numeric <- diseaseInfo_humansRemoved %>%\n    select(-Id) %>% # the case id shouldn't contain useful information\n    select(-c(longitude, latitude)) %>% # location data is also in country data\n    select_if(is.numeric) # select remaining numeric columns\n\n# make sure that our dataframe is all numeric\nstr(diseaseInfo_numeric)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"bc537ef3-e36d-4224-a8d4-272e0220423c","_uuid":"c59e5902abf955e0f838c12d4597cd8f3fd87286"},"cell_type":"markdown","source":"### Convert categorical information (like country) to a numeric format\n\nAlright, so now we've got all the numeric values we need. But what about non-numeric variables? For example, we have a column \"country\" that tells us which country an observation is from."},{"metadata":{"_cell_guid":"7cbb2ee7-d63f-4b43-a15a-30d266c97bbf","_uuid":"2c0258f313e4fb48b45fa0db40eab8fe54381d2a","trusted":false},"cell_type":"code","source":"# check out the first few rows of the country column\nhead(diseaseInfo$country)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"52272a4d-54ba-42f1-8ba7-7353d5b65301","_uuid":"1fd0f3e80c620a594a8adf60c6a9515453def64f"},"cell_type":"markdown","source":"How can we convert these categories to a matrix? One way to do this is using one-hot encoding. One-hot encoding takes each category and makes it its own column. Then, for each observation, it puts a \"0\" in that column if that observation doesn't belong to that column and \"1\" if it does. In R, we can convert a column with a categorical variable in it to a one-hot matrix like so: "},{"metadata":{"_cell_guid":"8ba3a3de-12dc-4ccd-8445-ca9e0df3ef59","_uuid":"e72f02deb0bb26b32cc1230325e6b89c28603eca","trusted":false},"cell_type":"code","source":"# one-hot matrix for just the first few rows of the \"country\" column\nmodel.matrix(~country-1,head(diseaseInfo))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"96c1720f-d95e-40eb-9675-220de687a24f","_uuid":"73ce9e6e99b9a51d92dbd91fd7e158fccdff44b8"},"cell_type":"markdown","source":"You may notice that this new matrix has a lot of zeros in it. This is a good example of the \"sparse matrix\" we talked about in the beginning of this section.\n\nNow let's convert the entire \"country\" column to a big one-hot matrix and save it as a matrix that we can add to our training data later."},{"metadata":{"_cell_guid":"285b5d9e-79b0-465d-afc9-c8c80688eb1d","_uuid":"225dea79db753be10a8918149c113bbf20d70665","trusted":false},"cell_type":"code","source":"# convert categorical factor into one-hot encoding\nregion <- model.matrix(~country-1,diseaseInfo)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6ca46929-edf7-4953-b21f-3f066f2605fa","_uuid":"3bb1c69136bf1230e20cb3275b398b6b90d50901"},"cell_type":"markdown","source":"Sometimes you may also need to do a little bit of text processing to get from a categorical variable to the point where we can turn it into a matrix. For example, we have a column, speciesDescription, that has information on what specific species of animal is sick AND whether it's domestic or not:"},{"metadata":{"_cell_guid":"28d61798-49cd-44c5-b888-b642feb30e68","_uuid":"82f44284698b7e81703380eb30bb02ad4f25c252","trusted":false},"cell_type":"code","source":"# some of the species\nhead(diseaseInfo$speciesDescription)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b4614cde-fae8-4afa-885c-367089fa6654","_uuid":"fd2ab53d90e2c1d1b85a34ec7b94f02c6fec909c"},"cell_type":"markdown","source":"We might think that, for example, domestic animals are more likely than wild animals to get people sick. We can include \"domestic\" as a variable by adding a column that is TRUE if the \"speciesDescription\" column has the word \"domestic\" in it in that row. "},{"metadata":{"_cell_guid":"8256787a-f9fd-44bd-b45a-03eb9c94c107","_uuid":"092ac3e888825971df1858679b1af325a0b8da93","trusted":false},"cell_type":"code","source":"# add a boolean column to our numeric dataframe indicating whether a species is domestic\ndiseaseInfo_numeric$is_domestic <- str_detect(diseaseInfo$speciesDescription, \"domestic\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9f3b83b7-9070-4573-bb16-686bbd3b042a","_uuid":"b4a45396b067416aa514926e2878fa61e1b2da2e"},"cell_type":"markdown","source":"We might also think that there may be a difference between how likely various species of animals are to get a person sick. For example, maybe ducks (wild or domestic) are particulary likely to get human sick becuase they swim in ponds that provide drinking water. \n\nSince the species is always the last word in the \"speciesDescription\", we can just grab the last word of each row and use that to create a one-hot matrix of different species."},{"metadata":{"_cell_guid":"002ba6c0-a7ea-45cb-9e39-48f3a4e334ab","_uuid":"adfc9afc774f7c59c7b8a420011d71797241123c","trusted":false},"cell_type":"code","source":"# get a list of all the species by getting the last\nspeciesList <- diseaseInfo$speciesDescription %>%\n    str_replace(\"[[:punct:]]\", \"\") %>% # remove punctuation (some rows have parentheses)\n    str_extract(\"[a-z]*$\") # extract the least word in each row\n\n# convert our list into a dataframe...\nspeciesList <- tibble(species = speciesList)\n\n# and convert to a matrix using 1 hot encoding\noptions(na.action='na.pass') # don't drop NA values!\nspecies <- model.matrix(~species-1,speciesList)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3573dd12-b5c0-4bd6-a730-244f272f061c","collapsed":true,"_uuid":"5344ca28a7c78f7b6a975f3d0d3788a9248ae2af"},"cell_type":"markdown","source":"So now we have three seperate data frames (diseaseInfo_numeric, region and species) all with numeric information in them. We can bundle all these columns together and then should be able to convert them to a matrix without a problem."},{"metadata":{"_cell_guid":"bdf9bd68-86e2-4abe-9d07-0fed63a0c356","_uuid":"d6e654744dafbb70f6d609ad2484b36245cb8345","trusted":false},"cell_type":"code","source":"# add our one-hot encoded variable and convert the dataframe into a matrix\ndiseaseInfo_numeric <- cbind(diseaseInfo_numeric, region, species)\ndiseaseInfo_matrix <- data.matrix(diseaseInfo_numeric)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2e15308-ca6c-4661-9582-8e9f8215e5b6","_uuid":"8c370188e425396133f32ff469eda8ade3566c74"},"cell_type":"markdown","source":"### Split dataset into testing and training subsets\n\nNow comes an important step: we need to split our data into testing and training data. This is so that we can check that our model is actually robust enough to extend to observations we haven't seen yet. (If it can't, it's probably not a very useful model!)\n\nFor this project, I'm going to use 70% of our data for training and the other 30% for testing."},{"metadata":{"_cell_guid":"19e169b2-c433-4616-80a3-ba916b48574f","_uuid":"92eb0864d685c6458c48980fadbe42c608ec6b15","trusted":false},"cell_type":"code","source":"# get the numb 70/30 training test split\nnumberOfTrainingSamples <- round(length(diseaseLabels) * .7)\n\n# training data\ntrain_data <- diseaseInfo_matrix[1:numberOfTrainingSamples,]\ntrain_labels <- diseaseLabels[1:numberOfTrainingSamples]\n\n# testing data\ntest_data <- diseaseInfo_matrix[-(1:numberOfTrainingSamples),]\ntest_labels <- diseaseLabels[-(1:numberOfTrainingSamples)]","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ceb19839-1708-4e22-accf-a8a1137388e4","_uuid":"65d20af7db306d09bc8dea98bf439431252a5004"},"cell_type":"markdown","source":"### Convert the cleaned dataframe to a dmatrix\n\nThe very final step is to convert our matrixes into dmatrix objects. This step isn't absolutely necessary, but it will help our model train move more quickly, and you'll need to to this if you ever want to train a model on multiple cores."},{"metadata":{"_cell_guid":"78d32857-5f94-432f-9e89-8e3fa63f74bb","_uuid":"ac0ce30ebb757c2428dee38d36378704d18ab1c5","trusted":false},"cell_type":"code","source":"# put our testing & training data into two seperates Dmatrixs objects\ndtrain <- xgb.DMatrix(data = train_data, label= train_labels)\ndtest <- xgb.DMatrix(data = test_data, label= test_labels)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e36d3286-71dc-415e-bac0-088f9a5325d7","_uuid":"94e2b10c544e4e202a161416facd64af235dc77e"},"cell_type":"markdown","source":"Whew! That was a quite a bit of data cleaning. To get our dataframe ready to be fed into the xgboost function, we needed to:\n\n* Remove information about the target variable from the training data\n* Reduce the amount of redundant information\n* Convert categorical information (like country) to a numeric format\n* Split dataset into testing and training subsets\n* Convert the cleaned dataframe to a Dmatrix\n\nBut now we're finally ready to train our model!\n___\n\n### Your turn!\n\nNow that you've seen how data cleaning works, why don't you [head over to the workbook for this section](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r-workbook/) and try cleaning a new dataset?"},{"metadata":{"_cell_guid":"cb902356-02c2-4ab2-a206-c67dd3d84bfb","_uuid":"2dca42eb3a9c7abf56e339bedf9e5bc6de039554"},"cell_type":"markdown","source":"\n# Training our model\n____\n\nNow that we have our testing & training set cleaned and ready to go, it's time to start training our model. Let's start by training one model and then work on tweaking parameters. (You can find full documentation on all the parameters and what they do [here](https://xgboost.readthedocs.io/en/latest/parameter.html).)\n\nIn order to train our model, we need to give it some information to start with. It needs to know:\n\n1. *What training data to use*. In this case, we've already put our data in a dmatrix and can just pass it that.\n2. *The number of training rounds.* This just means the number of times we're going to improve our naive model by adding\nadditional models. [In the figure above](#What-is-XGBoost?) going around the circle once = one boosting round.\n3. *What the objective function is.* The objective function you pick will depend on the task you have. Because we're going to try and predict something that's binary (either humans get sick or they don't), we're going to use “binary:logistic”, which is logistic regression for binary (two-class) classification. By default, xgboost will do linear regression."},{"metadata":{"_cell_guid":"21e7667f-803f-42f2-bd5c-28289cd3b3bf","_uuid":"ed77035a0181c7beb2b6aed5dc885dc1be07dfa4","trusted":false},"cell_type":"code","source":"# train a model using our training data\nmodel <- xgboost(data = dtrain, # the data   \n                 nround = 2, # max number of boosting iterations\n                 objective = \"binary:logistic\")  # the objective function","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d9eaf415-a2f4-42ed-90f2-a74b226aa62c","_uuid":"4f64092a80290e2bfbfd4e48a5de305b98309c0c"},"cell_type":"markdown","source":"We can see looking out the output of our model that for both the first and second rounds, we had the same error on the training data. This means that we didn't see an improvement in the second round of training. \n\nThat said, we're not really interested in how accurate we are on the training data. We're more interested in how accurate we are on the testing data, which our model hasn't seen before."},{"metadata":{"_cell_guid":"074c4371-d64e-49bc-9bce-35a5a4351c31","_uuid":"d16c94feb6595156dfaf56ab986f58c1867d45f4","trusted":false},"cell_type":"code","source":"# generate predictions for our held-out testing data\npred <- predict(model, dtest)\n\n# get & print the classification error\nerr <- mean(as.numeric(pred > 0.5) != test_labels)\nprint(paste(\"test-error=\", err))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ad342916-b919-47ef-b000-cd38cdfe1235","_uuid":"c64ea8f2f153ad9d628ccf301ddf91efc189c212"},"cell_type":"markdown","source":"Now that we've got a basic model, we can try our hand at parameter tuning. \n\n___\n## Your turn!\n\n[Head over to your workbook](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r-workbook/) and try your hand at predicting whether or not a sick horse will pull through (or whether a zoo animal is a mammal)."},{"metadata":{"_cell_guid":"c8c46baf-fd43-4e6e-a169-971cd919a408","_uuid":"84491d4f484fe5b290829a6688f98293d7992f48"},"cell_type":"markdown","source":"# Tuning our model\n_____\n\nGood news! Our initial model had a slightly lower error on our testing data than our training data. (That's great, it means we didn't over-fit!)\n\nLet's imagine, however, that we *didn't* see a lower error for our training data and we were worried that we might be over-fitting.\n\n> **Over-fitting**: when your model relies too much on randomness/noise in your training set to make its classifications. As a result, it will probably not extend well to a new dataset.\n\nOne way to avoid over-fitting is to make your model less complex. You can do this in xgboost by specifying that you want your decision trees to have fewer layers rather than more layers. Each layer splits the remaining data into smaller and smaller pieces and therefore makes it more likely that you're capturing randomness and not the important variation.\n\nBy default, the max.depth of trees in xgboost is 6. Let's set it to 3 instead."},{"metadata":{"_cell_guid":"7acacbda-ee66-43e4-86c8-d0b611442490","_uuid":"6689e82852f6647c8ef6ac7dde7d91bded52a174","trusted":false},"cell_type":"code","source":"# train an xgboost model\nmodel_tuned <- xgboost(data = dtrain, # the data           \n                 max.depth = 3, # the maximum depth of each decision tree\n                 nround = 2, # max number of boosting iterations\n                 objective = \"binary:logistic\") # the objective function \n\n# generate predictions for our held-out testing data\npred <- predict(model_tuned, dtest)\n\n# get & print the classification error\nerr <- mean(as.numeric(pred > 0.5) != test_labels)\nprint(paste(\"test-error=\", err))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d31d81e4-4140-4d87-bf6f-e4ca62eb9a0a","_uuid":"ee55aad6e30b41e622bef5113733ae96d7b1bd14"},"cell_type":"markdown","source":"In this case--because we weren't over-fitting to begin with--we don't really see a big change.\n\nWhat about the opposite problem, under-fitting? Is our model not making use of meaningful information in our dataset? (It seems fairly unlikely, since this is a pretty small dataset and xgboost has reasonable model defaults. But, for the purposes of demonstration, let's pretend.)\n\nThere are two things we can try to see if we improve our model performance. \n\n1. *Account for the fact that we have imbalanced classes*. \"Imbalanced classes\" just means that we have more examples from one category than the other. In this case, humans don't usually get sick when animals do, but sometimes they do. We can help make sure that we're making sure to predict rare events by scaling the weight we give to positive cases. \n2. *Train for more rounds*. If we stop training early, it's possible that our error rate is higher than it could be if we just kept at it for a little longer. It's also possible that training longer will result in a more complex model than we need and will cause us to over-fit. We can help guard against this by setting a second parameter, early_stopping_rounds, that will stop training if we have no improvement in a certain number of training rounds.\n\nLet's try re-training our model with these tweaks."},{"metadata":{"_cell_guid":"681e4b82-26ec-4710-8e2f-e36198c3b215","scrolled":true,"_uuid":"ec8887c6a96535bed33465263d591573f40cf8b7","trusted":false},"cell_type":"code","source":"# get the number of negative & positive cases in our data\nnegative_cases <- sum(train_labels == FALSE)\npostive_cases <- sum(train_labels == TRUE)\n\n# train a model using our training data\nmodel_tuned <- xgboost(data = dtrain, # the data           \n                 max.depth = 3, # the maximum depth of each decision tree\n                 nround = 10, # number of boosting rounds\n                 early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop\n                 objective = \"binary:logistic\", # the objective function\n                 scale_pos_weight = negative_cases/postive_cases) # control for imbalanced classes\n\n# generate predictions for our held-out testing data\npred <- predict(model_tuned, dtest)\n\n# get & print the classification error\nerr <- mean(as.numeric(pred > 0.5) != test_labels)\nprint(paste(\"test-error=\", err))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c2f35cd9-62a5-437f-85c3-cf11adc37d18","_uuid":"6285da7d613357bd1a3a2de725597a03ee57ae82"},"cell_type":"markdown","source":"There are a couple things to notice here. \n\nFirst, our error in the first round was actually higher than it was for earlier models (0.016... vs 0.014...). This is because we've penalized failing to capture very rare events. \n\nThen, as we add more training rounds, our error drops a little bit and actually ends up lower than it was with our earlier model. This is because adding additional training rounds adds additional complexity to our model that better allows it to capture the variation in our training data.\n\nAfter a while, though, our error starts to actually go up. This is probably due to over-fitting: we end up at the point where adding more complexity to the model is actually hurting it. We've talked about avoiding over-fitting above, but another technique that can help avoid over-fitting is adding a regularization term, gamma. Gamma is a measure of how much an additional split will need to reduce loss in order to be added to the ensemble. If a proposed model does not reduce loss by at least whatever-you-set-gamma-to, it won't be included. Here, I'll set it to one, which is fairly high. (By default gamma is zero.)"},{"metadata":{"_cell_guid":"9a100c3b-92fa-4605-aa1b-175d96af3a71","_uuid":"f79aaebed9b8f2c4ef09870d7fea138397d264fe","trusted":false},"cell_type":"code","source":"# train a model using our training data\nmodel_tuned <- xgboost(data = dtrain, # the data           \n                 max.depth = 3, # the maximum depth of each decision tree\n                 nround = 10, # number of boosting rounds\n                 early_stopping_rounds = 3, # if we dont see an improvement in this many rounds, stop\n                 objective = \"binary:logistic\", # the objective function\n                 scale_pos_weight = negative_cases/postive_cases, # control for imbalanced classes\n                 gamma = 1) # add a regularization term\n\n# generate predictions for our held-out testing data\npred <- predict(model_tuned, dtest)\n\n# get & print the classification error\nerr <- mean(as.numeric(pred > 0.5) != test_labels)\nprint(paste(\"test-error=\", err))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14e04d46-c232-4652-827a-8757893082e1","_uuid":"d629550d2e100cefe02da805bd0a9fc15c35e62a"},"cell_type":"markdown","source":"Adding a regularization terms makes our model more conservative, so it doesn't end up adding the models which were reducing our accuracy.\n\nWe've done quite a bit of parameter turning at this point, but you may have noticed that it didn't actually help our accuracy on the test set! The sensible defaults for xgboost are doing a pretty good job on their own. If you have a larger and more complex dataset you'll probably get more utility out of parameter tuning, but for this problem it looks like the simple model is actually just as useful as the more complex one.\n\n___\n## Your turn!\n\nParameter tuning may help you make more accurate predictions for which sick horses will get better. Why don't you [head over to your workbook and find out](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r-workbook/)?"},{"metadata":{"_cell_guid":"50247be6-8d12-472d-8afd-c55d7fd942dd","_uuid":"dce2c7b92b7659118888cdf72f5c52cdcfec66bc"},"cell_type":"markdown","source":"# Examining our model\n___\n\nSo far, we've:\n\n* cleaned & prepared our data\n* trained our model\n* tuned our model (not strictly necessary in this case, but generally it will help!)\n\nNow we can spend some time examing and interpreting our model. One of the really nice things about xgboost is that is has a lot of built-in functions to help us figure out why our model is making the distictions it's making.\n\nOne way that we can examine our model is by looking at a representation of the combination of all the decision trees in our model. Since all the trees have the same depth (remember that we set that with a parameter!) we can stack them all on top of one another and pick the things that show up most often in each node."},{"metadata":{"_cell_guid":"b03eed91-4e7c-4ec1-bc08-7bd6262a6d27","_uuid":"86084c4d030b9069b2f88187a1029102b77af9df","trusted":false},"cell_type":"code","source":"# plot them features! what's contributing most to our model?\nxgb.plot.multi.trees(feature_names = names(diseaseInfo_matrix), \n                     model = model)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f83ae82c-950b-493c-ac54-0e25bbf7253d","_uuid":"5f0a549916c672f8a22355abad2fa4e8d6706736"},"cell_type":"markdown","source":"The top of the tree is on the left and the bottom of the tree is on the right. For features, the number next to it is \"quality\", which helps indicate how important this feature was across all the trees. Higher quality means a feature was more important.  So we can tell that is_domestic was by far the most important feature across all of our trees, both because it's higher in the tree and also because it's quality score is very high.\n\nFor the nodes with \"Leaf\", the number next to the \"Leaf\" is the average value the model returned across all trees if a a certain observation ended up in that leaf. Because we're using a logistic model here, it's telling us the log-odds rather than the probability. We can pretty easily convert the log odds to probability, though. "},{"metadata":{"_cell_guid":"4600c8aa-e7af-48e3-bb93-a5ac2a89f516","_uuid":"8a2672d9044c31185c2dd7405e233e9b4ac6d4d8","trusted":false},"cell_type":"code","source":"# convert log odds to probability\nodds_to_probs <- function(odds){\n    return(exp(odds)/ (1 + exp(odds)))\n}\n\n\n# probability of leaf above countryPortugul\nodds_to_probs(-0.599)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9a0d48d8-64f6-4e9e-a9d1-62d5f055d4bc","_uuid":"a3dc63a06755c465d4089d1d994adbd0c1b51808"},"cell_type":"markdown","source":"So, in the trees where an observation ended up in that leaf, on average the probability that a human would be sick in that instance was 35%. Since that was below the threshold of 50% we used for our decision rule, we'd say that these instance usually wouldn't result in a human getting sick.\n\nWhat if we want a quick way to see which features are most important? We can do that using by creating and then plotting the importance matrix, like so:"},{"metadata":{"_cell_guid":"8ad5a34a-e745-4f1e-82cc-43a047b7b7c0","scrolled":true,"_uuid":"a35e66a483ce625fc04931a0cf52d3c1701609fd","trusted":false},"cell_type":"code","source":"# get information on how important each feature is\nimportance_matrix <- xgb.importance(names(diseaseInfo_matrix), model = model)\n\n# and plot it!\nxgb.plot.importance(importance_matrix)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a88afcc4-0111-4a06-8346-d016fabf5d93","_uuid":"ea945c7c8d9ee4617222f26b285baecae592f279"},"cell_type":"markdown","source":"Here, each bar is a different feature, and the x-axis is plotting the weighted gain. (\"Weighted\" just means that if you add together the gain for every feature, you'll get 1.) Basically this plot tells us how informative each feature was when we look at every tree in our ensemble. So features with a lot of gain were very important to our model while features with less gain were less helpful.\n\nHere, we can see that whether or not an animal that got sick was domestic was far and away the most important feature for figuring out if humans would get sick! This makes sense, since a person is more likely to come in contact with a domestic animal than a wild one.\n___\n## Your turn\n\nNow that you know how to examine a model, why don't you [head over to your workbook](https://www.kaggle.com/rtatman/machine-learning-with-xgboost-in-r-workbook/) and take a shot at examining the model you just trained?\n"},{"metadata":{"_cell_guid":"3bdd40bd-17c5-4314-b18e-08555209aa36","_uuid":"1c794139b63a964e85cb0134231c4c0e10d303de"},"cell_type":"markdown","source":"# Conclusion\n___\n\nAnd that's all there is to it! In this tutorial you learned:\n\n* What XGBoost is\n* How to prepare your data\n* How to train and tune a model using XGBoost\n* How to visualize & explore your model\n\nNow you're ready to test you skills on new datasets! Why not try some of [these ML friendly datasets](https://www.kaggle.com/annavictoria/ml-friendly-public-datasets) or [a Getting Started competition](https://www.kaggle.com/competitions?sortBy=grouped&group=general&page=1&pageSize=20&category=gettingStarted)?\n\nGood luck and happy analyzing!\n"}],"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"codemirror_mode":"r","mimetype":"text/x-r-source","version":"3.4.2","file_extension":".r","pygments_lexer":"r","name":"R"}},"nbformat":4,"nbformat_minor":1}