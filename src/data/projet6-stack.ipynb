{"cells":[{"metadata":{"_uuid":"3b3cf620c0ca7c297d1cb454857c8536459bdcb2"},"cell_type":"markdown","source":"# Projet 6: Catégoriser automatiquement des questions sur Stack Overflow"},{"metadata":{"_uuid":"c5c9b342e48b1c011fa17c21e4597d858e9835a3"},"cell_type":"markdown","source":"\n\n## Introduction:\n\nL'objectif de ce Notebook est d'utiliser un échantillo de données récupérées sur la base de données de questions du site StackOverflow afin d'implémenter un modèle permettant la suggestion automatique de tags aux utilisateurs une fois qu'ils ont rédigé leur question. Ce notebook contiendra une partie de prétraitement des données, puis de classification des questions en utilisant des méthodes supervisées et non supervisées.\n\n**1. Nettoyage et préparation des données**\n\n**2. Application d'une méthode non supervisée de modélisation des topics et tags**\n\n   - 2.1 Implémentation d'une LDA\n   - 2.2 Extraction des tags \n\n**3. Application d'une méthode supervisée de classification multi-label des tags**\n\n**4. Evaluation des performances et choix du modèle final**\n\n\n"},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"20adeafda5f276d35ac0b67dba96cab1888a448e","scrolled":true},"cell_type":"code","source":"!pip install --upgrade pip\n!pip install wordcloud\n!pip install --upgrade scikit-learn\n!pip install --upgrade pandas\n!pip install --upgrade scikit-learn","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"_uuid":"ccbbea7279afae31786297b6af9cc59642f126b7"},"cell_type":"code","source":"#Make all the necessary imports for modules used in the notebook\n# coding: utf-8\nimport re\nimport time\nimport pickle\nimport nltk, warnings\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk.tag.perceptron import PerceptronTagger\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\nfrom sklearn.multioutput import ClassifierChain\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, jaccard_similarity_score, hamming_loss, make_scorer\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport itertools\nimport os\nimport numpy as np\nimport calendar\nimport math\nimport matplotlib as mpl\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport plotly.graph_objs as go\nimport matplotlib.cm as cm\nfrom io import BytesIO","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1754cbaf19cd29e7966832e5ba3813babea078e3"},"cell_type":"markdown","source":"## 1. Nettoyage et préparation des données\n#### Chargement du Data Set et nettoyage préliminaire:\n\n+ En premier lieu, le data set est chargé en utilisant les méthodes de la librairie Pandas, nous effectuons le cleaning initial des données, en supprimant les lignes ne contenant pas de tags (qui ne nous seront pas utiles), et les éventuels duplicata.\n\n+ La taille initiale du Data Set est (50000, 4), taille maximale permise par requête unique sur Stack Exchange Data Explorer\n\n+ Les données fournies qui nous seront utiles sont le titre de la question, le corps du texte et les tags associés.\n\n+ Nous définissons ensuite l'ensemble des fonctions de nettoyage et de traitement du texte que nous utiliserons pour nettoyer chaque partie des données que nous allons utiliser\n\n"},{"metadata":{"trusted":true,"_uuid":"c3858dc286784a880c928f27274f340a9ea4c13b"},"cell_type":"code","source":"# We load the data set\n#df = pd.read_csv(BytesIO(csv_as_bytes))\ndf = pd.read_csv(\"../input/QueryResults2018.csv\")\nprint(df.shape)\ndf.head()\ndf=df.drop_duplicates()\ndf.dropna(inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"af51d639ca8947fe658a0065a258ed10eb6670d7"},"cell_type":"markdown","source":"### Fonctions définies:\n\n+ **separate_code(text)**: Sépare le code informatique du reste du texte dans le corps des questions. On utilise pour cela les expressions régulières pour isoler le contenu des tags code\n+ **remove_code(text)**: une fois le code extrait et enregistré dans une nouvelle colonne du Data Frame, on utilise cette méthode pour le supprimer du corps de texte\n+ **remove_html(text)**: en utilisant une méthode du module de scraping BeautifulSoup, on supprime les tags HTML présents dans le corps de texte\n+ **letters_only(text)**: fonction permettant de supprimer la ponctuation, les caractères spéciaux et les nombres du texte pour ne conserver que le texte brut\n+ **tokenize_body(text)**: fonction permettant de \"tokenizer\" les questions afin de pouvoir appliquer le POS tagging, le stemming et le lemmatizing\n+ **postag_body(text)**: POS tagging du texte tokenizé en vue de la lemmatization, on utilise ici la méthode de tagging du module NLTK\n+ **wordnet_tag(tag)**: conversion des tags obtenus par le tagging NLTK en tags compatibles avec le Wordnet Lemmatizer\n+ **lemm(text)**: lemmatisation du texte\n+ **stem(text)**: stemming du texte\n+ **remove_stopwords(text)**: fonction qui supprime les stopwords prédéfinis du texte\n+ **code_strip(text)**: nettoyage des sections de code extraites du texte afin de ne conserver ici aussi que les caractères alphabétiques\n+ **tag_clean(text)**: reformatage des tags afin de supprimer les caractères \">\" et \"<\"\n+ **body_join(text)**: réunion en une seule chaîne de caractères des listes de mots obtenues après tokenization"},{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"trusted":true,"_uuid":"264bdda3020b1bb0c9e341ce5ab47f41aeb0a40c"},"cell_type":"code","source":"def separate_code(text):\n    pointer=text.find('<code>')\n    result=''\n    while pointer!=-1:\n        ender=text.find(u'</code>',pointer)\n        result=result+text[pointer+6:ender]\n        pointer=text.find('<code>',ender)\n    return result\n\n  \ndef remove_code(text):\n    pointer=text.find('<code>')\n    while pointer!=-1:\n        ender=text.find(u'</code>')\n        text=text.replace(text[pointer:ender+7],' ')\n        pointer=text.find('<code>')\n    return text\ndef remove_html(text):\n    return BeautifulSoup(text, 'lxml').get_text()\n\n\ndef letters_only(text):\n    text=text.lower()\n    text=re.sub(\"c\\+\\+\",\"cplusplus\", text)\n    text=re.sub(\"c#\",\"csharp\", text)\n    text=re.sub(\"\\.net\",\"dotnet\", text)\n    text=re.sub(\"d3\\.js\",\"d3js\", text)\n    text=re.sub(\"[^a-zA-Z]\",\" \", text)\n    return text\n\n  \ndef tokenize_body(text):\n    text=word_tokenize(text)\n    return text\n  \n  \nlm = WordNetLemmatizer()\n\ndef wordnet_tag(tag):\n        # Convert POS default tags to wordnet lemmatizer tags\n        if tag.startswith('J'):\n            return wordnet.ADJ\n        elif tag.startswith('V'):\n            return wordnet.VERB\n        elif tag.startswith('N'):\n            return wordnet.NOUN\n        elif tag.startswith('R'):\n            return wordnet.ADV\n        else:\n            # Default pos in lemmatization is Noun\n            return wordnet.NOUN\n\ntagger=PerceptronTagger()          \ndef postag_body(text):\n    text=tagger.tag(text)\n    return text\n  \n  \ndef lemm(text):\n    for i,word in enumerate(text):\n        text[i]=lm.lemmatize(word[0],pos=wordnet_tag(word[1]))\n    return text\n  \n  \nps = PorterStemmer()\n\ndef stem(text):\n    for word in text:\n        word=ps.stem(word)\n    return text\n  \n  \ndefault_stopwords = set(stopwords.words('english'))\n# The custom Stopwords list is a custom list built and curated manually after running a count vectorizer on the body a first time\ncustom_stopwords = pickle.load( open( \"../input/custom_stopwords.p\", \"rb\" ) )\nstpwrds= default_stopwords.union(custom_stopwords)\n\n\ndef remove_stopwords(text):\n    return [ w for w in text if not w in stpwrds]\n  \n  \ndef code_strip(text):\n    text=text.strip(u'\\n')\n    text=text.lower()\n    text=re.sub(\"[^a-zA-Z]\",\" \", text)\n    return text\n  \n  \ndef tag_clean(text):\n    text=re.sub(\"<\",\"\", text)\n    text=re.sub(\">\",\" \", text)\n    return text\n  \ndef body_join(text):\n    text=' '.join(text)\n    return text  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce9f5a01a91ec855ab9bf57987c97b95458691c5","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Code']=df['Body'].apply(separate_code).apply(code_strip)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"da4e0ffb449c1c70ab8623922793582744815f7f","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(remove_code).apply(remove_html).apply(letters_only)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f896ad423e5737c3c06097398bb9363a74c0f02","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(tokenize_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92afed9ebf0d6186e4e0bd9ef13ca6475b6d6357","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(postag_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8a6d66c4796c6c37bcd47d1c4fa74474c655c6c","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(lemm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c836c3687ef49a8d3c79ff1864b45cf27de7bfc4","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(stem) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"02ff0c357833078993c331d10fbdd8cdd1527427","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Body']=df['Body'].apply(remove_stopwords).apply(body_join)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bdbe081d2fe474ddd803d99a5ead7620182cfab","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(letters_only)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1e9211f5d59495cae8438a8dc898016cd0cb579","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(tokenize_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78257853e7010ab26ea5702192a019612b8d894d","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(postag_body)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7f77b60eaea8c46042f82e9d144492f6650f7606","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(lemm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"65d6d429d1fbe5cd2d714132ea468ef06eda102c","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(stem)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b66db094825cc3fbcd84fa55718df85316507b41","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Title']=df['Title'].apply(remove_stopwords).apply(body_join)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6149040ec7dbebf0f3b0b61ea3e4cd949ef50bb7","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"df['Tags']=df['Tags'].apply(tag_clean)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c19fee38a0bb150e31820902e45f26413357c33"},"cell_type":"markdown","source":"## 2. Application d'une méthode non supervisée de modélisation des topics et tags\n\n### 2.1 Implémentation d'une LDA sur les titres des questions:\n\nPour notre approche non supervisée, nous utiliserons en premier lieu uniquement les titres des questions. Ceux-ci contiennent en général les informations spécifiques au sujet de la question et sont, a priori, suffisants pour avoir une idée du contenu de celle-ci.\n\n+ On utilise une LDA (Latent Dirichlet Allocation) pour obtenir une liste des sujets ou topics principaux des questions dont nous disposons"},{"metadata":{"trusted":true,"_uuid":"b6a361077001014f806b0ff9f5f9f731fc48c3d6"},"cell_type":"code","source":"title_vectorizer= CountVectorizer()\ntitle_CV=title_vectorizer.fit_transform(df['Title'])\ntitle_feature_names=title_vectorizer.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eef0429e995c335a999152d76e9926ae44a1c5cf"},"cell_type":"code","source":"#no_dummytags = 100\n\n#lda_title = LatentDirichletAllocation(n_components=no_dummytags, max_iter=5, learning_method='online', learning_offset=50., n_jobs=4,random_state=0).fit(title_CV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9a3a73d70d0953e1289a067ae5fc4d9fec09a43c","_kg_hide-input":false,"_kg_hide-output":true},"cell_type":"code","source":"#we directly load the model since lda is slow\nlda_title = pickle.load( open( \"../input/lda_title.p\", \"rb\" ) )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9d91a777262daf4852547b7bf69662eba9c29022"},"cell_type":"markdown","source":"\n\n#### On affiche quelques topics sous forme de Word Clouds afin d'évaluer les résultats:\n\n\n"},{"metadata":{"trusted":true,"_uuid":"f1b316205ef7bee55a7d60bc9d1363d9a6485785","_kg_hide-input":true},"cell_type":"code","source":"wordcloud= WordCloud(mode=\"RGBA\", background_color=None, max_words=50)\nfig = plt.figure(figsize=(30, 30))\nfig.subplots_adjust(hspace=0.01, wspace=0.1)\nfor k,topic in enumerate([6,10,21,23,24,28,39,51,58]):    \n    freq={}\n    for i,j in enumerate(lda_title.components_[topic]):\n        freq[title_feature_names[i]]=j\n\n    wordcloud.generate_from_frequencies(freq)\n    sp=331+k\n    plt.subplot(sp)\n    plt.imshow(wordcloud, interpolation=\"bilinear\")\n    plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06fb48e71759eea55da29f71897fb8a0a5c18438"},"cell_type":"markdown","source":"### 2.2 Extraction des tags:\n\nLes topics extraits par la LDA nous permettent d'extraire une liste de \"tags\" éventuels obtenue par filtrage des résultats de la LDA par le biais de la vectorisation TF-IDF de ceux-ci. En ne retenant que les 20 mots ayant le score TF-IDF le plus élevé pour chaque topic, avec pour condition que ceux-ci soient présents dans un minimum de 0.01% des questions. On peut constater que cette liste, bien que non exhaustive, comporte de nombreux mots référant aux langages de programmation et constitue un \"champ lexical\" cohérent. Un nettoyage manuel éventuel pourrait permettre d'extraire un noyau de tags utiles. En comparant les tags obtenus à ceux qui sont présents dans le data set, on voit que sur 639 tags, 574 sont effectivement des tags utilisés sur le site."},{"metadata":{"trusted":true,"_uuid":"81a43769823e9da65767e0f6cda9e1197cc49810","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# Sort the values in the TFIDF matrix in descending order\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n  \n# Extract the top n words from each topic  \n \ndef extract_topn_from_vector(feature_names, sorted_items, topn=10):\n    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n    \n    #use only topn items from vector\n    sorted_items = sorted_items[:topn]\n \n    score_vals = []\n    feature_vals = []\n    \n    # word index and corresponding tf-idf score\n    for idx, score in sorted_items:\n        \n        #keep track of feature name and its corresponding score\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n \n    #create a tuples of feature,score\n    #results = zip(feature_vals,score_vals)\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    return results\n\n# Build a dictionary of topics' main features\n        \ndef list_topics(model, feature_names, no_top_words):\n    topic_dic={}\n    for idx, topic in enumerate(model.components_):\n        topic_dic[idx]=\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]])\n    return topic_dic","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c7ba81a1f0724d4245051ef9242e3c64083e60c","_kg_hide-input":true},"cell_type":"code","source":"title_vectorizer= TfidfVectorizer(sublinear_tf=True, min_df=0.001)\n\ntitle_tfidf= title_vectorizer.fit_transform(df['Title'])\n\nfeature_names=title_vectorizer.get_feature_names()\n\ntitle_topics= list_topics(lda_title, title_feature_names, 150)\n\ntitle_tags=set()\n\nfor i in range(len(title_topics)):\n  \n    tf_idf_vector=title_vectorizer.transform([title_topics[i]])\n\n    sorted_items=sort_coo(tf_idf_vector.tocoo())\n\n    title_tags=title_tags.union(set(k for k in extract_topn_from_vector(feature_names,sorted_items,20)))\n\ntag_vectorizer= CountVectorizer()\ntag_CV=tag_vectorizer.fit_transform(df['Tags'])\ntag_names=tag_vectorizer.get_feature_names()\n    \n    \nprint(\"\\nNumber of Extracted Tags:\")\nprint(len(title_tags))\n\nprint(\"\\nTags found in both the extracted tags and the tag column of the dataset:\")\n\ncross_tags= [tag for tag in tag_names if tag in title_tags]\nprint(len(cross_tags))\nprint(sorted(cross_tags))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9293f84195b183acd367f704803b34d88120c6cf"},"cell_type":"markdown","source":"\n## 3. Application d'une méthode supervisée de classification multi-label pour prédire les tags\n\nNous allons maintenant entraîner plusieurs modèles de classification supervisée sur les données dans le but de prédire les tags associés à une question. Notre approche consistera d'abord à tester plusieurs modèles et de comparer leurs perfomances respectives. L'évaluation des performances sera réalisée par le biais de plusieurs métriques prenant en compte la nature des labels ( tags multiples ) afin de sélectionner le modèle le plus probant vis-à-vis de la problématique. Le but est de sélectionner 3 modèles qui seront entraînés respectivement sur le titre, le corps et le code de la question. Le modèle final consistera en un voting des trois modèles.\nAfin d'avoir plus de données d'entraînement, cette partie utilisera un data contenant 100 000 questions.\n\n"},{"metadata":{"trusted":true,"_uuid":"3d6ce43627c00a7c087e559750b1e8aacb333e1d"},"cell_type":"code","source":"df = pd.read_csv(\"../input/training_set.csv\")\ndf=df.drop_duplicates()\ndf.dropna(inplace=True)\nprint(df.shape)\ndf.head().style","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b411ead23ab9c054b8d589d2b5f6075943a4adbf","_kg_hide-input":true},"cell_type":"code","source":"tag_vectorizer= CountVectorizer()\ntag_CV=tag_vectorizer.fit_transform(df['Tags'])\ntag_names=tag_vectorizer.get_feature_names()\n# Sum up the counts of each vocabulary word\ntag_CV=tag_CV.toarray()\ndist = np.sum(tag_CV, axis=0)\nsorted_counts=dist.argsort()\ntags={}\nfor i in sorted_counts:\n  tags[tag_names[i]]=dist[i]\ntags_df=pd.DataFrame(columns=['Tag', 'Count'])\ntags_df['Tag']=list(tags.keys())\ntags_df['Count']=list(tags.values())\ntags_df.sort_values(by=['Count'],ascending=False,inplace=True)\ntags_df.shape\n\ntags_df[0:20].plot.bar(x='Tag',y='Count',rot=60,figsize=(15,10))\nprint(\"\\n------------------Top 20 tags:--------------------------\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df63402eca5fcc66d4f849e25f57a51eb3a0bae4"},"cell_type":"markdown","source":"\n### Traitement des tags:\n\nAfin de pouvoir entraîner les modèles, il est nécessaire de traiter les tags afin de créer une matrice utilisable pour l'entraînement. Dans notre cas, nous prendrons les tags présents dans un nombre minimum de 100 questions (afin d'éviter d'obtenir une matrice surdimensionnée contenant les tags peu utilisés). Ces tags sont convertis en une matrice binaire indiquant si oui ou non le tag est présent par OneHotEncoding.\n"},{"metadata":{"trusted":true,"_uuid":"38bc5c224f3bf7f474c2317a5f20cec8e2f0a8f8","_kg_hide-input":true},"cell_type":"code","source":"tag_set=set(tags_df.Tag[tags_df['Count']>200])\n\ndef select_tags(text):\n  text=text.split()\n  return [t for t in text if t in tag_set]\n\ndf['main_tags']=df['Tags'].copy(deep=True)\n\ndf['main_tags']=df['main_tags'].apply(select_tags)\n\ndf['main_tags']=df['main_tags'].apply(body_join)\n\nY=df['main_tags'].str.get_dummies(sep=' ')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"087afd62a302bc5ec661215efddd2cdf998c7c7e"},"cell_type":"markdown","source":"#### Nous créons une métrique simple permettant de comparer les performances des modèles:\nNous évaluerons le nombre de prédictions incorrectes de la façon qui suit:\n+ wrong_label_counter: % de prédictions fausses (le tag n'existe pas dans les données de test mais est prédit par le modèle), cela équivaut à la précision.\n+ missed_label_counter: % de labels présents dans les données de test mais non prédits par le modèle, cela équivaut au recall."},{"metadata":{"trusted":true,"_uuid":"2e65bbf44dd030c91208688ddd2b5165d458b23f","_kg_hide-input":true},"cell_type":"code","source":"def wrong_label_counter(y, y_pred):\n  try:\n    y=y.values\n  except:\n    pass\n  diff = y - y_pred\n  diff[diff==1]=0\n  diff=np.abs(diff)\n  diff=np.sum(diff,axis=1)\n  size=y.shape[0]*y.shape[1]-np.count_nonzero(y)\n  return 100*np.sum(diff)/size\n\ndef missed_label_counter(y, y_pred):\n  try:\n    y=y.values\n  except:\n    pass\n  diff = y - y_pred\n  diff[diff==-1]=0\n  diff=np.abs(diff)\n  diff=np.sum(diff,axis=1)\n  size=np.count_nonzero(y)\n  return 100*np.sum(diff)/size","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0fffc16e6a359d9b8bce419e61bc53ff5cb00923"},"cell_type":"markdown","source":"\n### Entraînement des modèles:\n\nOn entraîne des ClassifierChain sur MultinomialNaiveBayes et ComplementBayes, qui sont les modèles les plus rapides sur notre jeu de données. Nous entraînerons les modèles sur les titres uniquement, puis sur le corps de text et le code, et enfin sur les trois en même temps afin de comparer la qualité des prédictions.\n\n\n"},{"metadata":{"trusted":true,"_uuid":"092184b9a5b0af686664af8f8a4909313bd9b471"},"cell_type":"code","source":"df['full_text']=df['Title']+' '+df['Body']+' '+df['Code']\nX_train, X_test, y_train, y_test= train_test_split(df, Y,test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"034869c5801efdd21513fc366d0bb5733ec186f0"},"cell_type":"code","source":"# Create a list of the tag indexes in descending order of frequency for the classifier chains\ntag_order_dict={}\nfor index,tag in enumerate(list(Y.columns)):\n    tag_order_dict[tag]=index\ntags_ordered_indexes=[]\nfor tag in tags_df['Tag']:\n    try:\n        tags_ordered_indexes.append(tag_order_dict[tag])\n    except:\n        pass","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"21d28f1fe27ebdffa8c5930b18d126e4480123c0"},"cell_type":"markdown","source":"### Entraînement sur les titres:"},{"metadata":{"trusted":true,"_uuid":"0ffa4fbd602ebd7357d8340e9658062349856979","_kg_hide-input":true},"cell_type":"code","source":"title_vectorizer= CountVectorizer()\n\nx_train=title_vectorizer.fit_transform(X_train['Title'])\nx_test=title_vectorizer.transform(X_test['Title'])\n\n# initialize classifier chains multi-label classifier\ncmb_title = ClassifierChain(ComplementNB(), order=tags_ordered_indexes)\nmnb_title = ClassifierChain(MultinomialNB(), order=tags_ordered_indexes)\n\n# Training model on train data\ncmb_title.fit(x_train, y_train)\nmnb_title.fit(x_train, y_train)\n\npredictions_cmb_title= cmb_title.predict(x_test)\npredictions_mnb_title= mnb_title.predict(x_test)  \n\nprecision_scores_titles=pd.DataFrame(columns=['Model'])\nprecision_scores_titles['Model']=['MultinomialNB Titles','ComplementNB Titles']\n\nfor col, metric in zip(['Accuracy','Hamming Loss','Wrong Labels','Missed Labels'], [accuracy_score, hamming_loss, wrong_label_counter, missed_label_counter]):\n  precision_scores_titles[col]=[metric(y_test, predictions_mnb_title), metric(y_test, predictions_cmb_title) ]\n  \nprecision_scores_titles.style","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7f5ea79f2dfa9f044449f98736dec6d5e6094d7"},"cell_type":"markdown","source":"### Entraînement sur les corps de texte:"},{"metadata":{"trusted":true,"_uuid":"4b069dc33b2a35e7546815714dee5a7a8edb8148","_kg_hide-input":true},"cell_type":"code","source":"body_vectorizer= CountVectorizer()\n\nx_train=body_vectorizer.fit_transform(X_train['Body'])\nx_test=body_vectorizer.transform(X_test['Body'])\n\n# initialize classifier chains multi-label classifier\ncmb_body = ClassifierChain(ComplementNB(),order=tags_ordered_indexes)\nmnb_body = ClassifierChain(MultinomialNB(),order=tags_ordered_indexes)\n\n# Training model on train data\ncmb_body.fit(x_train, y_train)\nmnb_body.fit(x_train, y_train)\n\npredictions_cmb_body= cmb_body.predict(x_test)\npredictions_mnb_body= mnb_body.predict(x_test)  \n\nprecision_scores_body=pd.DataFrame(columns=['Model'])\nprecision_scores_body['Model']=['MultinomialNB Body','ComplementNB Body']\n\nfor col, metric in zip(['Accuracy','Hamming Loss','Wrong Labels','Missed Labels'], [accuracy_score, hamming_loss, wrong_label_counter, missed_label_counter]):\n  precision_scores_body[col]=[metric(y_test, predictions_mnb_body), metric(y_test, predictions_cmb_body) ]\n  \nprecision_scores_body.style","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"367aa5e65480f6207069a2568a32de0deef46d7b"},"cell_type":"markdown","source":"### Entraînement sur les sections de code:"},{"metadata":{"trusted":true,"_uuid":"2c751ec6baa51611a7b5e88b4429f546a0fec15e","_kg_hide-input":true},"cell_type":"code","source":"code_vectorizer= CountVectorizer()\ncode_vectorizer.fit(X_train['Code'])\nx_train=code_vectorizer.transform(X_train['Code'])\nx_test=code_vectorizer.transform(X_test['Code'])\n\n# initialize classifier chains multi-label classifier\ncmb_code = ClassifierChain(ComplementNB(),order=tags_ordered_indexes)\nmnb_code = ClassifierChain(MultinomialNB(),order=tags_ordered_indexes)\n\n# Training model on train data\ncmb_code.fit(x_train, y_train)\nmnb_code.fit(x_train, y_train)\n\npredictions_cmb_code= cmb_code.predict(x_test)\npredictions_mnb_code= mnb_code.predict(x_test)  \n\nprecision_scores_code=pd.DataFrame(columns=['Model'])\nprecision_scores_code['Model']=['MultinomialNB Code','ComplementNB Code']\n\nfor col, metric in zip(['Accuracy','Hamming Loss','Wrong Labels','Missed Labels'], [accuracy_score, hamming_loss, wrong_label_counter, missed_label_counter]):\n  precision_scores_code[col]=[metric(y_test, predictions_mnb_code), metric(y_test, predictions_cmb_code) ]\n  \nprecision_scores_code.style","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ba6b3042a16634fd031aa825584c3c079ebb7129"},"cell_type":"markdown","source":"### Entraînement sur texte + code + titre:"},{"metadata":{"trusted":true,"_uuid":"e6f32ce2ae0ede7afffa640352516e212983c8e4","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"X_train['full_text']=X_train['Title']+' '+X_train['Body']+' '+X_train['Code']\nX_test['full_text']=X_test['Title']+' '+X_test['Body']+' '+X_test['Code']\n\nfull_text_vectorizer= CountVectorizer()\n\nx_train=full_text_vectorizer.fit_transform(X_train['full_text'])\nx_test=full_text_vectorizer.transform(X_test['full_text'])\n\n# initialize classifier chains multi-label classifier\ncmb_full_text = ClassifierChain(ComplementNB(), order=tags_ordered_indexes)\nmnb_full_text = ClassifierChain(MultinomialNB(), order=tags_ordered_indexes)\n\n# Training model on train data\ncmb_full_text.fit(x_train, y_train)\nmnb_full_text.fit(x_train, y_train)\n\npredictions_cmb_full_text= cmb_full_text.predict(x_test)\npredictions_mnb_full_text= mnb_full_text.predict(x_test)  \n\nprecision_scores_full_text=pd.DataFrame(columns=['Model'])\nprecision_scores_full_text['Model']=['MultinomialNB Full Text','ComplementNB Full Text']\n\nfor col, metric in zip(['Accuracy','Hamming Loss','Wrong Labels','Missed Labels'], [accuracy_score, hamming_loss, wrong_label_counter, missed_label_counter]):\n  precision_scores_full_text[col]=[metric(y_test, predictions_mnb_full_text), metric(y_test, predictions_cmb_full_text) ]\n  ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"022bb543005c82010f3bae6885967f9c12217cfa"},"cell_type":"code","source":"precision_scores_full_text.style","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6dcc4cb58cd491cdd020d33a91d0d0904b62860b"},"cell_type":"markdown","source":"\n\n### Combinaison des résultats des modèles entraînés sur les différentes parties des questions:\n\nOn combine les résultats des modèles obtenus par entraînement sur les titres, corps et codes individuellement afin de créer un meilleur modèle.\n\n\n"},{"metadata":{"trusted":true,"_uuid":"8186a96ef42de1c99a3cd41a1f6805c29c379df1","_kg_hide-input":true},"cell_type":"code","source":"y_pred_combined_parts=predictions_mnb_title+predictions_mnb_body+predictions_mnb_code+predictions_cmb_title+predictions_cmb_body+predictions_cmb_code\ny_pred_combined_parts[y_pred_combined_parts>=1]=1\n\ny_pred_combined_full=predictions_cmb_full_text+predictions_mnb_full_text\ny_pred_combined_full[y_pred_combined_full>=1]=1\n\nprecision_scores_vote=pd.DataFrame(columns=['Model'])\nprecision_scores_vote['Model']=['Combined Partial Models','Combined Full Text Models']\n\nfor col, metric in zip(['Accuracy','Hamming Loss','Wrong Labels','Missed Labels'], [accuracy_score, hamming_loss, wrong_label_counter, missed_label_counter]):\n  precision_scores_vote[col]=[metric(y_test, y_pred_combined_parts),metric(y_test, y_pred_combined_full)]\n  \nprecision_scores_vote.style","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"25b9db79241bbe3ba2836fa269daac513a55acca"},"cell_type":"markdown","source":"\n### Conclusion:\n\nOn constate que le meilleur résultat est obtenu par combinaison de tous les modèles entraînés lorsqu'il s'agit du recall, avec une précision légèrement inférieure à celles des autres modèles. C'est donc le modèle que nous allons retenir.\n\n"},{"metadata":{"trusted":true,"_uuid":"77a4191f73020e635413bde0c0952d46764cc03a","_kg_hide-input":true},"cell_type":"code","source":"final_scores=precision_scores_titles.append(precision_scores_body,ignore_index=True).append(precision_scores_code,ignore_index=True).append(precision_scores_full_text,ignore_index=True).append(precision_scores_vote,ignore_index=True)\nfinal_scores.style","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"dbca122e10deba4feb3043e98cac7aaa230669da"},"cell_type":"code","source":"from sklearn.metrics import recall_score\nsample_recall=recall_score(y_test, y_pred_combined_parts, average= None)\nsample_scores=pd.DataFrame()\nsample_scores['Label']=list(Y.columns)\nsample_scores['Score']=sample_recall\nsample_scores.sort_values(by='Score',ascending=False,inplace=True)\nprint(\"Recall Scores for each label in descending order\")\nsample_scores.style","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73ada5e4f1a2946d5af4a12e04b798c6101e62a6"},"cell_type":"code","source":"from sklearn.metrics import precision_score\nsample_precision=precision_score(y_test, y_pred_combined_parts, average= None)\nsample_scores=pd.DataFrame()\nsample_scores['Label']=list(Y.columns)\nsample_scores['Score']=sample_precision\nsample_scores.sort_values(by='Score',ascending=False,inplace=True)\nprint(\"Precision Scores for each label in descending order\")\nsample_scores.style","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}