{"cells":[{"metadata":{"_uuid":"1e62801e54773db5278f82704a1aa6955f87ad4a"},"cell_type":"markdown","source":"# Overview\nA number of images taken from a fixed RGBD camera recording a scene"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport os, sys\nimport numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom glob import glob\nimport yaml\nimport ipywidgets as ipw\nfrom mpl_toolkits.mplot3d import Axes3D\ntry:\n    from skimage.util.montage import montage2d\nexcept ImportError:\n    from skimage.util import montage as montage2d\nbase_dir = '../input/hallway_rgbds'","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3df6ddf993fe3cdd5f5911d2b3a475d93db83652"},"cell_type":"markdown","source":"## YAML Data\n### Calibration Format\n\nAvailable in `calibration.yaml` or `calibration.mat` files, with the\nfollowing fields:\n\n* K - camera matrix\n* Pwc - world-to-camera matrix\n* Pcw - camera-to-world matrix\n* dist - distortion coefficients"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"all_yaml = {'/'.join(p.split('/')[-2:]): yaml.load(open(p, 'r')) \n            for p in glob(os.path.join(base_dir, '*','*.yaml'))}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23df63198fd499fd29610ed96f337923736ccade"},"cell_type":"code","source":"all_images_df = pd.DataFrame({'path': glob(os.path.join(base_dir, '*','*', '*.png'))})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fca8c4af34839b0bce2872da6ca5f5940b7b3f23"},"cell_type":"code","source":"all_images_df['file_id'] = all_images_df['path'].map(lambda x: os.path.splitext(os.path.basename(x))[0])\nall_images_df['file_prefix'] = all_images_df['file_id'].map(lambda x: ''.join([c for c in x if c.isalpha()]))\nall_images_df['file_idx'] = all_images_df['file_id'].map(lambda x: ''.join([c for c in x if c.isnumeric()]))\nall_images_df['experiment'] = all_images_df['path'].map(lambda x: x.split('/')[-2])\nall_images_df['series'] = all_images_df['path'].map(lambda x: x.split('/')[-3])\nall_images_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9c37961a0550525abdb3b3c1d538210f2ee66ae"},"cell_type":"code","source":"image_pairs_df = all_images_df.pivot_table(values='path', \n                          index=['series', 'experiment', 'file_idx'], \n                          columns='file_prefix', \n                          aggfunc='first').reset_index()\nimage_pairs_df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"94d126dc53a69f449addb80ca926e4822ecb1036"},"cell_type":"code","source":"fig, m_axs = plt.subplots(3, 2, figsize = (20, 10))\nfor (ax1, ax2), (_, i_row) in zip(m_axs, \n                                  image_pairs_df.sample(len(m_axs)).iterrows()):\n    ax1.imshow(imread(i_row['rgb']))\n    ax1.set_title('RGB')\n    ax2.imshow(imread(i_row['depth']))\n    ax2.set_title('Depth Map')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c654deadcc1ff0a36059d9cee8daef9ed3436e01"},"cell_type":"code","source":"exp_list = list(image_pairs_df.groupby(['series', 'experiment']))\nprint(len(exp_list), 'experiments')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef12a3ee096571c70f7cb96e4333c9588d06a167"},"cell_type":"code","source":"(series, exp), t_rows = exp_list[-1]\nprint((series, exp))\nt_rows = t_rows.copy()\nprint(t_rows.shape[0], 'rows to process')\nt_rows['rgb'] = t_rows['rgb'].map(imread)\nt_rows['depth'] = t_rows['depth'].map(imread)\nall_depth = np.stack(t_rows['depth'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce629f788b173446065b98f8b76aa2aff767ced4"},"cell_type":"code","source":"@ipw.interact()\ndef show_scene_figure(index=(0, t_rows.shape[0])):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n    ax1.imshow(t_rows['rgb'].iloc[index])\n    ax2.imshow(t_rows['depth'].iloc[index])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c453dba3a955a847355a1eb48a0acfbbdd27e270"},"cell_type":"code","source":"fig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nvmin, vmax = np.min(all_depth), np.max(all_depth)\nax1.imshow(np.mean(all_depth, 0), vmin=vmin, vmax=vmax)\nax1.set_title('Average')\nax2.imshow(np.median(all_depth, 0), vmin=vmin, vmax=vmax)\nax2.set_title('Median')\nax3.imshow(np.std(all_depth, 0), vmin=vmin, vmax=vmax)\nax3.set_title('Std')\nax4.imshow(np.min(all_depth, 0), vmin=vmin, vmax=vmax)\nax4.set_title('Min')\nax5.imshow(np.max(all_depth, 0), vmin=vmin, vmax=vmax)\nax5.set_title('Max')\nax6.imshow(np.max(all_depth, 0)-np.min(all_depth, 0), vmin=0, vmax=vmax-vmin)\nax6.set_title('Range')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3b29dac806eb126ea0faad27e6d734f71041f93"},"cell_type":"code","source":"na_depth = all_depth.astype('float32')\nna_depth[na_depth==0] = np.NAN\nfig, ((ax1, ax2, ax3),(ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20, 15))\nvmin, vmax = np.min(all_depth), np.max(all_depth)\nax1.imshow(np.nanmean(na_depth, 0), vmin=vmin, vmax=vmax)\nax1.set_title('Average')\nax2.imshow(np.nanmedian(na_depth, 0), vmin=vmin, vmax=vmax)\nax2.set_title('Median')\nax3.imshow(np.nanstd(na_depth, 0), vmin=vmin, vmax=vmax)\nax3.set_title('Std')\nax4.imshow(np.nanmin(na_depth, 0), vmin=vmin, vmax=vmax)\nax4.set_title('Min')\nax5.imshow(np.nanmax(na_depth, 0), vmin=vmin, vmax=vmax)\nax5.set_title('Max')\nax6.imshow(np.nanmax(na_depth, 0)-np.nanmin(na_depth, 0), vmin=0, vmax=vmax-vmin)\nax6.set_title('Range')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3fb29a246a526b2ccbd87b91129b46a512564845"},"cell_type":"markdown","source":"# Convert RGBD -> Volume\nHere we convert the RGBD data into a Volume for each time step. The volume will then make it easier to see the regions which change the most"},{"metadata":{"trusted":true,"_uuid":"ccaf7788204a3b2bb17090ecdc157b3cdced7928"},"cell_type":"code","source":"(series, exp)\ncur_calib_dict = all_yaml['{}/calibration.yaml'.format(series)]\nK = np.array(cur_calib_dict['K'])\nPcw = np.array(cur_calib_dict['Pcw'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a4e8f95c8a9d370f8dd225244a464e25834a35d"},"cell_type":"code","source":"plt.hist(all_depth[all_depth>0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"065ef1a61c9cc58b232aaca9a46d6f3b57b60d1b"},"cell_type":"code","source":"# hacky point cloud reconstruction using some TUM code\n# https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/generate_pointcloud.py\n# TODO: replace hard coded focal length and scaling factor with values from Pcw\nfocalLength = 525.0\ncenterX = K[0,2]\ncenterY = K[1,2]\nscalingFactor = 5000.0\ndef slice_to_cloud(in_depth):\n    xx, yy = np.meshgrid(range(in_depth.shape[1]), range(in_depth.shape[0]), indexing='xy')\n    Z = in_depth.astype('float32') / scalingFactor\n    X = (xx - centerX) * Z / focalLength\n    Y = (yy - centerY) * Z / focalLength\n    return X.ravel(), Y.ravel(), Z.ravel()\ndef slice_to_dfcloud(in_rgb, in_depth):\n    X, Y, Z = slice_to_cloud(in_depth[::-1])\n    pc_df = pd.DataFrame({'x': X, 'y': Y, 'z': Z})\n    for i,k in enumerate('rgb'):\n        pc_df[k] = in_rgb[::-1, :, i].ravel()\n    return pc_df.query('z>0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"339f2bf4139821799aa80e3f1d574cfec53f6aa4"},"cell_type":"code","source":"show_scene_figure(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f48c835cd732ce635057d617e29069a72e4e953e"},"cell_type":"code","source":"test_df = slice_to_dfcloud(t_rows['rgb'].iloc[0], \n                           t_rows['depth'].iloc[0]).sample(100000)\nfig, m_axs = plt.subplots(1, 3, figsize = (20, 5))\nax_names = 'xyz'\nfor i, c_ax in enumerate(m_axs.flatten()):\n    plot_axes = [x for j, x in enumerate(ax_names) if j!=i]\n    c_ax.scatter(test_df[plot_axes[0]],\n                test_df[plot_axes[1]],\n                c=test_df[['r', 'g', 'b']].values/255, \n                 s=1\n                )\n    c_ax.set_xlabel(plot_axes[0])\n    c_ax.set_ylabel(plot_axes[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d42eb6f860e6ed003d10310b61fda0f3045532b2"},"cell_type":"code","source":"fig = plt.figure(figsize=(15,10))\nax = plt.axes(projection='3d')\nax.scatter(test_df['z'], test_df['x'], test_df['y'],\n            c=test_df[['r', 'g', 'b']].values/255, s=3)  \nax.view_init(15, -45)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01ca001536490070a5c77d4b0e23d6db82c2bcea"},"cell_type":"markdown","source":"## Create a Volume\nWe make a low resolution volume and just keep track of the occupancy"},{"metadata":{"trusted":true,"_uuid":"e9284668f396561041964a808f58b49575a7555b"},"cell_type":"code","source":"import sys\nfrom scipy.spatial import KDTree\nsys.setrecursionlimit(10000) # kdtree gets hungry (https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.spatial.KDTree.html)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9029365f74f5ec64edb9ddec0812e1223f6ee443"},"cell_type":"code","source":"x_sig = 2\ny_sig = 2\nz_sig = 2\nx_steps = 100\ny_steps = 40\nz_steps = 100\nbbox = {}\nfor c, sigma in zip('xyz', [x_sig,y_sig,z_sig]):\n    ax_mean, ax_std = test_df[c].mean(), test_df[c].std()\n    bbox[c] = (ax_mean-sigma*ax_std, ax_mean+sigma*ax_std)\nxx, yy, zz = np.meshgrid(np.linspace(*bbox['x'], x_steps),\n                         np.linspace(*bbox['y'], y_steps),\n                         np.linspace(*bbox['z'], z_steps),\n                         indexing='ij'\n                        )\nprint(xx.shape)\ndx = np.diff(xx[0:2, 0, 0])[0]\ndy = np.diff(yy[0, 0:2, 0])[0]\ndz = np.diff(zz[0, 0, 0:2])[0]\ndr = np.sqrt(dx**2+dy**2+dz**2)\nprint(dx, dy, dz, dr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f3a9552c22a1f1befde545fbdc624c9c3ee03b3f"},"cell_type":"code","source":"test_df = slice_to_dfcloud(t_rows['rgb'].iloc[0], \n                           t_rows['depth'].iloc[0])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6fc8c6960353ce93dc37e48846ad38b1c89b17da"},"cell_type":"markdown","source":"## Fast Lookup\nHere we transform the test_df coordinates into indices and then set the appropriate indices."},{"metadata":{"trusted":true,"_uuid":"ead6a618d68bc6f65488995eca8f3068ec4369ba"},"cell_type":"code","source":"%%time\nfor c_ax, c_xx, c_dx, c_steps in zip('xyz', \n                            [xx, yy, zz], \n                            [dx, dy, dz], \n                            [x_steps, y_steps, z_steps]):\n    test_df['i{}'.format(c_ax)] = (test_df[c_ax]-c_xx.min())/c_dx\n    test_df['i{}'.format(c_ax)] = test_df['i{}'.format(c_ax)].map(lambda x: x if (x>0) and (x<c_steps) else np.NAN)\ntest_idx = test_df[['ix', 'iy', 'iz']].dropna().values.astype(int)\nprint('Valid Points: {}/{}'.format(test_idx.shape[0], test_df.shape[0]))\nout_vol = np.zeros_like(xx)\nout_vol[test_idx[:, 0], test_idx[:, 1], test_idx[:, 2]]+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"68e241972de644a0f336bda7fc46055e348f787c"},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\nax1.imshow(np.sum(out_vol, 0))\nax2.imshow(np.sum(out_vol, 1))\nax3.imshow(np.sum(out_vol, 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7219eb5d5ece309acefca21a65d55021008c54ce"},"cell_type":"markdown","source":"## KDTree Lookup \nComparing thousands of points thousands of times is very very inefficient without binary search trees"},{"metadata":{"trusted":true,"_uuid":"b7dcbad032f0efef7e2c671ef7da0a8ec5c1d076"},"cell_type":"code","source":"%%time\ntest_kdtree = KDTree(test_df[['x', 'y', 'z']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f2480c435bf174c42b5246e18f735d6870413af"},"cell_type":"code","source":"%%time\nout_dist, _ = test_kdtree.query(np.stack([xx, yy, zz], -1), k=1, distance_upper_bound = 1.1*dr)\ndist_vol = np.isinf(out_dist).reshape(xx.shape)==False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f263665dcc7e41c659f7183ae85ce62b191117df"},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\nax1.imshow(np.sum(dist_vol, 0))\nax2.imshow(np.sum(dist_vol, 1))\nax3.imshow(np.sum(dist_vol, 2))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dcb36734ec2450b6c76bee79d94a60b168f0049c"},"cell_type":"markdown","source":"## Distance Maps could be more useful\nHere we make a distance map to the nearest point rather than a binary map"},{"metadata":{"trusted":true,"_uuid":"5c24bda9cc61614156156a76098b51791b389c9f"},"cell_type":"code","source":"%%time\nout_dist, _ = test_kdtree.query(np.stack([xx, yy, zz], -1), k=1)\ndist_vol = (out_dist<1.5*dr).reshape(xx.shape)==False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edc8f9139008ea9b174c965796e63c42c74506d3"},"cell_type":"code","source":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (20, 10))\ndist_vol = np.log2(dr/out_dist.reshape(xx.shape))\nax1.imshow(np.sum(dist_vol, 0))\nax2.imshow(np.sum(dist_vol, 1))\nax3.imshow(np.sum(dist_vol, 2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d21693c4da0401ebb65f89e4aba5f4b38567a45"},"cell_type":"code","source":"fig, (ax1) = plt.subplots(1, 1, figsize = (15, 15))\nax1.imshow(montage2d(dist_vol.swapaxes(0,1)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6fedb9db1ebc62b3426b78a428a234328b16931"},"cell_type":"markdown","source":"## Simple Marching Cubes Isosurface"},{"metadata":{"trusted":true,"_uuid":"95deea6f57fdebbfae1ab121ca0619364d3b984a"},"cell_type":"code","source":"plt.hist(dist_vol.ravel(), 50);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d3b6779d789f94c27a0a85538ace9b9cb22a64d"},"cell_type":"code","source":"fig, (ax1) = plt.subplots(1, 1, figsize = (15, 15))\nax1.imshow(montage2d(dist_vol.swapaxes(0,1)>0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91d8ddc2b4d36724e04e282cc536787ec468c20d"},"cell_type":"code","source":"from mpl_toolkits.mplot3d.art3d import Poly3DCollection\nfrom skimage import measure\nverts, faces, normals, values = measure.marching_cubes_lewiner(dist_vol, 1.0, spacing=(dx, dy, dz))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"969f93fd96575655ae92664fd7c5aa9c131d8877"},"cell_type":"code","source":"fig = plt.figure(figsize=(10, 10))\nax = fig.add_subplot(111, projection='3d')\nax.plot_trisurf(verts[:, 2], verts[:, 0], faces, verts[:, 1],\n                cmap=plt.cm.Greens, lw=0.05, edgecolor='k')\nax.view_init(15, -90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e7fca26b731d180103b22905e5026dbded6a477a"},"cell_type":"markdown","source":"# Generate all timesteps\nHere we process the rest of the time steps"},{"metadata":{"trusted":true,"_uuid":"ef9f26385749100d5dbfe6339d10981eeaa91658"},"cell_type":"code","source":"from tqdm import tqdm\nimport h5py\nwith h5py.File('time_steps.h5', 'w') as f:\n    time_ds = f.create_dataset('volume_time', \n                               shape=(t_rows.shape[0],)+xx.shape,\n                               chunks=(1,)+xx.shape, \n                               dtype='int', \n                               compression='gzip')\n    for i, (_, c_row) in tqdm(enumerate(t_rows.iterrows())):\n        test_df = slice_to_dfcloud(c_row['rgb'], \n                                   c_row['depth'])\n        for c_ax, c_xx, c_dx, c_steps in zip('xyz', \n                                    [xx, yy, zz], \n                                    [dx, dy, dz], \n                                    [x_steps, y_steps, z_steps]):\n            test_df['i{}'.format(c_ax)] = (test_df[c_ax]-c_xx.min())/c_dx\n            test_df['i{}'.format(c_ax)] = test_df['i{}'.format(c_ax)].map(lambda x: x if (x>0) and (x<c_steps) else np.NAN)\n        test_idx = test_df[['ix', 'iy', 'iz']].dropna().values.astype(int)\n        out_vol = np.zeros_like(xx)\n        out_vol[test_idx[:, 0], test_idx[:, 1], test_idx[:, 2]]+=1\n        time_ds[i] = out_vol","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a12b645d526395cc5fcae79ea3c0f0da1cb4bcb8"},"cell_type":"code","source":"!ls -lh *.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ec5f8224ab97ff08f7f0c96e07707f19952ca8c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}