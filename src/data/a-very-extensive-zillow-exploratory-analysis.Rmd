---
title: "Zillow Exploratory Analysis"
author: "Troy Walters"
date: "May 24, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE)
```

* [Data Preparation](#preparation)
* [Missing Data](#missing)
* [Target Feature Analysis](#target)
* [Geographic Features](#geographic)
* [Physical Features](#physical)
* [Geographic Features](#geographic)



```{r, message=FALSE}

library(data.table)
library(bit64)
library(tidyverse)
library(lubridate)
library(corrplot)
library(gridExtra)
library(DT)
library(leaflet)
library(htmltools)

```

## Data Preparation {#preparation}

```{r, warning=FALSE}

train_2016 <- fread('../input/train_2016.csv', showProgress=FALSE)
properties_2016 <- fread('../input/properties_2016.csv', showProgress=FALSE)

```

First, let's join the two tables together on the parcelid column such that we only include properties that have a target value in train_2016.

```{r}

# set key of both sets to parcelid
setkey(train_2016, parcelid)
setkey(properties_2016, parcelid)

# perform the join using data.table
dtrain <- properties_2016[train_2016]

# Remove train_2016 and properties_2016
rm(train_2016, properties_2016)

```

Now we've joined the two data sets and have the complete set of properties with a corresponding target feature. 

## Missing Data {#missing}

```{r}

miss_pct <- map_dbl(dtrain, function(x) { round((sum(is.na(x)) / length(x)) * 100, 1) })

miss_pct <- miss_pct[miss_pct > 0]

data.frame(miss=miss_pct, var=names(miss_pct), row.names=NULL) %>%
    ggplot(aes(x=reorder(var, -miss), y=miss)) + 
    geom_bar(stat='identity', fill='red') +
    labs(x='', y='% missing', title='Percent missing data by feature') +
    theme(axis.text.x=element_text(angle=90, hjust=1))

```


## Target Feature Analysis {#target}

First, let's take a look at the distribution of the target feature: the 'logerror'

```{r}

dtrain %>%
    ggplot(aes(x=logerror)) + 
    geom_density(fill='steelblue', color='steelblue') + 
    ggtitle('Distribution of logerror')

```

Let's see if the error varies across the the time period of the training set.

```{r}

# make transactiondate column a Date object
dtrain[, transactiondate := as.Date(transactiondate)]

dtrain[, list(med_error= abs(mean(logerror))), by=transactiondate] %>%
    ggplot(aes(x=transactiondate, y=med_error)) + 
    geom_bar(stat='identity', fill='steelblue') + 
    labs(x='', y='Mean log error', title='Absolute mean log error over time')

```

What is the volume of transaction over time?

```{r}

dtrain[, .N, by=transactiondate] %>%
    ggplot(aes(x=transactiondate, y=N)) + 
    geom_bar(stat='identity', color='steelblue') + 
    labs(x='', y='Number of transactions', title='Total transactions by day')

```



As explained in the data description, the transactions are undersampled after October 15, 2016. The test data contains the remainder of the observations after October 15. 

```{r}

plot1 <-
    dtrain[, list(n = .N, error = abs(mean(logerror))), by = month(transactiondate)] %>%
    ggplot(aes(x = as.factor(month), y = error)) +
    geom_bar(stat = 'identity', fill = 'steelblue') +
    labs(x = 'Month', y = 'Mean absolute lor error', title = 'Error by month of year')

plot2 <-
    dtrain[, list(n = .N, error = abs(mean(logerror))), by = month(transactiondate)] %>%
    ggplot(aes(x = as.factor(month), y = n)) +
    geom_bar(stat = 'identity') +
    labs(x = 'Month', y = 'Number of transactions', title = 'Number of transactions by month of year')

grid.arrange(plot1, plot2)

```


## Geographic Features {#geographic}

Let's build a map of the homes. To avoid overplotting, we'll use leaflet's clustering option and then add labels. Hover over an individual point to see that home's data.

```{r, warning=FALSE, fig.align='center'}

dtrain[, 
       list(label=HTML(
           paste(sep="<br>",
                 paste("Bedrooms:", bedroomcnt),
                 paste("Bathrooms:", bathroomcnt),
                 paste("Total area:", finishedsquarefeet15)))), 
       list(longitude, latitude)] %>%
    leaflet() %>%
    addTiles() %>%
    addCircleMarkers(
    lat =  ~ latitude / 10e5,
    lng =  ~ longitude / 10e5,
    label = ~label,
    clusterOptions = markerClusterOptions()
    )
    

```


Let's see if there is a significant difference in log error between the three counties (Los Angeles, Orange, and Ventura) in the data set. 

```{r}

dtrain[, list(n=.N, mean_error=mean(logerror), st_dev_error=sd(logerror)), by=regionidcounty] %>%
    round(3) %>% datatable()

```

It's unclear which id represents each of the three counties. However, judging by the number of transactions, I'd say that 3101 refers to Los Angeles county, 1266 is Orange county, and 2061 is Ventura county. There does not appear to be much difference in the log error between the three counties. 

## Physical Features {#physical}
 
 
To start, let's look at a correlation plot of some of the physical features including logerror. 

```{r, warning=FALSE}

cnt_vars <- c('bathroomcnt', 'bedroomcnt', 'calculatedbathnbr', 'finishedfloor1squarefeet', 
              'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet13',
              'finishedsquarefeet15', 'finishedsquarefeet50', 'finishedsquarefeet6',
              'fireplacecnt','fullbathcnt', 'garagecarcnt', 'garagetotalsqft',
              'poolcnt', 'roomcnt', 'threequarterbathnbr', 'unitcnt', 
              'numberofstories', 'logerror')

corrplot(cor(dtrain[, ..cnt_vars], use='pairwise.complete.obs'), type='lower')

```

As we might suspect, the log error does not seem to have any correlation with any of these features. 

Is there a difference in error between the building quality types?

```{r}

dtrain %>%
    ggplot(aes(x=as.factor(buildingqualitytypeid), y=logerror)) + 
    geom_jitter(alpha=0.5, color='lightgrey') + 
    geom_boxplot(color='steelblue', outlier.colour = NA)


```

It is difficult to see any difference in error across the various building types. The error is normally distributed with a low standard deviation across each of the building type categories with a reasonable number of observations. 

It's beginning to look like this will be a difficult competition in which to get ahead. There is litle variation in log error across any of the features. Of course, this is to be expected given that Zillow has refined their prediction system over many years. 

Let's check for variation in log error across some of the other discrete and factor features.


```{r, warning=FALSE}

dtrain[, list(mean_error=mean(logerror)), by=yearbuilt] %>%
    ggplot(aes(x=yearbuilt, y=abs(mean_error))) + 
    geom_point(color='grey', alpha=0.8) + 
    geom_smooth(color='steelblue') + 
    labs(y='Mean log error', title='Mean absolute log error by year built')
    
```



```{r}

ggplot(data=dtrain, aes(x=as.factor(bedroomcnt), y=abs(logerror))) + 
    geom_jitter(alpha=0.3, color='lightgrey') +
    geom_boxplot(outlier.color=NA, color='steelblue') + 
    labs(x='Number of bedrooms', title='Distribution of absolute log error by bedroom count')
    
```

```{r}

ggplot(data=dtrain, aes(x=as.factor(bathroomcnt), y=abs(logerror))) + 
    geom_jitter(alpha=0.3, color='lightgrey') +
    geom_boxplot(outlier.color=NA, color='steelblue') + 
    labs(x='Number of bathrooms', title='Distribution of absolute log error by bathroom count')
    
```

```{r}

ggplot(data=dtrain, aes(x=as.factor(unitcnt), y=abs(logerror))) + 
    geom_jitter(alpha=0.3, color='lightgrey') +
    geom_boxplot(outlier.color=NA, color='steelblue') + 
    labs(x='Number units in structure', title='Distribution of absolute log error by unit count')
    
```


I am only getting started and plan to add a lot more to this soon. Please check back.